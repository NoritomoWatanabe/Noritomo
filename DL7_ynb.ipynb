{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL7.ynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPui/fNxQned1XQzWWx20lA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoritomoWatanabe/Noritomo/blob/main/DL7_ynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_flWQbP1Uesg"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jQMaX7sY_SN",
        "outputId": "563c4ec5-6aa0-46f5-c58f-5b65767ea6ca"
      },
      "source": [
        "import sys,os\n",
        "sys.path.append(os.pardir)\n",
        "from common.util import im2col\n",
        "\n",
        "x1 = np.random.rand(1,3,7,7)\n",
        "col1 = im2col(x1,5,5,stride=1,pad=0)\n",
        "print(col1.shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9, 75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PddYHqrwY_Xr",
        "outputId": "887c3e15-8e9d-4f3d-daef-632201b0980c"
      },
      "source": [
        "x2 = np.random.rand(10,3,7,7)\n",
        "col2=im2col(x2,5,5,stride=1,pad=0)\n",
        "print(col2.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFGW7UOUY_bO"
      },
      "source": [
        "class Convolution:\n",
        "  def __init__(self,w,b,stride=1,pad=0):\n",
        "    self.W=W\n",
        "    self.b = b\n",
        "    self.stride = stride\n",
        "    self.pad=pad\n",
        "\n",
        "  def forward(self,x):\n",
        "    FN,C,FH,FW = self.W.shape\n",
        "    out_h=int(1+(H+2*self.pad-PH)/self.stride)\n",
        "\n",
        "    col = im2col(x,FH,FW,self.stride,self.pad)\n",
        "    col_w=self.W.reshape(FN,-1).T\n",
        "    out = np.dot(col,col_W) + self.b\n",
        "\n",
        "    out = out.reshape(N,out_h,out_w,-1).transpose(0,3,1,2)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3yi1-WKgnLN"
      },
      "source": [
        "class Pooling:\n",
        "  def __init(self,ppol_h,pool_w,stride=2,pad=0):\n",
        "    self.pool_h = pool_h\n",
        "    self.pool_w =pool_w\n",
        "    self.stride = stride\n",
        "    self.pad = pad\n",
        "\n",
        "  def forward(self,x):\n",
        "    N,C,H,W = x.shape\n",
        "    out_h = int(1 +(H - self.pool_h)/self.stride)\n",
        "    out_w = int(1 +(W-self.pool_w)/self.stride)  \n",
        "    col = im2col(x,self.pool_h,self.pool_w,self.stride,self.pad)\n",
        "    col = col.reshape(-1,self.pool_h*self.pool_w)\n",
        "\n",
        "    out = np.max(col,axis=1)\n",
        "\n",
        "    out = out.reshape(N,out_h,out_w,C).transpose(0,3,1,2)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx7Ss3mEhoah"
      },
      "source": [
        "\n",
        "class SimpleConvNet:\n",
        "  def __init__(self, input_dim=(1, 28, 28), \n",
        "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
        "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
        "        filter_num = conv_param['filter_num']\n",
        "        filter_size = conv_param['filter_size']\n",
        "        filter_pad = conv_param['pad']\n",
        "        filter_stride = conv_param['stride']\n",
        "        input_size = input_dim[1]\n",
        "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
        "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
        "\n",
        "        # 重みの初期化\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * \\\n",
        "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
        "        self.params['b1'] = np.zeros(filter_num)\n",
        "        self.params['W2'] = weight_init_std * \\\n",
        "                            np.random.randn(pool_output_size, hidden_size)\n",
        "        self.params['b2'] = np.zeros(hidden_size)\n",
        "        self.params['W3'] = weight_init_std * \\\n",
        "                            np.random.randn(hidden_size, output_size)\n",
        "        self.params['b3'] = np.zeros(output_size)\n",
        "\n",
        "        # レイヤの生成\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
        "                                           conv_param['stride'], conv_param['pad'])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
        "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
        "        self.layers['Relu2'] = Relu()\n",
        "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
        "\n",
        "        self.last_layer = SoftmaxWithLoss()\n",
        "\n",
        "  def predict(self, x):\n",
        "      for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "      return x\n",
        "\n",
        "  def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return self.last_layer.forward(y, t)\n",
        "\n",
        "  def gradient(self, x, t):\n",
        "     \n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.last_layer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 設定\n",
        "        grads = {}\n",
        "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
        "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        "\n",
        "        return grads\n",
        "\n",
        "  def save_params(self, file_name=\"params.pkl\"):\n",
        "        params = {}\n",
        "        for key, val in self.params.items():\n",
        "            params[key] = val\n",
        "        with open(file_name, 'wb') as f:\n",
        "            pickle.dump(params, f)\n",
        "\n",
        "  def load_params(self, file_name=\"params.pkl\"):\n",
        "        with open(file_name, 'rb') as f:\n",
        "            params = pickle.load(f)\n",
        "        for key, val in params.items():\n",
        "            self.params[key] = val\n",
        "\n",
        "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
        "            self.layers[key].W = self.params['W' + str(i+1)]\n",
        "            self.layers[key].b = self.params['b' + str(i+1)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "6uvQyTjovtfW",
        "outputId": "bc83841f-57e4-44c2-fd22-b27f81197379"
      },
      "source": [
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-814f6d024930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# データの読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 処理に時間のかかる場合はデータを削減\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dataset/mnist.py\u001b[0m in \u001b[0;36mload_mnist\u001b[0;34m(normalize, flatten, one_hot_label)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0minit_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dataset/mnist.py\u001b[0m in \u001b[0;36minit_mnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mdownload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating pickle file ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dataset/mnist.py\u001b[0m in \u001b[0;36m_convert_numpy\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_img'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0m_load_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_img'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dataset/mnist.py\u001b[0m in \u001b[0;36m_load_img\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Converting \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" to NumPy Array ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[1;32m    494\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p770Oj05tqVW",
        "outputId": "9d9765ea-4940-49db-d725-ce028c63ee68"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from simple_convnet import SimpleConvNet\n",
        "from common.trainer import Trainer\n",
        "\n",
        "# データの読み込み\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
        "\n",
        "# 処理に時間のかかる場合はデータを削減 \n",
        "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
        "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
        "\n",
        "max_epochs = 20\n",
        "\n",
        "network = SimpleConvNet(input_dim=(1,28,28), \n",
        "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
        "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
        "                        \n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
        "                  epochs=max_epochs, mini_batch_size=100,\n",
        "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
        "                  evaluate_sample_num_per_epoch=1000)\n",
        "trainer.train()\n",
        "\n",
        "# パラメータの保存\n",
        "network.save_params(\"params.pkl\")\n",
        "print(\"Saved Network Parameters!\")\n",
        "\n",
        "# グラフの描画\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(max_epochs)\n",
        "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
        "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "train loss:0.0005802152688588391\n",
            "train loss:0.0034778449520918233\n",
            "train loss:0.005344797414983584\n",
            "train loss:0.002153253871847322\n",
            "train loss:0.07570850435009024\n",
            "train loss:0.012903279002835374\n",
            "train loss:0.0039630074140070935\n",
            "train loss:0.0075039908597188945\n",
            "train loss:0.002209407081505217\n",
            "train loss:0.0022371176108755457\n",
            "train loss:0.0022719109157173624\n",
            "train loss:0.0018876790037326463\n",
            "train loss:0.0018913732431439865\n",
            "train loss:0.008004664240899746\n",
            "train loss:0.0017756338306142792\n",
            "train loss:0.003953164337512937\n",
            "train loss:0.009993536124323113\n",
            "train loss:0.0027991502795747213\n",
            "train loss:0.003689424391868772\n",
            "train loss:0.027818974892779548\n",
            "train loss:0.000705573586624722\n",
            "train loss:0.0031163806924537248\n",
            "train loss:0.019615765109044385\n",
            "train loss:0.009065001873937922\n",
            "train loss:0.0028562339005762088\n",
            "train loss:0.002201785628710084\n",
            "train loss:0.0014824958118886075\n",
            "train loss:0.02187639607612164\n",
            "train loss:0.04045651223175985\n",
            "train loss:0.007796755179995777\n",
            "train loss:0.006584212602612001\n",
            "train loss:0.009500846860848414\n",
            "train loss:0.0015942175048647065\n",
            "train loss:0.010361223089795963\n",
            "train loss:0.009204752701658138\n",
            "train loss:0.00418181457865023\n",
            "train loss:0.0030839986293681497\n",
            "train loss:0.0011620350147968522\n",
            "train loss:0.0106418547750849\n",
            "train loss:0.0015601422881333909\n",
            "train loss:0.0005242944950512764\n",
            "train loss:0.0025459161842661233\n",
            "train loss:0.005665788079556193\n",
            "train loss:0.004161697780501195\n",
            "train loss:0.008659587255880221\n",
            "train loss:0.011829200430173254\n",
            "train loss:0.022136300141752024\n",
            "train loss:0.003719600589543639\n",
            "train loss:0.0078664627075409\n",
            "train loss:0.007999768335656243\n",
            "train loss:0.0004535582465392272\n",
            "train loss:0.004748473957313376\n",
            "train loss:0.0010468154393513454\n",
            "train loss:0.003914556261248523\n",
            "train loss:0.0037176571497985877\n",
            "train loss:0.017556841346823532\n",
            "train loss:0.003318238963084585\n",
            "train loss:0.003106519129632614\n",
            "train loss:0.0016792423289270963\n",
            "train loss:0.001299924711604135\n",
            "train loss:0.002065997621123231\n",
            "train loss:0.010236698899555847\n",
            "train loss:0.001789010675884761\n",
            "train loss:0.007663848092323028\n",
            "train loss:0.0019991113419254025\n",
            "train loss:0.00882468576309018\n",
            "train loss:0.0012139842736837182\n",
            "train loss:0.017253050042485958\n",
            "train loss:0.03269027547614243\n",
            "train loss:0.021482207834887395\n",
            "train loss:0.008634205814244315\n",
            "train loss:0.004740618023197308\n",
            "train loss:0.008189043700477612\n",
            "train loss:0.005978972275331179\n",
            "train loss:0.03235749911678661\n",
            "train loss:0.014019673490276933\n",
            "train loss:0.006411669097601166\n",
            "train loss:0.0023903459732989587\n",
            "train loss:0.009248034861389835\n",
            "train loss:0.0024040065904358853\n",
            "train loss:0.013292799357439721\n",
            "train loss:0.0032979162813285955\n",
            "train loss:0.0006359608435247211\n",
            "train loss:0.09644347542957118\n",
            "train loss:0.0027887416519969473\n",
            "train loss:0.005088011197963687\n",
            "train loss:0.0021120527645091085\n",
            "train loss:0.006027643724638337\n",
            "train loss:0.0016495742975256278\n",
            "train loss:0.008117388962867126\n",
            "train loss:0.0036002819765129468\n",
            "train loss:0.009131169063240047\n",
            "train loss:0.005756946927480186\n",
            "train loss:0.0007527928539776428\n",
            "train loss:0.0012486296131645304\n",
            "train loss:0.007207290156464821\n",
            "train loss:0.01092219757818626\n",
            "train loss:0.021772052004147096\n",
            "train loss:0.0012905070801346495\n",
            "train loss:0.002593201067047399\n",
            "train loss:0.01497382740926844\n",
            "train loss:0.0025288615442405466\n",
            "train loss:0.0013526811471278283\n",
            "train loss:0.008950347011701516\n",
            "train loss:0.0013105842533619036\n",
            "train loss:0.027015184270091558\n",
            "train loss:0.004437471811907005\n",
            "train loss:0.0007311893412445173\n",
            "train loss:0.03256098473408207\n",
            "train loss:0.0015970368199708035\n",
            "train loss:0.002987696910842354\n",
            "train loss:0.022607238786572777\n",
            "train loss:0.004572299543697298\n",
            "train loss:0.000760138604697757\n",
            "train loss:0.0039163035558123695\n",
            "train loss:0.0028241306556143777\n",
            "train loss:0.0016357276080441986\n",
            "train loss:0.002428398818391632\n",
            "train loss:0.006628963871639641\n",
            "train loss:0.004254908187332922\n",
            "train loss:0.0015972490816012776\n",
            "train loss:0.0011948003196985055\n",
            "train loss:0.0382258816642455\n",
            "train loss:0.017731970966419805\n",
            "train loss:0.007893823739711852\n",
            "train loss:0.003769270759382548\n",
            "train loss:0.004438180234604694\n",
            "train loss:0.002622395512128069\n",
            "train loss:0.0032287054158938594\n",
            "train loss:0.006894316109778786\n",
            "train loss:0.0010133853716568198\n",
            "train loss:0.011270841286667372\n",
            "train loss:0.007371246824706273\n",
            "train loss:0.007970023146382583\n",
            "train loss:0.00814833616547781\n",
            "train loss:0.007320687068380336\n",
            "train loss:0.011528307648846573\n",
            "train loss:0.006006898722358923\n",
            "train loss:0.005159403561851734\n",
            "train loss:0.0027029363453620835\n",
            "train loss:0.0033221961696105083\n",
            "train loss:0.02198261615087753\n",
            "train loss:0.01035196562341553\n",
            "train loss:0.004539147761854724\n",
            "train loss:0.005093522206314067\n",
            "train loss:0.004189784724786345\n",
            "train loss:0.003640539694229829\n",
            "train loss:0.00975708979039303\n",
            "train loss:0.0072315782982819085\n",
            "train loss:0.011754597792382391\n",
            "train loss:0.0012196951056025367\n",
            "train loss:0.01171042054956124\n",
            "train loss:0.001651363534489034\n",
            "train loss:0.0009901212216786562\n",
            "train loss:0.01319908051778486\n",
            "train loss:0.045811043063835086\n",
            "train loss:0.00215681587775569\n",
            "train loss:0.0015039175847357692\n",
            "train loss:0.02321079181044278\n",
            "train loss:0.0016340672809802967\n",
            "train loss:0.0011996143697232658\n",
            "train loss:0.002847899868426828\n",
            "train loss:0.005838160994584552\n",
            "train loss:0.000553745590185645\n",
            "train loss:0.0038111811657232414\n",
            "train loss:0.001723147118024515\n",
            "train loss:0.002093143452979685\n",
            "train loss:0.0011992009516575265\n",
            "train loss:0.0024439404135519526\n",
            "train loss:0.005168775968599817\n",
            "train loss:0.05638274680347823\n",
            "train loss:0.007992159050291367\n",
            "train loss:0.006638121800262139\n",
            "train loss:0.0023571750492099625\n",
            "train loss:0.010943370810520558\n",
            "train loss:0.0017454345490690575\n",
            "train loss:0.00046316403319239134\n",
            "train loss:0.0032802270945199363\n",
            "train loss:0.01624873172794908\n",
            "train loss:0.004002465605040458\n",
            "train loss:0.010305347356660974\n",
            "train loss:0.004982745041607571\n",
            "train loss:0.013881033992498156\n",
            "train loss:0.0017657236107250732\n",
            "train loss:0.006364470994429162\n",
            "train loss:0.024461328171727123\n",
            "train loss:0.000414380398442872\n",
            "train loss:0.0037426183522010193\n",
            "train loss:0.012914011567503245\n",
            "train loss:0.003579836012900864\n",
            "=== epoch:13, train acc:0.997, test acc:0.993 ===\n",
            "train loss:0.00045603507947196615\n",
            "train loss:0.00680920210273573\n",
            "train loss:0.003268953496643692\n",
            "train loss:0.005784333591926382\n",
            "train loss:0.0011394814248653097\n",
            "train loss:0.0027062618249564657\n",
            "train loss:0.029022553359080848\n",
            "train loss:0.006082935476215548\n",
            "train loss:0.02120687942983122\n",
            "train loss:0.005141601551242469\n",
            "train loss:0.040846996269580646\n",
            "train loss:0.0018641135957375007\n",
            "train loss:0.003330041233910143\n",
            "train loss:0.0002722316683850599\n",
            "train loss:0.0005008237455041973\n",
            "train loss:0.00351045544871102\n",
            "train loss:0.002544763170544403\n",
            "train loss:0.0025183614994791765\n",
            "train loss:0.005095200579044949\n",
            "train loss:0.0013125530772910329\n",
            "train loss:0.005679145499624506\n",
            "train loss:0.013818929330251726\n",
            "train loss:0.000451976551688408\n",
            "train loss:0.004023936228634856\n",
            "train loss:0.0014396426596700923\n",
            "train loss:0.00219643121025959\n",
            "train loss:0.0018932421715801024\n",
            "train loss:0.002254793138811918\n",
            "train loss:0.0005394394780269212\n",
            "train loss:0.002868836190908455\n",
            "train loss:0.004707827444659334\n",
            "train loss:0.00048580345493477354\n",
            "train loss:0.03488934484630986\n",
            "train loss:0.002019037179948741\n",
            "train loss:0.00023296197430597093\n",
            "train loss:0.0014712542614599272\n",
            "train loss:0.00525273696468486\n",
            "train loss:0.00264711808718424\n",
            "train loss:0.0004007174598881413\n",
            "train loss:0.0011099411523670993\n",
            "train loss:0.009555682356845941\n",
            "train loss:0.0020962584922977453\n",
            "train loss:0.004388082096820163\n",
            "train loss:0.0034754077879390216\n",
            "train loss:0.028081663972728176\n",
            "train loss:0.000727344688744279\n",
            "train loss:0.004051374230268288\n",
            "train loss:0.0002404877710500516\n",
            "train loss:0.004600964717193065\n",
            "train loss:0.012613019738335247\n",
            "train loss:0.003963036220206563\n",
            "train loss:0.005042347752852723\n",
            "train loss:0.0024720326943055214\n",
            "train loss:0.0064473785562757235\n",
            "train loss:0.003600706120833951\n",
            "train loss:0.014642790157384247\n",
            "train loss:0.00788509218681235\n",
            "train loss:0.003958813069999118\n",
            "train loss:0.0017874936802998738\n",
            "train loss:0.00626309805421248\n",
            "train loss:0.003425066648536653\n",
            "train loss:0.0007857620758545428\n",
            "train loss:0.005879441347181947\n",
            "train loss:0.0007244569315611082\n",
            "train loss:0.0025704284778803434\n",
            "train loss:0.001094750834685286\n",
            "train loss:0.0025706620803178314\n",
            "train loss:0.012104308689530805\n",
            "train loss:0.003221064888525384\n",
            "train loss:0.011638963037742665\n",
            "train loss:0.0008217039077539462\n",
            "train loss:0.006934673631969619\n",
            "train loss:0.018426568494692444\n",
            "train loss:0.008471848169192808\n",
            "train loss:0.0022868002108173916\n",
            "train loss:0.0023311105439139286\n",
            "train loss:0.00748780328052665\n",
            "train loss:0.0025431063936805494\n",
            "train loss:0.007437431927765814\n",
            "train loss:0.005469951659884057\n",
            "train loss:0.04071215216587126\n",
            "train loss:0.0009877151904174148\n",
            "train loss:0.0006632839050387411\n",
            "train loss:0.001748168846643203\n",
            "train loss:0.0026131499810087967\n",
            "train loss:0.00048649598633574695\n",
            "train loss:0.002675264353196026\n",
            "train loss:0.036150403297917376\n",
            "train loss:0.0031282558549157076\n",
            "train loss:0.0002882050598023652\n",
            "train loss:0.005202346646656356\n",
            "train loss:0.0008327308054523716\n",
            "train loss:0.005856780971494263\n",
            "train loss:0.0123090965437572\n",
            "train loss:0.001805559253073254\n",
            "train loss:0.002442126240049651\n",
            "train loss:0.0008316971374176019\n",
            "train loss:0.002117888164650928\n",
            "train loss:0.0007849578534475017\n",
            "train loss:0.0010710316925184415\n",
            "train loss:0.000544241707033946\n",
            "train loss:0.0029309083200927673\n",
            "train loss:0.0014775138334005623\n",
            "train loss:0.011199607061406127\n",
            "train loss:0.0007228208244454329\n",
            "train loss:0.002165012748164702\n",
            "train loss:0.0005396188231239852\n",
            "train loss:0.0011819550882685445\n",
            "train loss:0.008138738169131122\n",
            "train loss:0.004990560361357773\n",
            "train loss:0.020951544833671943\n",
            "train loss:0.019932714151624547\n",
            "train loss:0.0003302613553329702\n",
            "train loss:0.0048535303420134636\n",
            "train loss:0.0019548968983623093\n",
            "train loss:0.015997007205440627\n",
            "train loss:0.004571873842059677\n",
            "train loss:0.0005567200727556572\n",
            "train loss:0.07914515947682942\n",
            "train loss:0.005265721216327523\n",
            "train loss:0.00613266505096063\n",
            "train loss:0.0008216716551412262\n",
            "train loss:0.008571201588777798\n",
            "train loss:0.0025154042994857333\n",
            "train loss:0.0009282392038198566\n",
            "train loss:0.0018396553970163165\n",
            "train loss:0.0015742240434272426\n",
            "train loss:0.0003249986332858384\n",
            "train loss:0.0031646442046371487\n",
            "train loss:0.008354750280796108\n",
            "train loss:0.0014585284629293773\n",
            "train loss:0.005775588672117365\n",
            "train loss:0.0014086092953553868\n",
            "train loss:0.0026141556725607297\n",
            "train loss:0.015382759917237712\n",
            "train loss:0.0036507449078185044\n",
            "train loss:0.0003571060801457816\n",
            "train loss:0.009216366136065484\n",
            "train loss:0.010042396463009935\n",
            "train loss:0.006292962231241136\n",
            "train loss:0.002470008858869953\n",
            "train loss:0.0041509811147965245\n",
            "train loss:0.0022808031121269476\n",
            "train loss:0.0024759168371722394\n",
            "train loss:0.0052513431700615945\n",
            "train loss:0.0010178141585306937\n",
            "train loss:0.008866001073541654\n",
            "train loss:0.00395214171152231\n",
            "train loss:0.001729121338474097\n",
            "train loss:0.006170542587981478\n",
            "train loss:0.003178320996932348\n",
            "train loss:0.010711509784930484\n",
            "train loss:0.012388042808896962\n",
            "train loss:0.0010527644088614248\n",
            "train loss:0.000615508758104207\n",
            "train loss:0.002262530447391552\n",
            "train loss:0.003452690156505476\n",
            "train loss:0.0013542059141720538\n",
            "train loss:0.0034072181078629383\n",
            "train loss:0.003620330551282512\n",
            "train loss:0.006175181228505459\n",
            "train loss:0.002314704628963189\n",
            "train loss:0.012783288762237272\n",
            "train loss:0.004202675215337772\n",
            "train loss:0.004656860529701269\n",
            "train loss:0.0016780232203635608\n",
            "train loss:0.0024870656848225304\n",
            "train loss:0.006494411953207365\n",
            "train loss:0.0061245323963979095\n",
            "train loss:0.005800491058111361\n",
            "train loss:0.003774450026784325\n",
            "train loss:0.0021183452152799946\n",
            "train loss:0.0008481333966590978\n",
            "train loss:0.0034225239388976686\n",
            "train loss:0.009258046981831103\n",
            "train loss:0.0027230775182349506\n",
            "train loss:0.0006845979276590895\n",
            "train loss:0.0031254753379370507\n",
            "train loss:0.008139627562759343\n",
            "train loss:0.001877975815636776\n",
            "train loss:0.0027643217673110824\n",
            "train loss:0.0006700747009929653\n",
            "train loss:0.004919155031559426\n",
            "train loss:0.0016625719502650549\n",
            "train loss:0.004319942106133159\n",
            "train loss:0.012549582500436427\n",
            "train loss:0.019234561641092197\n",
            "train loss:0.0008459726197018848\n",
            "train loss:0.004057376672511105\n",
            "train loss:0.0031664289686743857\n",
            "train loss:0.004229351033092605\n",
            "train loss:0.005474302872692073\n",
            "train loss:0.01159553170068156\n",
            "train loss:0.0010980372555590538\n",
            "train loss:0.006374528953954474\n",
            "train loss:0.0013712169937626162\n",
            "train loss:0.0019819251812404383\n",
            "train loss:0.005648484814009556\n",
            "train loss:0.004483372151150773\n",
            "train loss:0.003015611642179799\n",
            "train loss:0.0013972932213009292\n",
            "train loss:0.010621744550937793\n",
            "train loss:0.002981902454964047\n",
            "train loss:0.0010877686170489705\n",
            "train loss:0.0029413837830106725\n",
            "train loss:0.009097526876958568\n",
            "train loss:0.00047852788380294003\n",
            "train loss:0.002296813650525964\n",
            "train loss:0.00350024021222272\n",
            "train loss:0.007011011323262292\n",
            "train loss:0.00021158907208092845\n",
            "train loss:0.0002289598534218615\n",
            "train loss:0.011159723771274534\n",
            "train loss:0.006284470964083934\n",
            "train loss:0.004006406484299772\n",
            "train loss:0.006188841587872734\n",
            "train loss:0.0006529315845276183\n",
            "train loss:0.0026818468112992707\n",
            "train loss:0.0005590783876572063\n",
            "train loss:0.00034826600238216826\n",
            "train loss:0.03843303962509011\n",
            "train loss:0.0007497335718241251\n",
            "train loss:0.0026069059070938346\n",
            "train loss:0.0005784654820327754\n",
            "train loss:0.00042480248977961525\n",
            "train loss:0.00477365612338939\n",
            "train loss:0.002192746866827643\n",
            "train loss:0.0019220822145264544\n",
            "train loss:0.0013436072534513707\n",
            "train loss:0.003324778329908077\n",
            "train loss:0.001022464697023212\n",
            "train loss:0.007347824442374002\n",
            "train loss:0.0013243467340274514\n",
            "train loss:0.004008227926245877\n",
            "train loss:0.004144729434094318\n",
            "train loss:0.007957461733720196\n",
            "train loss:0.003254003737765494\n",
            "train loss:0.0022056055929391013\n",
            "train loss:0.0020148954030404127\n",
            "train loss:0.0007424848275175282\n",
            "train loss:0.00020112479421587396\n",
            "train loss:0.0004920308842499277\n",
            "train loss:0.008395241783163044\n",
            "train loss:0.002065112886002709\n",
            "train loss:0.00018321983167914258\n",
            "train loss:0.00954597938593522\n",
            "train loss:0.0018404416967259423\n",
            "train loss:7.590065754288024e-05\n",
            "train loss:0.004987258455618659\n",
            "train loss:0.003368503621173292\n",
            "train loss:0.006177233718318138\n",
            "train loss:0.0016787783715294896\n",
            "train loss:0.04598466961990869\n",
            "train loss:0.0013990337174927695\n",
            "train loss:0.0023065074348286\n",
            "train loss:0.005924895065476462\n",
            "train loss:0.004871120401276936\n",
            "train loss:0.0014284697782420944\n",
            "train loss:0.0016983925615791672\n",
            "train loss:0.00404594801715061\n",
            "train loss:0.0004992714946621443\n",
            "train loss:0.0021666649884946425\n",
            "train loss:0.0021690375986579296\n",
            "train loss:0.003958097440276259\n",
            "train loss:0.0022632620523170876\n",
            "train loss:0.0009229432781210896\n",
            "train loss:0.009041606404615465\n",
            "train loss:0.0009712215646988739\n",
            "train loss:0.004583639683093456\n",
            "train loss:0.001170834569489438\n",
            "train loss:0.00035377999105602937\n",
            "train loss:0.022889346142928934\n",
            "train loss:0.00905445601021253\n",
            "train loss:0.026573561021499385\n",
            "train loss:0.004579399698397566\n",
            "train loss:0.008983688275145112\n",
            "train loss:0.0013573601374554242\n",
            "train loss:0.0041144375349253404\n",
            "train loss:0.0019131916160307944\n",
            "train loss:0.00034707273609444123\n",
            "train loss:0.013167656518716677\n",
            "train loss:0.0019300795838835222\n",
            "train loss:0.001354348443803782\n",
            "train loss:0.000616094309308605\n",
            "train loss:0.001047972186081657\n",
            "train loss:0.0053233094621711\n",
            "train loss:0.0026504328914996327\n",
            "train loss:0.015820136982277955\n",
            "train loss:0.004204950244468675\n",
            "train loss:0.0011938360682372555\n",
            "train loss:0.0017341953023859845\n",
            "train loss:0.004258746996418729\n",
            "train loss:0.012469521240055853\n",
            "train loss:0.0008042866735424519\n",
            "train loss:0.0034984412531949695\n",
            "train loss:0.0029237964566571576\n",
            "train loss:0.002535944492558833\n",
            "train loss:0.0020115469541647363\n",
            "train loss:0.00868141358904969\n",
            "train loss:0.0007346716398334365\n",
            "train loss:0.008927340129111193\n",
            "train loss:0.00253997594898866\n",
            "train loss:0.0024965120972637745\n",
            "train loss:0.0017226352657920838\n",
            "train loss:0.000300272417957687\n",
            "train loss:0.0009044634249763075\n",
            "train loss:0.006978972135951752\n",
            "train loss:0.00035535438046943883\n",
            "train loss:0.0005547745737670843\n",
            "train loss:0.008172783166945948\n",
            "train loss:0.00019377575218084661\n",
            "train loss:0.0003355631123077847\n",
            "train loss:0.0006787698274916854\n",
            "train loss:0.017897245927920354\n",
            "train loss:0.006672475400149279\n",
            "train loss:0.004891803902085363\n",
            "train loss:0.05213682072172114\n",
            "train loss:0.011225678896000048\n",
            "train loss:0.014872053703948798\n",
            "train loss:0.005640057272225582\n",
            "train loss:0.007200001925712487\n",
            "train loss:0.019643321713555272\n",
            "train loss:0.029865252954987445\n",
            "train loss:0.009302686237806388\n",
            "train loss:0.07387439124414348\n",
            "train loss:0.01317543287798994\n",
            "train loss:0.00042920469971949635\n",
            "train loss:0.0014398816537715942\n",
            "train loss:0.007182172368526034\n",
            "train loss:0.013863462507805175\n",
            "train loss:0.009448119161422441\n",
            "train loss:0.0020515657067406764\n",
            "train loss:0.014168067695376214\n",
            "train loss:0.008260520448346407\n",
            "train loss:0.019405224123688725\n",
            "train loss:0.008014874289032947\n",
            "train loss:0.005238133195032584\n",
            "train loss:0.00549785809210494\n",
            "train loss:0.019914114125745744\n",
            "train loss:0.0022491905117689934\n",
            "train loss:0.003130600127585437\n",
            "train loss:0.02179848389832963\n",
            "train loss:0.009856884503853327\n",
            "train loss:0.013808424238170873\n",
            "train loss:0.0016509980705699074\n",
            "train loss:0.007423365982750325\n",
            "train loss:0.0015115971810883053\n",
            "train loss:0.003286221016214449\n",
            "train loss:0.003074017436433021\n",
            "train loss:0.0064749748257060535\n",
            "train loss:0.0013165134579131588\n",
            "train loss:0.010994094963201107\n",
            "train loss:0.006814254298974923\n",
            "train loss:0.010146261286013364\n",
            "train loss:0.011038966001738093\n",
            "train loss:0.00642005264024801\n",
            "train loss:0.011085609562851945\n",
            "train loss:0.0006516165668610589\n",
            "train loss:0.007731518827728247\n",
            "train loss:0.005155818208745377\n",
            "train loss:0.0008639833666952194\n",
            "train loss:0.0433383984112552\n",
            "train loss:0.0026200883652506076\n",
            "train loss:0.003499524538406781\n",
            "train loss:0.00887223172952418\n",
            "train loss:0.004992378887691043\n",
            "train loss:0.010756554421086438\n",
            "train loss:0.003330234881400206\n",
            "train loss:0.0030802700501598827\n",
            "train loss:0.02267005669034158\n",
            "train loss:0.0017925832424423\n",
            "train loss:0.01545091896142289\n",
            "train loss:0.001195577893101904\n",
            "train loss:0.011272419205430326\n",
            "train loss:0.005539418096998721\n",
            "train loss:0.00826977004172498\n",
            "train loss:0.00026328196034282894\n",
            "train loss:0.017743288925929183\n",
            "train loss:0.010132357458061483\n",
            "train loss:0.0024802052319412003\n",
            "train loss:0.019556647423137043\n",
            "train loss:0.0018130215045965355\n",
            "train loss:0.002962039489345922\n",
            "train loss:0.0007659085056796346\n",
            "train loss:0.0005422265569034169\n",
            "train loss:0.007434169940816931\n",
            "train loss:0.014733257562316728\n",
            "train loss:0.00222695200794674\n",
            "train loss:0.004675951848975803\n",
            "train loss:0.00617260333921788\n",
            "train loss:0.015224175635122978\n",
            "train loss:0.010421712530942779\n",
            "train loss:0.00022250109967070144\n",
            "train loss:0.018017514520516104\n",
            "train loss:0.016308830839757357\n",
            "train loss:0.007988525396358892\n",
            "train loss:0.0006606084288153118\n",
            "train loss:0.004669204049707634\n",
            "train loss:0.0004349489624865817\n",
            "train loss:0.0021648704814587715\n",
            "train loss:0.0035783455488952016\n",
            "train loss:0.00505691707384791\n",
            "train loss:0.0008191393199522727\n",
            "train loss:0.004983298273361196\n",
            "train loss:0.0803876902898688\n",
            "train loss:0.0013079188634526739\n",
            "train loss:0.0038850962852967036\n",
            "train loss:0.02889153564941025\n",
            "train loss:0.003760593252734582\n",
            "train loss:0.003446923726352365\n",
            "train loss:0.004085143775041638\n",
            "train loss:0.006358661942941824\n",
            "train loss:0.002868564319893399\n",
            "train loss:0.003081302669604669\n",
            "train loss:0.001116455884398932\n",
            "train loss:0.0013909494836102558\n",
            "train loss:0.006920230800209319\n",
            "train loss:0.004811236688650618\n",
            "train loss:0.021441692138444296\n",
            "train loss:0.017470905129517048\n",
            "train loss:0.0011126407721513583\n",
            "train loss:0.0047239038420931806\n",
            "train loss:0.0016180932070134946\n",
            "train loss:0.002020701228891492\n",
            "train loss:0.0041417419790123425\n",
            "train loss:0.007003080840746112\n",
            "train loss:0.004881828668196104\n",
            "train loss:0.003330156892874247\n",
            "train loss:0.000651548090241242\n",
            "train loss:0.021223339517541132\n",
            "train loss:0.0020452104750635753\n",
            "train loss:0.0009478894673999451\n",
            "train loss:0.003489300822302074\n",
            "train loss:0.06454468391078144\n",
            "train loss:0.0005442903676310677\n",
            "train loss:0.0018272796181620999\n",
            "train loss:0.005672092753856287\n",
            "train loss:0.00373251005296875\n",
            "train loss:0.018915226665053346\n",
            "train loss:0.0022175276881761788\n",
            "train loss:0.00872379924256861\n",
            "train loss:0.00723397162652886\n",
            "train loss:0.00011147713892755263\n",
            "train loss:0.006033996945796599\n",
            "train loss:0.0008907989387923157\n",
            "train loss:0.001529934976129743\n",
            "train loss:0.010132845795352818\n",
            "train loss:0.0024319389332707695\n",
            "train loss:0.0018114594851471244\n",
            "train loss:0.016914988543900916\n",
            "train loss:0.0013427072683051067\n",
            "train loss:0.002142309834623159\n",
            "train loss:0.005429290893623779\n",
            "train loss:0.002227460666453008\n",
            "train loss:0.012724075345358767\n",
            "train loss:0.0004363865790688778\n",
            "train loss:0.011935540121003336\n",
            "train loss:0.0001856062347196169\n",
            "train loss:0.001746289564092372\n",
            "train loss:0.0002953954974708824\n",
            "train loss:0.007407004533719535\n",
            "train loss:0.0032586723347253544\n",
            "train loss:0.002924615097161247\n",
            "train loss:0.0060548618864677385\n",
            "train loss:0.0007673488544896061\n",
            "train loss:0.0075813238868261855\n",
            "train loss:0.007509439540960302\n",
            "train loss:0.0038367735138137445\n",
            "train loss:0.004792138175422841\n",
            "train loss:0.0002742504287996702\n",
            "train loss:0.0026184362325948948\n",
            "train loss:0.0018542237095856254\n",
            "train loss:0.0006908995039375239\n",
            "train loss:0.00501133248563358\n",
            "train loss:0.0011749246925837294\n",
            "train loss:0.0029300047079241233\n",
            "train loss:0.0009777860564186463\n",
            "train loss:0.0004487558184758799\n",
            "train loss:0.002440539594196402\n",
            "train loss:0.004595355000571052\n",
            "train loss:0.021427783556317158\n",
            "train loss:0.006210038848363999\n",
            "train loss:0.000691523374182315\n",
            "train loss:0.0023664409003200824\n",
            "train loss:0.001215152777971138\n",
            "train loss:0.009694481530704614\n",
            "train loss:0.0018710835350743723\n",
            "train loss:0.0025735968836913055\n",
            "train loss:0.007551185032651105\n",
            "train loss:0.003811091169080054\n",
            "train loss:0.036360607012331646\n",
            "train loss:0.001855460000753332\n",
            "train loss:0.001284562749599511\n",
            "train loss:0.018005719747934537\n",
            "train loss:0.0046955997862931555\n",
            "train loss:0.008614684644664795\n",
            "train loss:0.005437132474708907\n",
            "train loss:0.017076177222560673\n",
            "train loss:0.003356653323500568\n",
            "train loss:0.009541061818377841\n",
            "train loss:0.006391574657030682\n",
            "train loss:0.002674030870690477\n",
            "train loss:0.0014775212812240324\n",
            "train loss:0.007340646783103556\n",
            "train loss:0.00043904617863123395\n",
            "train loss:0.001545220098107085\n",
            "train loss:0.0006131939282732044\n",
            "train loss:0.004788029491761809\n",
            "train loss:0.0003077589550910818\n",
            "train loss:0.0017788595776087987\n",
            "train loss:0.01855460396721387\n",
            "train loss:0.0007161782888325322\n",
            "train loss:0.00028343181507913445\n",
            "train loss:0.003774905525786407\n",
            "train loss:0.007204407253028238\n",
            "train loss:0.015902263124795167\n",
            "train loss:0.000793140006143728\n",
            "train loss:0.017789178162862317\n",
            "train loss:0.06730870977699835\n",
            "train loss:0.004177729789061933\n",
            "train loss:0.003669200250381266\n",
            "train loss:0.007184174852278612\n",
            "train loss:0.005819077038567036\n",
            "train loss:0.0006365097834269705\n",
            "train loss:0.004938158451533822\n",
            "train loss:0.003638535586296519\n",
            "train loss:0.001233290141191684\n",
            "train loss:0.005727898452606305\n",
            "train loss:0.08952789297511789\n",
            "train loss:0.014905059160199843\n",
            "train loss:0.001793053946794619\n",
            "train loss:0.009612283244670592\n",
            "train loss:0.013572377637236661\n",
            "train loss:0.0025672604927475117\n",
            "train loss:0.00042893125862863616\n",
            "train loss:0.003274035164477598\n",
            "train loss:0.0023589408954610993\n",
            "train loss:0.0035741263810923894\n",
            "train loss:0.04455706139085904\n",
            "train loss:0.006931968228209364\n",
            "train loss:0.0041930236103090305\n",
            "train loss:0.0019150304719624137\n",
            "train loss:0.0005353593186506724\n",
            "train loss:0.009840158713187934\n",
            "train loss:0.004516986535831177\n",
            "train loss:0.007666417719163916\n",
            "train loss:0.005561649159536875\n",
            "train loss:0.0035709195642795693\n",
            "train loss:0.00787111664772813\n",
            "train loss:0.00013568855858411835\n",
            "train loss:0.001246062982804894\n",
            "train loss:0.0021597059243318823\n",
            "train loss:0.0071561115932824906\n",
            "train loss:0.006822513399633225\n",
            "train loss:0.0008133891979160662\n",
            "train loss:0.009336719554090496\n",
            "train loss:0.030248252938577712\n",
            "train loss:0.002668883682587634\n",
            "train loss:0.00025418692715234117\n",
            "train loss:0.004652848256694325\n",
            "train loss:0.011375654236837127\n",
            "train loss:0.0017174564318991835\n",
            "train loss:8.19151486085752e-05\n",
            "train loss:0.000706261653893189\n",
            "train loss:0.0006859604779395197\n",
            "train loss:0.0030090328941239385\n",
            "train loss:0.0005040908350376299\n",
            "train loss:0.01101833675688551\n",
            "train loss:0.0025937115167880315\n",
            "train loss:0.005954153333316917\n",
            "train loss:0.0013384244480705773\n",
            "train loss:0.006542301401753391\n",
            "train loss:0.01030619224943123\n",
            "train loss:0.003330393891403321\n",
            "train loss:0.007872635202526563\n",
            "train loss:0.0005139496521851425\n",
            "train loss:0.0015452749083810166\n",
            "train loss:0.006410237734286658\n",
            "train loss:0.001087881981749974\n",
            "train loss:0.0005468323147452136\n",
            "train loss:0.01434666259111509\n",
            "train loss:0.0014020862269207666\n",
            "train loss:0.004015958677790633\n",
            "train loss:0.00019998855942957998\n",
            "train loss:0.014029970269405308\n",
            "train loss:0.01676015879419378\n",
            "train loss:0.005649719094561054\n",
            "train loss:0.005342990520853253\n",
            "train loss:0.006195308246352622\n",
            "train loss:0.0034058315251298352\n",
            "train loss:0.002191040112414817\n",
            "train loss:0.008219142586749287\n",
            "train loss:0.004912376232001102\n",
            "train loss:0.004667526638345729\n",
            "train loss:0.0006903037686514697\n",
            "train loss:0.003199680772078654\n",
            "train loss:0.0024818049498988486\n",
            "train loss:0.019323865232085288\n",
            "train loss:0.00032170877346825275\n",
            "train loss:0.011384872554241825\n",
            "=== epoch:14, train acc:0.997, test acc:0.993 ===\n",
            "train loss:0.0038940457064384343\n",
            "train loss:0.0002671805289368069\n",
            "train loss:0.004012618747678121\n",
            "train loss:0.004356658259150979\n",
            "train loss:0.0017484123158633786\n",
            "train loss:0.0003304153628756473\n",
            "train loss:0.002621760895322162\n",
            "train loss:0.0026173370092621375\n",
            "train loss:0.001143917846989639\n",
            "train loss:0.0005176571223013569\n",
            "train loss:0.0012374192953971028\n",
            "train loss:0.0008011013968917798\n",
            "train loss:0.0029798575569226094\n",
            "train loss:0.02135746978353533\n",
            "train loss:0.0050288557093796805\n",
            "train loss:0.0027834450369971986\n",
            "train loss:0.0009403778210552041\n",
            "train loss:0.0038053541635414433\n",
            "train loss:0.00167973146810635\n",
            "train loss:0.0018037292260658087\n",
            "train loss:0.00099288395468443\n",
            "train loss:0.006146212533818752\n",
            "train loss:0.002333699276712721\n",
            "train loss:0.001137420272371604\n",
            "train loss:0.011249233049849237\n",
            "train loss:0.0014615758373298017\n",
            "train loss:0.002004498198142099\n",
            "train loss:0.0007434434942730287\n",
            "train loss:0.0038751121197759535\n",
            "train loss:0.0004950699526313038\n",
            "train loss:0.012084693835216494\n",
            "train loss:0.0011990477320182643\n",
            "train loss:0.001399077780568026\n",
            "train loss:0.015735776315414077\n",
            "train loss:0.006144679460434946\n",
            "train loss:0.00439808820135537\n",
            "train loss:0.0008196010156098864\n",
            "train loss:0.0017348542892034896\n",
            "train loss:0.0069633623019736725\n",
            "train loss:0.0013836325412450862\n",
            "train loss:0.004375473188744383\n",
            "train loss:0.001529657953542611\n",
            "train loss:0.0023768601324642936\n",
            "train loss:0.0035425697136306144\n",
            "train loss:0.0008200033961727096\n",
            "train loss:0.0025706786491474167\n",
            "train loss:0.00896530078983584\n",
            "train loss:0.008420526822159836\n",
            "train loss:0.0020383645920292255\n",
            "train loss:0.002791052378276411\n",
            "train loss:0.0016002267938803607\n",
            "train loss:0.005701973901713159\n",
            "train loss:0.003079730832975966\n",
            "train loss:0.005650696288885076\n",
            "train loss:0.0027643799906634093\n",
            "train loss:0.0016566050044935956\n",
            "train loss:0.004014313920577059\n",
            "train loss:0.00023989512382976722\n",
            "train loss:0.0001556651458326417\n",
            "train loss:0.00028822255233987054\n",
            "train loss:0.0006658824488043142\n",
            "train loss:0.00046220144075123507\n",
            "train loss:0.0013055015557456983\n",
            "train loss:0.00023463592764366183\n",
            "train loss:0.00035001105459810886\n",
            "train loss:0.0016363149700650377\n",
            "train loss:0.0020279786453338763\n",
            "train loss:0.0025981137083584765\n",
            "train loss:0.0026710196311711025\n",
            "train loss:0.00362066050367554\n",
            "train loss:0.005212518085245146\n",
            "train loss:0.004921715800949134\n",
            "train loss:0.0007743516901385996\n",
            "train loss:0.0029397348887400926\n",
            "train loss:0.0004440844502275449\n",
            "train loss:0.006598029222199243\n",
            "train loss:0.0012656688309558761\n",
            "train loss:0.00020479164294452158\n",
            "train loss:0.0005368348958736987\n",
            "train loss:0.0002956319609775236\n",
            "train loss:0.0025506323025180156\n",
            "train loss:0.0009089117916889301\n",
            "train loss:0.0009065245737982363\n",
            "train loss:0.006346521206695919\n",
            "train loss:0.0014712875326938688\n",
            "train loss:0.002499128656401948\n",
            "train loss:0.0029530615145226145\n",
            "train loss:0.0026118143314062393\n",
            "train loss:0.00912856527192963\n",
            "train loss:0.0004515731153831184\n",
            "train loss:0.001335819009650369\n",
            "train loss:0.004963556599586291\n",
            "train loss:0.0021775496609061015\n",
            "train loss:0.0013783367817772755\n",
            "train loss:0.0007158487271515851\n",
            "train loss:0.007553597816490037\n",
            "train loss:0.0011221423354099373\n",
            "train loss:0.0007436810083013942\n",
            "train loss:0.0015304860483811005\n",
            "train loss:0.0002755363076320454\n",
            "train loss:0.0005891357000150332\n",
            "train loss:0.006756894331111228\n",
            "train loss:0.010882872077264683\n",
            "train loss:0.008297147493268006\n",
            "train loss:0.00036564991402493225\n",
            "train loss:0.014796012768431675\n",
            "train loss:0.0005312780449572745\n",
            "train loss:0.0024677818220897956\n",
            "train loss:0.0072820925919394605\n",
            "train loss:0.0006032539707061827\n",
            "train loss:0.0012959874838429477\n",
            "train loss:0.05939593976210517\n",
            "train loss:0.007816157770321564\n",
            "train loss:0.002325892112869267\n",
            "train loss:0.0003850066060697762\n",
            "train loss:0.010037869595877774\n",
            "train loss:0.06911451981215416\n",
            "train loss:0.047583248898995005\n",
            "train loss:0.001402907113313431\n",
            "train loss:0.006667613321378846\n",
            "train loss:0.0026467397532884355\n",
            "train loss:0.0024475078302151846\n",
            "train loss:0.015691543278945418\n",
            "train loss:0.0022124757339067537\n",
            "train loss:0.006160422514277741\n",
            "train loss:0.0019416596707850936\n",
            "train loss:0.006986764295660345\n",
            "train loss:0.0023312812382355647\n",
            "train loss:0.007498496319075665\n",
            "train loss:0.009007929856544245\n",
            "train loss:0.0011203150819788235\n",
            "train loss:0.0014498017952227847\n",
            "train loss:0.0009346997873406065\n",
            "train loss:0.001968111368511932\n",
            "train loss:0.0028884367559918155\n",
            "train loss:0.002663362184542427\n",
            "train loss:0.001710459730350177\n",
            "train loss:0.0012299429674794268\n",
            "train loss:0.008353024030178093\n",
            "train loss:0.0006084964676854263\n",
            "train loss:0.0011606445660932662\n",
            "train loss:0.015721348096616586\n",
            "train loss:0.0032612728428077376\n",
            "train loss:0.00018813749291897924\n",
            "train loss:0.0029769720584452686\n",
            "train loss:0.002465011821802878\n",
            "train loss:0.0023663677658131775\n",
            "train loss:0.002626872818576402\n",
            "train loss:0.006167409619787192\n",
            "train loss:0.014268818047020966\n",
            "train loss:0.0007418417890658413\n",
            "train loss:0.0031626463181060093\n",
            "train loss:0.0039067121349260145\n",
            "train loss:0.0006771274125455017\n",
            "train loss:0.003748459228245041\n",
            "train loss:0.0011278030672713152\n",
            "train loss:0.005654121074713171\n",
            "train loss:0.011374149824409954\n",
            "train loss:0.0020273600430884124\n",
            "train loss:0.0011575736334877244\n",
            "train loss:0.001531475070504218\n",
            "train loss:0.0016224660291516719\n",
            "train loss:0.004046529398754757\n",
            "train loss:0.008789986727163046\n",
            "train loss:0.0062531422838261784\n",
            "train loss:0.0022016040147639624\n",
            "train loss:0.018517530622043844\n",
            "train loss:0.0004829184472160219\n",
            "train loss:0.027284625722280326\n",
            "train loss:0.002136323434901468\n",
            "train loss:0.0015484942914191632\n",
            "train loss:0.0040824653877855575\n",
            "train loss:0.002329623347956999\n",
            "train loss:0.0022674784264578806\n",
            "train loss:0.009090028086230505\n",
            "train loss:0.006324202233192371\n",
            "train loss:0.0025034186637835996\n",
            "train loss:0.0007985957630116633\n",
            "train loss:0.0015330889169748619\n",
            "train loss:0.0015044118435907487\n",
            "train loss:0.00313022514147442\n",
            "train loss:0.055135240028795655\n",
            "train loss:0.0016570159034893484\n",
            "train loss:0.0037533253484056516\n",
            "train loss:0.0021519878981331223\n",
            "train loss:0.0013314355660547367\n",
            "train loss:0.004401601524226128\n",
            "train loss:0.009625629968560864\n",
            "train loss:0.0016028857986144767\n",
            "train loss:0.006418259470068277\n",
            "train loss:0.0036955723095389403\n",
            "train loss:0.049052899860662566\n",
            "train loss:0.01994039823875278\n",
            "train loss:0.0008191896939692668\n",
            "train loss:0.004169887130865119\n",
            "train loss:0.0009123503467584144\n",
            "train loss:0.0007901984197094\n",
            "train loss:0.002198467422055373\n",
            "train loss:0.0037075448040566105\n",
            "train loss:0.0010802527073880287\n",
            "train loss:0.0011807159406573271\n",
            "train loss:0.008027482141475254\n",
            "train loss:0.002772547542458433\n",
            "train loss:0.0007077885313381384\n",
            "train loss:0.002668526083748758\n",
            "train loss:0.0015557920792147104\n",
            "train loss:0.011549145397409621\n",
            "train loss:0.00562566027299732\n",
            "train loss:0.004794406385870898\n",
            "train loss:0.004473174928321923\n",
            "train loss:0.0009960428113711802\n",
            "train loss:0.0034751971020942594\n",
            "train loss:0.014015627793776013\n",
            "train loss:0.001480148597075951\n",
            "train loss:0.0015618702353034683\n",
            "train loss:0.00860215845450087\n",
            "train loss:0.011894041688841677\n",
            "train loss:0.0018554286118543494\n",
            "train loss:0.027246756606191087\n",
            "train loss:0.0008444871239771116\n",
            "train loss:0.003497688885307875\n",
            "train loss:0.01708191515812573\n",
            "train loss:0.002231408116770792\n",
            "train loss:0.0020999010212675866\n",
            "train loss:0.00014412860498732758\n",
            "train loss:0.014121076469892729\n",
            "train loss:0.005082091987155399\n",
            "train loss:0.0021242814654937082\n",
            "train loss:0.005666729854939577\n",
            "train loss:0.0014102045185703004\n",
            "train loss:0.002958491949232881\n",
            "train loss:0.002872891326663494\n",
            "train loss:0.0025834731817185584\n",
            "train loss:0.0018827953465021731\n",
            "train loss:0.0023135245552643865\n",
            "train loss:0.000601811015631616\n",
            "train loss:0.003813623664155741\n",
            "train loss:0.0004342988254662751\n",
            "train loss:0.0002172763459053222\n",
            "train loss:0.002361057591771711\n",
            "train loss:0.007871758219299483\n",
            "train loss:0.001260965503107118\n",
            "train loss:0.003930859128177618\n",
            "train loss:0.0009753633565273867\n",
            "train loss:0.0009945541974095244\n",
            "train loss:0.007595574482786274\n",
            "train loss:0.004559321515181573\n",
            "train loss:0.001455710823853525\n",
            "train loss:0.0017193163426771824\n",
            "train loss:0.001279559938386966\n",
            "train loss:0.00030971415891887605\n",
            "train loss:0.002698078291739669\n",
            "train loss:0.009997118947958118\n",
            "train loss:0.03089570458338762\n",
            "train loss:0.011283624557943605\n",
            "train loss:0.0003833277626010583\n",
            "train loss:0.0009907132727151506\n",
            "train loss:0.002847859200715794\n",
            "train loss:0.0020419806197863742\n",
            "train loss:0.0020615861593545836\n",
            "train loss:0.003178840587523028\n",
            "train loss:0.000908095903054781\n",
            "train loss:0.000464814427881763\n",
            "train loss:0.0011824921680349666\n",
            "train loss:0.0019745052973154094\n",
            "train loss:0.0063146617716013645\n",
            "train loss:0.0008238154864853882\n",
            "train loss:0.00117318134367838\n",
            "train loss:0.002107408623733007\n",
            "train loss:0.00547110086394871\n",
            "train loss:0.0007768419190468008\n",
            "train loss:0.0032879002889395696\n",
            "train loss:0.000497193741218239\n",
            "train loss:0.0002032661138560423\n",
            "train loss:0.0016530509751755704\n",
            "train loss:0.0008151791701601169\n",
            "train loss:0.00713329557304906\n",
            "train loss:0.0017446894626924198\n",
            "train loss:0.003476946477021653\n",
            "train loss:0.0019954074959493513\n",
            "train loss:0.0012758272764788394\n",
            "train loss:0.0008597825261851904\n",
            "train loss:0.004215474391824233\n",
            "train loss:0.002929145841029418\n",
            "train loss:0.016225534463117898\n",
            "train loss:0.0018129014152716068\n",
            "train loss:0.0015474883462615263\n",
            "train loss:0.009086471488431759\n",
            "train loss:0.0012226135865870294\n",
            "train loss:0.0007713384084828397\n",
            "train loss:0.002242089728464926\n",
            "train loss:0.001990274730272264\n",
            "train loss:0.003578789047498028\n",
            "train loss:0.0033390628885421082\n",
            "train loss:0.003034978429379312\n",
            "train loss:0.0005127748179857619\n",
            "train loss:0.0010859053969628893\n",
            "train loss:0.015084155360172545\n",
            "train loss:0.0006898658648099852\n",
            "train loss:0.005061224128306348\n",
            "train loss:0.013199255250253871\n",
            "train loss:0.0015177143651316448\n",
            "train loss:0.0029762888136849806\n",
            "train loss:0.0004402586974987584\n",
            "train loss:0.0023137941846558805\n",
            "train loss:0.0030140067024079565\n",
            "train loss:0.01147697550505292\n",
            "train loss:0.00022056833425133378\n",
            "train loss:0.0003081165759040423\n",
            "train loss:0.002101765420290031\n",
            "train loss:0.001984034510227552\n",
            "train loss:0.0029050569751735774\n",
            "train loss:0.0069972826983241525\n",
            "train loss:0.009053775575949531\n",
            "train loss:0.0035947052420763777\n",
            "train loss:0.0009760968515146085\n",
            "train loss:0.0012251722067506852\n",
            "train loss:0.0023652402258769025\n",
            "train loss:0.0005369467301531729\n",
            "train loss:0.003907472437280258\n",
            "train loss:0.014086212434624015\n",
            "train loss:0.0033148345626119557\n",
            "train loss:0.002232540459900114\n",
            "train loss:0.0023555314612349752\n",
            "train loss:0.0018797612769309569\n",
            "train loss:0.0003727763910505529\n",
            "train loss:0.010589833833884415\n",
            "train loss:0.0001773175810494739\n",
            "train loss:0.011539731024516464\n",
            "train loss:0.0005919397908838847\n",
            "train loss:0.0009629951370489393\n",
            "train loss:0.0004750725109245271\n",
            "train loss:0.0006859704696795622\n",
            "train loss:0.00043909186482000236\n",
            "train loss:0.032351112051274236\n",
            "train loss:0.001340631935685262\n",
            "train loss:0.000523332862510826\n",
            "train loss:0.002362548583542316\n",
            "train loss:0.0011651725488966453\n",
            "train loss:0.0014083419678034307\n",
            "train loss:0.0009894813715204634\n",
            "train loss:0.0476884456905179\n",
            "train loss:0.0014820352604649908\n",
            "train loss:0.003476605311551127\n",
            "train loss:0.0008157910761551978\n",
            "train loss:0.003272785009614892\n",
            "train loss:0.0038834635537652105\n",
            "train loss:0.003286621339854888\n",
            "train loss:0.003522473961340731\n",
            "train loss:0.0013399263454837126\n",
            "train loss:0.0025755602058584346\n",
            "train loss:0.005770397050259306\n",
            "train loss:0.0017274789370603184\n",
            "train loss:0.0007677763152904205\n",
            "train loss:0.0003116940323233284\n",
            "train loss:0.004333742298664991\n",
            "train loss:0.030986084693394412\n",
            "train loss:0.0016814064067029488\n",
            "train loss:0.0030554941078163567\n",
            "train loss:0.00445156854250638\n",
            "train loss:0.0018845140248246498\n",
            "train loss:0.0012131255847256208\n",
            "train loss:0.0023235066477705433\n",
            "train loss:0.01899058310265319\n",
            "train loss:0.0007710625082167242\n",
            "train loss:0.01673224159984028\n",
            "train loss:0.006034759221114603\n",
            "train loss:0.0033510866426281222\n",
            "train loss:0.002941970003097262\n",
            "train loss:0.007706373927362274\n",
            "train loss:0.0043521703365231425\n",
            "train loss:0.003419217447656464\n",
            "train loss:0.009956124512747874\n",
            "train loss:0.015891212386636683\n",
            "train loss:0.0025764248184908787\n",
            "train loss:0.0005142844690027136\n",
            "train loss:0.01124418694759599\n",
            "train loss:0.005445809660467772\n",
            "train loss:0.004378162703770848\n",
            "train loss:0.00913958252722204\n",
            "train loss:0.0006437889929241043\n",
            "train loss:0.009351441335229537\n",
            "train loss:0.0013801888823892986\n",
            "train loss:0.0004609878691440791\n",
            "train loss:0.0002637363952691355\n",
            "train loss:0.007958400974165046\n",
            "train loss:0.0010385890500831441\n",
            "train loss:0.0030136277434811153\n",
            "train loss:0.003833582195217017\n",
            "train loss:0.00040990529961694254\n",
            "train loss:0.0013723663512566137\n",
            "train loss:0.0028639156291693736\n",
            "train loss:0.0009035893193171346\n",
            "train loss:0.0007799585939364523\n",
            "train loss:0.0008283208148276729\n",
            "train loss:0.00026542878175128383\n",
            "train loss:0.0014183658540812124\n",
            "train loss:0.005285376497938798\n",
            "train loss:0.0012660686616534468\n",
            "train loss:0.0021623365854202842\n",
            "train loss:0.004762393493302813\n",
            "train loss:0.002193518964331129\n",
            "train loss:0.0007287122695486645\n",
            "train loss:0.0026718714810596528\n",
            "train loss:0.002469622011371948\n",
            "train loss:0.013119896388584372\n",
            "train loss:0.00019912260179765745\n",
            "train loss:0.0009763900553689882\n",
            "train loss:0.0012153217919990316\n",
            "train loss:0.002362808202281457\n",
            "train loss:0.027315675582393603\n",
            "train loss:0.0011706581625202713\n",
            "train loss:0.002262766266213489\n",
            "train loss:0.008333429415652325\n",
            "train loss:0.0021355361088491605\n",
            "train loss:0.008767887660901651\n",
            "train loss:0.003624838561994638\n",
            "train loss:0.001007278215704483\n",
            "train loss:0.010994078018636683\n",
            "train loss:0.021920361607993287\n",
            "train loss:0.0015436443009404735\n",
            "train loss:0.0017501427463587232\n",
            "train loss:0.006920645711557337\n",
            "train loss:0.0010202560607538364\n",
            "train loss:0.0005163733451978874\n",
            "train loss:0.00039368052081340573\n",
            "train loss:0.003456598355505422\n",
            "train loss:0.0035414724152899755\n",
            "train loss:0.000828128484200509\n",
            "train loss:0.004938836826501395\n",
            "train loss:0.0037459316351595166\n",
            "train loss:0.0015555415136425266\n",
            "train loss:0.0008973889721340536\n",
            "train loss:0.014033934163464944\n",
            "train loss:0.001096892988381275\n",
            "train loss:0.0033971145499410967\n",
            "train loss:0.00010089556249438386\n",
            "train loss:0.0020699287109060644\n",
            "train loss:0.0006378727897047242\n",
            "train loss:0.00018223585395026637\n",
            "train loss:0.002482738480900762\n",
            "train loss:0.004276101112927717\n",
            "train loss:0.00020330652715411132\n",
            "train loss:0.0004751636378486086\n",
            "train loss:0.007821592917978116\n",
            "train loss:0.0005631158291810761\n",
            "train loss:0.0006916886001738592\n",
            "train loss:0.008093004429186725\n",
            "train loss:0.007098128319536645\n",
            "train loss:0.002974793938410986\n",
            "train loss:0.0006088062675392628\n",
            "train loss:0.018344983321261107\n",
            "train loss:0.00109551536254276\n",
            "train loss:0.0005332153170432659\n",
            "train loss:0.0018752775662211232\n",
            "train loss:0.013798888502773672\n",
            "train loss:0.004213777975960496\n",
            "train loss:0.0016328350001160988\n",
            "train loss:0.0032582558513630272\n",
            "train loss:0.00035898838802483224\n",
            "train loss:0.003302451514889349\n",
            "train loss:0.00048688430576227556\n",
            "train loss:0.004852643796633027\n",
            "train loss:0.000738264435113762\n",
            "train loss:0.0011924639706584123\n",
            "train loss:0.001120181014305369\n",
            "train loss:0.0006411427387843713\n",
            "train loss:0.005115792293455174\n",
            "train loss:0.012228380156979073\n",
            "train loss:0.00012473990196245466\n",
            "train loss:0.006868906395081738\n",
            "train loss:0.0015879234287505925\n",
            "train loss:0.0009068622929121127\n",
            "train loss:0.000167902484026297\n",
            "train loss:0.00048318411152872804\n",
            "train loss:0.006908935813877399\n",
            "train loss:0.027395586697390884\n",
            "train loss:0.003989978812160733\n",
            "train loss:0.0017188798130279592\n",
            "train loss:0.001847455597683135\n",
            "train loss:0.023738697892030088\n",
            "train loss:0.0032885817666902777\n",
            "train loss:0.00542510281163473\n",
            "train loss:0.002077373771607796\n",
            "train loss:0.003091340643459955\n",
            "train loss:0.007545472383071371\n",
            "train loss:0.0004308841125000353\n",
            "train loss:0.001524368499547567\n",
            "train loss:0.0020406687079550286\n",
            "train loss:0.0022755171334450514\n",
            "train loss:0.00046110545548389123\n",
            "train loss:0.0036865805723014216\n",
            "train loss:0.0010400730031812667\n",
            "train loss:0.0009379800415405914\n",
            "train loss:0.002805311590791209\n",
            "train loss:0.0009626254966742223\n",
            "train loss:0.0011390867868778236\n",
            "train loss:0.0004349055197580393\n",
            "train loss:0.006320963957013464\n",
            "train loss:0.0002696485695225735\n",
            "train loss:0.0011111839086815254\n",
            "train loss:2.896373326822864e-05\n",
            "train loss:0.0003001870357236015\n",
            "train loss:0.003195993515107133\n",
            "train loss:0.0008095372071628801\n",
            "train loss:0.0015601624884640183\n",
            "train loss:0.00026371579132155806\n",
            "train loss:0.002503490439270994\n",
            "train loss:0.005413917079825862\n",
            "train loss:0.00015288656806406996\n",
            "train loss:0.0002759245087175661\n",
            "train loss:0.006447750979272396\n",
            "train loss:0.00013125688574048977\n",
            "train loss:0.0040969799656309395\n",
            "train loss:0.0014133556230277152\n",
            "train loss:0.0003612333899762475\n",
            "train loss:0.012039725375513255\n",
            "train loss:0.0002965680421091082\n",
            "train loss:0.0028503740412544522\n",
            "train loss:0.0012186097937609938\n",
            "train loss:0.00032005525584043377\n",
            "train loss:0.001763645413284652\n",
            "train loss:0.0005388915929757239\n",
            "train loss:0.0023792416323257667\n",
            "train loss:0.001944172854608393\n",
            "train loss:0.0011056281686462077\n",
            "train loss:0.003969379856487518\n",
            "train loss:0.004679008476231415\n",
            "train loss:0.004940624352044781\n",
            "train loss:0.0009389823539662165\n",
            "train loss:0.002189685886340431\n",
            "train loss:0.0009748855077911919\n",
            "train loss:0.0004505364428555638\n",
            "train loss:0.0036844414314838015\n",
            "train loss:0.011897550387843438\n",
            "train loss:0.0035612664423115593\n",
            "train loss:0.00010110868424721569\n",
            "train loss:0.004340317416302515\n",
            "train loss:0.00555872580148542\n",
            "train loss:0.0006443058047777615\n",
            "train loss:0.0017965351748077487\n",
            "train loss:0.0055983039562226685\n",
            "train loss:0.0018818861858728927\n",
            "train loss:0.0006994117521977629\n",
            "train loss:0.0009182923082839059\n",
            "train loss:0.000536146542944009\n",
            "train loss:0.0013929447079488828\n",
            "train loss:0.0011033901153209358\n",
            "train loss:0.0006910996742775621\n",
            "train loss:0.0015340640471984484\n",
            "train loss:0.0008906324674320544\n",
            "train loss:0.0006963953763576596\n",
            "train loss:0.00044123973969606824\n",
            "train loss:0.00045209411330870015\n",
            "train loss:0.005355475139265995\n",
            "train loss:0.0003462884637276358\n",
            "train loss:0.002385100830008022\n",
            "train loss:0.0016892342931052807\n",
            "train loss:0.0007816363949388746\n",
            "train loss:0.0008506754672249997\n",
            "train loss:0.0005818837750625858\n",
            "train loss:0.0007386817523243297\n",
            "train loss:0.0017542520612309235\n",
            "train loss:0.001481922677042299\n",
            "train loss:0.00599531395848852\n",
            "train loss:0.0025072024554312856\n",
            "train loss:0.0013899702128209515\n",
            "train loss:0.003029296316641778\n",
            "train loss:0.0003149741588402627\n",
            "train loss:0.00139287002381378\n",
            "train loss:0.002156822958822038\n",
            "train loss:0.02882774658515972\n",
            "train loss:0.0014672929435314633\n",
            "train loss:0.0021629995229442496\n",
            "train loss:0.0006601410983226606\n",
            "train loss:0.00042745006678364286\n",
            "train loss:0.0002994481100290088\n",
            "train loss:0.002040767012335197\n",
            "train loss:0.003622334681375148\n",
            "train loss:0.0015688932890181645\n",
            "train loss:0.00074365719374818\n",
            "train loss:8.88761642813311e-05\n",
            "train loss:0.015631769553972982\n",
            "train loss:0.0008210387764425747\n",
            "train loss:0.00038881590074720337\n",
            "train loss:0.0006814290360316458\n",
            "train loss:0.0008388110293966734\n",
            "train loss:0.0005039534591104727\n",
            "train loss:0.08780673291181836\n",
            "train loss:0.002028621538201647\n",
            "train loss:0.0025454903164889163\n",
            "train loss:0.0008862613181167308\n",
            "train loss:0.003414986452889818\n",
            "train loss:0.10526496291286376\n",
            "train loss:0.0013793193181509044\n",
            "train loss:0.0017081145958092287\n",
            "train loss:0.0011521059615440478\n",
            "train loss:0.0032464487290104725\n",
            "train loss:0.002206361259262346\n",
            "train loss:0.005496337191019763\n",
            "=== epoch:15, train acc:0.999, test acc:0.986 ===\n",
            "train loss:0.00528370852045315\n",
            "train loss:0.0013939736685637575\n",
            "train loss:0.006754466569931409\n",
            "train loss:0.003099167604376352\n",
            "train loss:0.0014898021067647638\n",
            "train loss:0.004900838580783314\n",
            "train loss:0.0007512121241251358\n",
            "train loss:0.008882914852205772\n",
            "train loss:0.0005243625040235592\n",
            "train loss:0.0010684895076715462\n",
            "train loss:0.00028228943462985144\n",
            "train loss:0.008898377507566741\n",
            "train loss:0.00018682885438559327\n",
            "train loss:0.0009424849853642582\n",
            "train loss:0.0018682420061150676\n",
            "train loss:0.0011040635697229704\n",
            "train loss:0.0020584065716693265\n",
            "train loss:0.0091110362321329\n",
            "train loss:0.0004294087056444455\n",
            "train loss:0.0032024879139841657\n",
            "train loss:0.007311348989479148\n",
            "train loss:0.0025974977728102627\n",
            "train loss:0.0025382221029070164\n",
            "train loss:0.0005001037589849524\n",
            "train loss:0.0018606532815072859\n",
            "train loss:0.00036135512643745073\n",
            "train loss:0.00027427147916099737\n",
            "train loss:0.000384477606261719\n",
            "train loss:0.0007618475389261953\n",
            "train loss:0.004436788333370804\n",
            "train loss:0.0013176197281857258\n",
            "train loss:0.0010404827923952645\n",
            "train loss:0.00298154768486333\n",
            "train loss:0.009489008520856778\n",
            "train loss:0.032055244902146146\n",
            "train loss:0.0004977012809799018\n",
            "train loss:0.0024057263477112833\n",
            "train loss:0.00162769083478114\n",
            "train loss:0.0026078695591594436\n",
            "train loss:8.857120214308111e-05\n",
            "train loss:0.0046648316097877614\n",
            "train loss:0.00020865076490289927\n",
            "train loss:0.004341934469093992\n",
            "train loss:0.0001024623682069836\n",
            "train loss:0.0006504436601273886\n",
            "train loss:0.003997984834141704\n",
            "train loss:0.0011198227551659984\n",
            "train loss:0.000585343584917913\n",
            "train loss:0.008533782310246533\n",
            "train loss:0.007564791636955499\n",
            "train loss:0.004128818929771072\n",
            "train loss:0.00023827025752021084\n",
            "train loss:0.0009958132472255579\n",
            "train loss:0.002476431162369402\n",
            "train loss:0.0003811024922647252\n",
            "train loss:0.0006694413804205402\n",
            "train loss:0.0015103383580612384\n",
            "train loss:0.0020213255525573302\n",
            "train loss:0.00035131872850229407\n",
            "train loss:0.0006200057998102899\n",
            "train loss:0.0037313855261392375\n",
            "train loss:0.0010071422483967168\n",
            "train loss:0.0010709043433750189\n",
            "train loss:0.0012559077632539914\n",
            "train loss:0.008224735427365121\n",
            "train loss:0.0025095781091237428\n",
            "train loss:0.00018863749265041148\n",
            "train loss:0.002633743875385902\n",
            "train loss:0.008492308471815042\n",
            "train loss:0.0013251828746857527\n",
            "train loss:0.003953789137630578\n",
            "train loss:0.010554975320586192\n",
            "train loss:0.002586772459812549\n",
            "train loss:0.001442927420234989\n",
            "train loss:0.0027406706867317775\n",
            "train loss:0.0017181871375505308\n",
            "train loss:0.0009346701665104624\n",
            "train loss:0.0002585501902460648\n",
            "train loss:0.0007245445489115243\n",
            "train loss:0.0003971592547709258\n",
            "train loss:0.0014006872509796683\n",
            "train loss:0.008121226677417943\n",
            "train loss:0.001682055734251124\n",
            "train loss:0.0002142852849242755\n",
            "train loss:0.0012944475586669558\n",
            "train loss:0.001951245521327961\n",
            "train loss:0.0049322785245904935\n",
            "train loss:0.0010418889851550833\n",
            "train loss:0.00023704152977854293\n",
            "train loss:0.008710328230420283\n",
            "train loss:0.00039978768833576325\n",
            "train loss:0.0017996570522359084\n",
            "train loss:0.0024307932484905186\n",
            "train loss:0.0008634430824317177\n",
            "train loss:0.0050061749287379975\n",
            "train loss:0.00036425115876046116\n",
            "train loss:0.011270751198646711\n",
            "train loss:0.00025558779351103904\n",
            "train loss:0.0016778221296054766\n",
            "train loss:0.01695875976924944\n",
            "train loss:0.006202926503242228\n",
            "train loss:0.0015143643951386753\n",
            "train loss:0.0029060529753747793\n",
            "train loss:0.0009404925281808532\n",
            "train loss:0.0018129998945644612\n",
            "train loss:0.0003521490621964003\n",
            "train loss:0.0051345857469713785\n",
            "train loss:0.0002898740173096577\n",
            "train loss:0.008167438167995063\n",
            "train loss:0.0014169744908481868\n",
            "train loss:0.0018046204332053581\n",
            "train loss:0.0008429716298772111\n",
            "train loss:0.00926043498380952\n",
            "train loss:0.002019018560332151\n",
            "train loss:0.002030672917070002\n",
            "train loss:0.00026704079313650305\n",
            "train loss:7.241498582863939e-05\n",
            "train loss:0.0007979374436172059\n",
            "train loss:0.00787935538638171\n",
            "train loss:0.0011122161252490298\n",
            "train loss:0.00014087368106392327\n",
            "train loss:0.004594677948122301\n",
            "train loss:0.00016962835054864427\n",
            "train loss:0.0023774466393169155\n",
            "train loss:0.001974061256704911\n",
            "train loss:0.0007832818073237056\n",
            "train loss:0.0004982899413241224\n",
            "train loss:0.0007143444999927018\n",
            "train loss:0.003008422883072993\n",
            "train loss:0.0009557355893634655\n",
            "train loss:0.0009978270861432132\n",
            "train loss:0.004327753211109125\n",
            "train loss:0.0008632450083707642\n",
            "train loss:0.003250825024140676\n",
            "train loss:0.00059422033081971\n",
            "train loss:0.0007410514596846062\n",
            "train loss:0.0012892466104177254\n",
            "train loss:0.0027229207106816266\n",
            "train loss:0.0003370817490753377\n",
            "train loss:0.010200306421859168\n",
            "train loss:0.004006592800769182\n",
            "train loss:0.0008083688874986974\n",
            "train loss:0.00012166837784269313\n",
            "train loss:0.0009205151152458267\n",
            "train loss:0.0022194858175336673\n",
            "train loss:0.0077001150353016665\n",
            "train loss:0.0011894798986683487\n",
            "train loss:0.0005444203354929863\n",
            "train loss:0.0069052658985668414\n",
            "train loss:0.0021738240718859343\n",
            "train loss:0.0005493809900380883\n",
            "train loss:0.003384219123243884\n",
            "train loss:0.0034166749295701957\n",
            "train loss:0.001100248117508381\n",
            "train loss:0.002166657565908929\n",
            "train loss:0.004253547970244242\n",
            "train loss:0.0010352584406798074\n",
            "train loss:0.0014799485668742188\n",
            "train loss:0.0002964886590460512\n",
            "train loss:0.0014661974159680183\n",
            "train loss:0.0024782720508497087\n",
            "train loss:0.0016528514061285415\n",
            "train loss:0.00042788303278947415\n",
            "train loss:0.004457623485927123\n",
            "train loss:0.0005674071288624401\n",
            "train loss:0.004305793432995847\n",
            "train loss:0.0018458311781467177\n",
            "train loss:0.001750908364125944\n",
            "train loss:0.0010761229210685538\n",
            "train loss:0.005168686948429928\n",
            "train loss:0.0009843736038733406\n",
            "train loss:0.00891990310544982\n",
            "train loss:0.0025288928890088934\n",
            "train loss:0.0015142469043788402\n",
            "train loss:0.00032989115189440186\n",
            "train loss:0.00617818805701096\n",
            "train loss:0.0004370643430906632\n",
            "train loss:0.0006404698432086116\n",
            "train loss:0.000459878873627301\n",
            "train loss:0.0008920619741312332\n",
            "train loss:0.0008360853539808043\n",
            "train loss:0.0013790439427064805\n",
            "train loss:0.0007806377228106667\n",
            "train loss:0.0006805488391993093\n",
            "train loss:0.0002925931622251749\n",
            "train loss:0.002380732778652584\n",
            "train loss:0.000314713327735519\n",
            "train loss:0.0022066171565324863\n",
            "train loss:0.0006723934202105105\n",
            "train loss:0.013221165299440316\n",
            "train loss:0.0026245579201783185\n",
            "train loss:0.0009187741525360491\n",
            "train loss:0.00029590481829886486\n",
            "train loss:0.001011650888222526\n",
            "train loss:0.0024684464210199043\n",
            "train loss:0.029342854925015018\n",
            "train loss:0.0047613339069915135\n",
            "train loss:0.0006776961994965432\n",
            "train loss:0.004290572102442469\n",
            "train loss:0.0006757186621325168\n",
            "train loss:0.0020898815116903355\n",
            "train loss:0.002509545819134554\n",
            "train loss:0.0033807671923061127\n",
            "train loss:0.0007457542301587406\n",
            "train loss:0.0013606403294978183\n",
            "train loss:0.0027305083775546095\n",
            "train loss:0.00020977650365327689\n",
            "train loss:0.0010203361498437652\n",
            "train loss:0.0005213678885883189\n",
            "train loss:0.00011848581021374968\n",
            "train loss:0.0006931302941068773\n",
            "train loss:0.0009032932277292403\n",
            "train loss:0.009235223432949281\n",
            "train loss:0.002493041073847774\n",
            "train loss:0.0002661626569143399\n",
            "train loss:0.0036033673944984705\n",
            "train loss:0.025076572279751925\n",
            "train loss:0.0021129008615346717\n",
            "train loss:0.00029005035788327963\n",
            "train loss:0.0010602758357876403\n",
            "train loss:0.005017617929407001\n",
            "train loss:0.0012776911126623877\n",
            "train loss:0.0027179299699530523\n",
            "train loss:0.002779956575752785\n",
            "train loss:0.0014261020756000126\n",
            "train loss:0.0014815972231154919\n",
            "train loss:0.0018793636027571352\n",
            "train loss:0.002583915926248338\n",
            "train loss:0.0006432390021263045\n",
            "train loss:0.0037062045827928646\n",
            "train loss:0.0007495772606050555\n",
            "train loss:0.006035138978511484\n",
            "train loss:0.0010441115768113761\n",
            "train loss:0.007920880988859383\n",
            "train loss:0.000665767260561626\n",
            "train loss:0.0001114736913600069\n",
            "train loss:0.0025619590930962754\n",
            "train loss:0.0020091412595258725\n",
            "train loss:0.00020046188866250464\n",
            "train loss:0.004608033219215488\n",
            "train loss:0.0016348326046816222\n",
            "train loss:0.003684371971869612\n",
            "train loss:0.0004762550438291038\n",
            "train loss:0.0005935566491860526\n",
            "train loss:0.00109265013086308\n",
            "train loss:0.0014081692556124582\n",
            "train loss:0.0011493080569962416\n",
            "train loss:0.005262992466722953\n",
            "train loss:0.004557638687455459\n",
            "train loss:0.0013553618347401412\n",
            "train loss:0.0052424465749730045\n",
            "train loss:0.000695762606771053\n",
            "train loss:0.010095250069726938\n",
            "train loss:0.002011515666125435\n",
            "train loss:0.0010941332355200303\n",
            "train loss:0.005377346179833289\n",
            "train loss:0.00046640080049499376\n",
            "train loss:0.005692333869946848\n",
            "train loss:0.0022962053709943008\n",
            "train loss:0.0010278774976725789\n",
            "train loss:0.000962528792667328\n",
            "train loss:0.000779590996965333\n",
            "train loss:0.0005245248863850788\n",
            "train loss:0.008228223798509723\n",
            "train loss:0.004746531362162123\n",
            "train loss:0.0033892258683297714\n",
            "train loss:0.00041574772159642346\n",
            "train loss:0.007661015322615034\n",
            "train loss:0.00041797317258715114\n",
            "train loss:0.004888190106658154\n",
            "train loss:0.00764269661103355\n",
            "train loss:0.012882381245635021\n",
            "train loss:0.0004935729481385998\n",
            "train loss:0.0005009268410555331\n",
            "train loss:0.00533656981547072\n",
            "train loss:0.010175566737122738\n",
            "train loss:0.0005411921681319249\n",
            "train loss:0.0045875936050799706\n",
            "train loss:0.0060487230698991175\n",
            "train loss:0.003342927033967087\n",
            "train loss:0.004450518834730386\n",
            "train loss:0.004040263421389411\n",
            "train loss:0.0045669952315909\n",
            "train loss:0.0032247467288894255\n",
            "train loss:0.005898417241259723\n",
            "train loss:0.0010012420611558168\n",
            "train loss:0.0015643253683217339\n",
            "train loss:0.0007168658034577501\n",
            "train loss:0.00045149185896269664\n",
            "train loss:0.0021125519423120546\n",
            "train loss:0.0008915554763235914\n",
            "train loss:0.004460427708114249\n",
            "train loss:0.008793504874280343\n",
            "train loss:0.0012977061083365548\n",
            "train loss:0.0010063386981315867\n",
            "train loss:0.0010019399851905104\n",
            "train loss:0.001657114142940035\n",
            "train loss:0.00022111839460334248\n",
            "train loss:0.002549624382368427\n",
            "train loss:0.0026743808305845023\n",
            "train loss:0.0046442781471421855\n",
            "train loss:0.0017195943499945195\n",
            "train loss:0.0030013923932362373\n",
            "train loss:0.0043561536510534375\n",
            "train loss:0.0002559379924986716\n",
            "train loss:0.0005042115916516825\n",
            "train loss:0.003865867315282086\n",
            "train loss:0.00010493699129371568\n",
            "train loss:5.4593788187585386e-05\n",
            "train loss:0.0002690979828627609\n",
            "train loss:0.0004170184318591414\n",
            "train loss:0.002109376851708232\n",
            "train loss:0.0002902961683504591\n",
            "train loss:0.013010581709157724\n",
            "train loss:0.0590344019483207\n",
            "train loss:0.003000083610427138\n",
            "train loss:6.085580724031348e-05\n",
            "train loss:0.0015963031097394986\n",
            "train loss:0.0011370375884335484\n",
            "train loss:0.005309089417171349\n",
            "train loss:0.003640317603163706\n",
            "train loss:0.004910820040887774\n",
            "train loss:0.0027469517227411305\n",
            "train loss:0.005660549080265173\n",
            "train loss:0.002493432673592545\n",
            "train loss:0.005262114503256705\n",
            "train loss:0.0025503497868088988\n",
            "train loss:0.0011416190208142385\n",
            "train loss:0.0037132975069523073\n",
            "train loss:0.001254524052849517\n",
            "train loss:0.022246631043753917\n",
            "train loss:0.006523317284449672\n",
            "train loss:0.0028788996260447368\n",
            "train loss:0.006709726094667599\n",
            "train loss:0.00020544592501487758\n",
            "train loss:0.00391423112377836\n",
            "train loss:0.0004876663890204061\n",
            "train loss:0.0034112850433727776\n",
            "train loss:0.0005754980460627869\n",
            "train loss:0.000436577904584344\n",
            "train loss:0.00024168275607960057\n",
            "train loss:9.72814007177374e-05\n",
            "train loss:0.003975712250573401\n",
            "train loss:0.0009318129783765499\n",
            "train loss:0.011551400385850164\n",
            "train loss:0.0027790627897990965\n",
            "train loss:0.0012213507468444601\n",
            "train loss:0.004308927297220157\n",
            "train loss:0.00023890363737432915\n",
            "train loss:0.0019336418034950652\n",
            "train loss:0.0014522187915498028\n",
            "train loss:0.0014354696052884329\n",
            "train loss:0.0027019855737574006\n",
            "train loss:0.0002204742618591186\n",
            "train loss:0.0011641461499059236\n",
            "train loss:0.0056349716328873\n",
            "train loss:0.0022281815735147557\n",
            "train loss:0.00014513854464876457\n",
            "train loss:0.03651989561141285\n",
            "train loss:0.0029302000558471797\n",
            "train loss:0.01166012167436589\n",
            "train loss:0.0012837808212037352\n",
            "train loss:0.0018549486659487518\n",
            "train loss:0.0015851393814226124\n",
            "train loss:0.004736113556051756\n",
            "train loss:0.0007197515667304577\n",
            "train loss:0.003988803744959995\n",
            "train loss:0.0006684269626953905\n",
            "train loss:0.0024552976269851907\n",
            "train loss:0.0009924406847778794\n",
            "train loss:0.0013741041623580984\n",
            "train loss:0.02076294494928395\n",
            "train loss:0.012624252261215819\n",
            "train loss:0.0023085715331652\n",
            "train loss:0.006816652161881232\n",
            "train loss:0.002531177000761722\n",
            "train loss:0.0005269658035806028\n",
            "train loss:0.0029805322327934427\n",
            "train loss:0.0010202301683610744\n",
            "train loss:0.008216769746959141\n",
            "train loss:0.004295258715056009\n",
            "train loss:0.004006583069730465\n",
            "train loss:0.00014753370072402458\n",
            "train loss:0.00034606153074845706\n",
            "train loss:0.00046404195935751313\n",
            "train loss:0.005749548495814565\n",
            "train loss:0.0013678341205572272\n",
            "train loss:0.005398466520385864\n",
            "train loss:0.005465938102431879\n",
            "train loss:0.002482910314026058\n",
            "train loss:0.0023899865534165203\n",
            "train loss:0.0013482622553786607\n",
            "train loss:0.0006827389728280247\n",
            "train loss:0.0032091610688883805\n",
            "train loss:0.0028515519091069893\n",
            "train loss:0.004024273454065886\n",
            "train loss:0.002680806220705838\n",
            "train loss:0.0011884666907092086\n",
            "train loss:0.005885636727258753\n",
            "train loss:0.027882325994398792\n",
            "train loss:0.001714042756763496\n",
            "train loss:0.0026747299429514273\n",
            "train loss:0.0006266048124200707\n",
            "train loss:0.0013215655054321293\n",
            "train loss:0.001972871646183481\n",
            "train loss:0.014863685577328018\n",
            "train loss:0.0010269021891667531\n",
            "train loss:0.0014923443271597783\n",
            "train loss:0.00853886970436355\n",
            "train loss:0.0018308607468780088\n",
            "train loss:0.0018646182424843052\n",
            "train loss:0.002559965983760941\n",
            "train loss:0.008174275505330487\n",
            "train loss:0.003967760302825334\n",
            "train loss:0.0036397347664551645\n",
            "train loss:0.0008056268422850467\n",
            "train loss:0.0027297518924529795\n",
            "train loss:0.00022304095950866263\n",
            "train loss:0.019431269566183178\n",
            "train loss:0.0007368923110561052\n",
            "train loss:0.004144331821332345\n",
            "train loss:0.001217449867366796\n",
            "train loss:0.0002533150652667751\n",
            "train loss:0.015076207928927292\n",
            "train loss:0.004432375141864941\n",
            "train loss:0.0019022846881024053\n",
            "train loss:0.0004622689900423554\n",
            "train loss:0.002601960260261665\n",
            "train loss:0.0011944505801352197\n",
            "train loss:0.003592056320351133\n",
            "train loss:0.002673571113420718\n",
            "train loss:0.003972170012481468\n",
            "train loss:0.0004418448404293429\n",
            "train loss:0.0013418430240540696\n",
            "train loss:0.0002492803165588437\n",
            "train loss:0.000890995385358691\n",
            "train loss:0.04308510436043131\n",
            "train loss:0.0012060286244630384\n",
            "train loss:0.002207027966357498\n",
            "train loss:0.0031396793213282325\n",
            "train loss:0.0026986259985343685\n",
            "train loss:0.001467893672870867\n",
            "train loss:0.001007384406488014\n",
            "train loss:0.00017954962842658072\n",
            "train loss:0.00026746597994845695\n",
            "train loss:0.006617190052254426\n",
            "train loss:0.0010110920531984265\n",
            "train loss:0.003402518309909867\n",
            "train loss:0.0007760043904715374\n",
            "train loss:0.0012261257699960875\n",
            "train loss:0.0003753639136217158\n",
            "train loss:0.00481827929620124\n",
            "train loss:0.0019394135482334893\n",
            "train loss:0.001132951518000368\n",
            "train loss:0.000938096605953797\n",
            "train loss:0.00027217113811194043\n",
            "train loss:0.0008408091878001107\n",
            "train loss:0.0011048594176429234\n",
            "train loss:0.004059620618693518\n",
            "train loss:0.0038694055292836285\n",
            "train loss:0.00386817946074063\n",
            "train loss:0.0003810976680212121\n",
            "train loss:0.004905752453922858\n",
            "train loss:0.004477960194811053\n",
            "train loss:0.002449360223175676\n",
            "train loss:0.004778356619023799\n",
            "train loss:0.0015136895729870336\n",
            "train loss:0.0005526389254766395\n",
            "train loss:0.0009631872398682987\n",
            "train loss:0.0003220092581877584\n",
            "train loss:0.009768638754034215\n",
            "train loss:0.0007115892329452569\n",
            "train loss:0.006901991691174387\n",
            "train loss:0.004605284749270674\n",
            "train loss:0.003428774298071363\n",
            "train loss:0.0010970360035156502\n",
            "train loss:0.005397742053295121\n",
            "train loss:0.007478208391009682\n",
            "train loss:0.0002904613306167889\n",
            "train loss:0.0002509323407346677\n",
            "train loss:0.0008712204870428966\n",
            "train loss:0.006161381722527126\n",
            "train loss:0.0002640862113818985\n",
            "train loss:0.0007131571659984708\n",
            "train loss:0.059198891249010094\n",
            "train loss:0.003998934005981609\n",
            "train loss:0.007501011319823758\n",
            "train loss:0.004020396686225686\n",
            "train loss:0.0019625150551325823\n",
            "train loss:0.004226737360544091\n",
            "train loss:0.00038019196514725123\n",
            "train loss:0.0024378675915666427\n",
            "train loss:0.0008505932435786445\n",
            "train loss:0.0006527199179869061\n",
            "train loss:0.0018092838345095815\n",
            "train loss:0.04719593333289076\n",
            "train loss:0.005423222662635864\n",
            "train loss:0.0024572212624395418\n",
            "train loss:0.0011459551581707154\n",
            "train loss:0.0009015755349602589\n",
            "train loss:0.005098976746024211\n",
            "train loss:0.0032303396446882655\n",
            "train loss:0.0001395354017535223\n",
            "train loss:0.003128442469443995\n",
            "train loss:0.0014213258800367145\n",
            "train loss:0.0025166041991425895\n",
            "train loss:0.005425867630373215\n",
            "train loss:0.0023013854022885492\n",
            "train loss:0.004407164772908026\n",
            "train loss:0.0006370929153227178\n",
            "train loss:0.00015237567995060169\n",
            "train loss:0.014123109881039103\n",
            "train loss:0.0002811823252976379\n",
            "train loss:0.0002866514075858757\n",
            "train loss:0.0016269723220238414\n",
            "train loss:0.0021134623657918777\n",
            "train loss:0.00021880625843068646\n",
            "train loss:0.00030075061172465316\n",
            "train loss:0.0035418997696947205\n",
            "train loss:0.0008490731347234426\n",
            "train loss:0.0005416369739856916\n",
            "train loss:0.0003068743253946277\n",
            "train loss:0.0003098177697558292\n",
            "train loss:0.00042517444127523267\n",
            "train loss:0.028301936924430896\n",
            "train loss:0.0035915262650524555\n",
            "train loss:0.005681131114733221\n",
            "train loss:0.000638436336669212\n",
            "train loss:0.0015541882021702863\n",
            "train loss:0.00012168227836303117\n",
            "train loss:0.0008360240294114332\n",
            "train loss:0.003200950113493921\n",
            "train loss:0.001637006128643481\n",
            "train loss:0.000690436788789152\n",
            "train loss:0.0028390091258626614\n",
            "train loss:0.0025222257586736564\n",
            "train loss:0.005468726182722536\n",
            "train loss:0.01634127067632014\n",
            "train loss:0.004789242652539095\n",
            "train loss:0.0017345297073262298\n",
            "train loss:0.008137497693686258\n",
            "train loss:0.0019719397339796837\n",
            "train loss:0.015340182129428061\n",
            "train loss:0.0020166020239887252\n",
            "train loss:0.0005832827732211803\n",
            "train loss:0.0021291912787012295\n",
            "train loss:0.004343307678293992\n",
            "train loss:0.0015315526977093099\n",
            "train loss:0.00017938752169289622\n",
            "train loss:0.0037476057927553707\n",
            "train loss:0.00665267966476821\n",
            "train loss:0.0066355058255328555\n",
            "train loss:0.00040077104473338796\n",
            "train loss:0.002277766866678728\n",
            "train loss:0.0015937898081990805\n",
            "train loss:0.002041117977956854\n",
            "train loss:0.0007413548811909506\n",
            "train loss:0.006242536396203687\n",
            "train loss:0.0040151743674971515\n",
            "train loss:0.005727045080185934\n",
            "train loss:0.006859709482070133\n",
            "train loss:0.005073586948250202\n",
            "train loss:0.0016384059689348324\n",
            "train loss:0.002561783125343127\n",
            "train loss:0.0015018343657685646\n",
            "train loss:0.0052028603798747455\n",
            "train loss:0.000702815774466901\n",
            "train loss:0.005143490958662932\n",
            "train loss:0.0020560278232341703\n",
            "train loss:0.002586672029012691\n",
            "train loss:0.0003413775619061677\n",
            "train loss:0.0005445850615867729\n",
            "train loss:0.00045212983043483484\n",
            "train loss:0.0015121235987981768\n",
            "train loss:0.002645566370436211\n",
            "train loss:0.0014793924831848918\n",
            "train loss:0.0008381203681578669\n",
            "train loss:0.003912944694314069\n",
            "train loss:0.016141630973367595\n",
            "train loss:0.0010967142756652375\n",
            "train loss:0.0022129973739125155\n",
            "train loss:0.001051765749981468\n",
            "train loss:0.00042969452944892144\n",
            "train loss:0.0007673240649907351\n",
            "train loss:0.0014769284699649601\n",
            "train loss:0.002786940338938875\n",
            "train loss:0.00041352588072827995\n",
            "train loss:0.0010980471489831424\n",
            "train loss:0.00398551108435969\n",
            "train loss:0.0006602587752443283\n",
            "train loss:0.02184162950698382\n",
            "train loss:0.0037384323771110723\n",
            "train loss:0.0004905313218954796\n",
            "train loss:0.001690417587557864\n",
            "train loss:0.0015169412656038238\n",
            "train loss:0.0025077390377268327\n",
            "train loss:0.00028589887463486126\n",
            "train loss:0.004115921299331863\n",
            "train loss:0.003562993959842956\n",
            "train loss:0.00041911138017176837\n",
            "=== epoch:16, train acc:0.998, test acc:0.989 ===\n",
            "train loss:0.0040957603123781\n",
            "train loss:0.002865557844005933\n",
            "train loss:0.0016768142887374242\n",
            "train loss:0.0003807247092251139\n",
            "train loss:0.002157060555672043\n",
            "train loss:0.004422872828202022\n",
            "train loss:0.0005896042907681612\n",
            "train loss:0.0005413504454780784\n",
            "train loss:0.00857141262225824\n",
            "train loss:0.0022723327797082075\n",
            "train loss:0.0046421600261541815\n",
            "train loss:0.03277892190461576\n",
            "train loss:0.002643666092228807\n",
            "train loss:0.0003975596033439657\n",
            "train loss:0.004510837010198647\n",
            "train loss:0.0015955754315136858\n",
            "train loss:0.007731688079910663\n",
            "train loss:0.0015737288248435758\n",
            "train loss:9.634072824065226e-05\n",
            "train loss:0.0010795523405011179\n",
            "train loss:0.00036750791435875623\n",
            "train loss:0.00040141115392670695\n",
            "train loss:0.0011240056351084773\n",
            "train loss:0.0012249793692149064\n",
            "train loss:0.0035134929798966014\n",
            "train loss:0.00020165527837586256\n",
            "train loss:2.1271713305737258e-05\n",
            "train loss:0.00347938548111818\n",
            "train loss:0.000988452266630633\n",
            "train loss:0.0010384708434712433\n",
            "train loss:0.0031750336879280494\n",
            "train loss:0.0022172006194713305\n",
            "train loss:0.001181743025791529\n",
            "train loss:0.0004900156426806222\n",
            "train loss:0.0005742362094919138\n",
            "train loss:0.0002288162794440381\n",
            "train loss:0.0009674723866946634\n",
            "train loss:0.0004220996820479867\n",
            "train loss:0.006063664305402258\n",
            "train loss:0.0023185394908531386\n",
            "train loss:0.001177394469666814\n",
            "train loss:0.00026508119808159856\n",
            "train loss:0.0016459090453645772\n",
            "train loss:0.0009561554563757865\n",
            "train loss:0.000607188700816526\n",
            "train loss:0.0032286169827792327\n",
            "train loss:0.0010146264677500857\n",
            "train loss:0.0017285192647060019\n",
            "train loss:0.007954966232847893\n",
            "train loss:0.00047998443060374914\n",
            "train loss:0.008237341072135895\n",
            "train loss:0.0010929150378501855\n",
            "train loss:2.9290670254233817e-05\n",
            "train loss:0.0015607221446522818\n",
            "train loss:0.0033728927226079697\n",
            "train loss:0.0021609393486357567\n",
            "train loss:0.0010667410357958949\n",
            "train loss:0.0038033739672599302\n",
            "train loss:0.0012920800991305353\n",
            "train loss:0.005690883851613719\n",
            "train loss:0.0010447260160030799\n",
            "train loss:0.0010096713893393348\n",
            "train loss:0.00021499210251669533\n",
            "train loss:0.00196964852415014\n",
            "train loss:0.0024158373313222085\n",
            "train loss:0.003932907763923802\n",
            "train loss:0.0021193700696210288\n",
            "train loss:0.0003751633919835671\n",
            "train loss:0.0020138074329580005\n",
            "train loss:0.0028576714694106974\n",
            "train loss:0.000910105182014547\n",
            "train loss:0.0013754720772288234\n",
            "train loss:0.0009231760021203196\n",
            "train loss:0.0006035162188002577\n",
            "train loss:0.002052349637382704\n",
            "train loss:0.0011732489060994492\n",
            "train loss:0.0012979914835596572\n",
            "train loss:0.0011252517197641752\n",
            "train loss:0.0037254311497807923\n",
            "train loss:0.0015509577771848238\n",
            "train loss:0.0014009575957092527\n",
            "train loss:0.004676984382944097\n",
            "train loss:0.001221219583219951\n",
            "train loss:0.0006091398116873352\n",
            "train loss:0.0013902321065215695\n",
            "train loss:0.0006467863479907458\n",
            "train loss:0.0016831251280137183\n",
            "train loss:0.009847555110848599\n",
            "train loss:0.0012317048895740244\n",
            "train loss:0.0011466074112899962\n",
            "train loss:0.0009764347305174572\n",
            "train loss:0.003747559187277421\n",
            "train loss:0.002408453018196841\n",
            "train loss:0.0015611355514720637\n",
            "train loss:0.0017883416070736157\n",
            "train loss:0.0013214438581554608\n",
            "train loss:0.0013477256189717403\n",
            "train loss:0.0011836845796282588\n",
            "train loss:0.0041195756874175225\n",
            "train loss:0.00012836026903183335\n",
            "train loss:0.0042390609307087065\n",
            "train loss:0.0007807306624542074\n",
            "train loss:0.0005164887350177469\n",
            "train loss:0.001499140454888598\n",
            "train loss:0.0017362919764310524\n",
            "train loss:1.9082550041054578e-05\n",
            "train loss:0.00025285148247588857\n",
            "train loss:0.0012456549033131653\n",
            "train loss:0.0009144096046743958\n",
            "train loss:0.0003219138166043315\n",
            "train loss:0.0009171734235479943\n",
            "train loss:0.0005452897856721033\n",
            "train loss:0.001968018738361955\n",
            "train loss:0.0010318036799437133\n",
            "train loss:0.0017031651251974236\n",
            "train loss:0.003031842633892233\n",
            "train loss:3.9872733378408234e-05\n",
            "train loss:0.0001237529895189823\n",
            "train loss:0.0002155708908575603\n",
            "train loss:0.00047030339609936917\n",
            "train loss:0.00019660648112455412\n",
            "train loss:0.00022272981922786292\n",
            "train loss:0.0025442854181285286\n",
            "train loss:0.0014740678457990596\n",
            "train loss:0.004127866548748066\n",
            "train loss:0.0009042369016690675\n",
            "train loss:0.0010963231390929366\n",
            "train loss:0.0007034816296771342\n",
            "train loss:0.00027496807527395374\n",
            "train loss:0.0023430174193321083\n",
            "train loss:4.048386745834063e-05\n",
            "train loss:0.0007710395804993233\n",
            "train loss:0.0002528236720272409\n",
            "train loss:0.005910619621189372\n",
            "train loss:0.00030182893159178274\n",
            "train loss:0.0012564707663855928\n",
            "train loss:0.0005796481717779789\n",
            "train loss:0.0022277446803038365\n",
            "train loss:0.005228399298696804\n",
            "train loss:0.0019280646016358435\n",
            "train loss:0.001341607393631085\n",
            "train loss:0.004774396761382166\n",
            "train loss:0.0010707135363318618\n",
            "train loss:0.0021507430168183615\n",
            "train loss:0.0006914684610291864\n",
            "train loss:0.0018317440854459426\n",
            "train loss:0.0008263504105514126\n",
            "train loss:0.0013392591362167206\n",
            "train loss:0.0001508726268564532\n",
            "train loss:0.0009304040658045559\n",
            "train loss:0.0015702258296414044\n",
            "train loss:0.0024963292980838647\n",
            "train loss:0.002390225836453547\n",
            "train loss:0.017305201770837737\n",
            "train loss:7.093776493843021e-05\n",
            "train loss:0.0009848280885640538\n",
            "train loss:0.0002792413733087362\n",
            "train loss:0.0007598089602681639\n",
            "train loss:0.006998896066359866\n",
            "train loss:0.0015304924152518098\n",
            "train loss:5.1802443570221904e-05\n",
            "train loss:0.00032860732868533483\n",
            "train loss:0.0004572738702224936\n",
            "train loss:0.004342784814168388\n",
            "train loss:0.00047586808932395134\n",
            "train loss:9.493531515730264e-05\n",
            "train loss:0.002647277648430543\n",
            "train loss:0.013038848877911036\n",
            "train loss:0.0010649101529667494\n",
            "train loss:0.0009524726735761893\n",
            "train loss:0.002014737580537388\n",
            "train loss:0.00022380876277969662\n",
            "train loss:0.0006981235603084521\n",
            "train loss:0.0010027486144164488\n",
            "train loss:0.008143798754232594\n",
            "train loss:0.0008369326395756094\n",
            "train loss:0.000533728010641977\n",
            "train loss:0.0002467973316873699\n",
            "train loss:0.0003588686232671405\n",
            "train loss:0.004164854911921023\n",
            "train loss:0.002747585533798839\n",
            "train loss:0.003481774657270867\n",
            "train loss:0.002946656281388721\n",
            "train loss:0.0022263199431798862\n",
            "train loss:0.001334561568640309\n",
            "train loss:0.0014060395044845977\n",
            "train loss:0.0014961940031132243\n",
            "train loss:0.008540229165408357\n",
            "train loss:0.002205429423114839\n",
            "train loss:0.0003590468540137234\n",
            "train loss:0.0013876903870964133\n",
            "train loss:0.0018679056577211189\n",
            "train loss:0.00036312906576375855\n",
            "train loss:0.0039572940997317195\n",
            "train loss:0.0006509147085225334\n",
            "train loss:0.00028242300198868945\n",
            "train loss:0.0010723731602008174\n",
            "train loss:0.005267395284338013\n",
            "train loss:0.00032512241783802997\n",
            "train loss:0.002052861165536868\n",
            "train loss:0.0007289298281131199\n",
            "train loss:0.0027053899745328185\n",
            "train loss:0.0011913939022059842\n",
            "train loss:9.85571402149293e-05\n",
            "train loss:0.0005880255566864428\n",
            "train loss:0.0006611901823703546\n",
            "train loss:0.0010356010686499116\n",
            "train loss:0.00011254705443047176\n",
            "train loss:0.0010678276950099232\n",
            "train loss:0.004796497575992475\n",
            "train loss:0.00022479830250750162\n",
            "train loss:0.008317104245249528\n",
            "train loss:0.002774170994849979\n",
            "train loss:4.1835693068111096e-05\n",
            "train loss:0.0037985163776058234\n",
            "train loss:0.007004329489987022\n",
            "train loss:0.003072350394691259\n",
            "train loss:0.002885533688710521\n",
            "train loss:0.0002163877718374949\n",
            "train loss:0.002348319131711406\n",
            "train loss:0.0010692094888741185\n",
            "train loss:0.0005944393046487888\n",
            "train loss:0.0016975472431231056\n",
            "train loss:0.009370965030508516\n",
            "train loss:0.0005335946172677502\n",
            "train loss:0.0025214810319059396\n",
            "train loss:0.0021318670271973203\n",
            "train loss:7.362240800393268e-05\n",
            "train loss:0.0009052457226725748\n",
            "train loss:0.00018297374498066094\n",
            "train loss:0.0018243181167159831\n",
            "train loss:0.0005911088674422926\n",
            "train loss:0.0032274776586993853\n",
            "train loss:0.0007943553733707687\n",
            "train loss:4.322872104155765e-05\n",
            "train loss:2.651135942699784e-05\n",
            "train loss:0.0007714259387335967\n",
            "train loss:0.008371082217485845\n",
            "train loss:0.004530766579381455\n",
            "train loss:0.002059400586218283\n",
            "train loss:0.0009387351929399682\n",
            "train loss:0.0037090001819574466\n",
            "train loss:0.012015676990785656\n",
            "train loss:0.0390642690142618\n",
            "train loss:0.0012937795465593708\n",
            "train loss:0.00023372570454525049\n",
            "train loss:0.001051629623142522\n",
            "train loss:0.0007280076174868188\n",
            "train loss:0.0008649493580681528\n",
            "train loss:0.0007917691940445749\n",
            "train loss:0.0025860960279684136\n",
            "train loss:0.003579771782154085\n",
            "train loss:0.007880836020687242\n",
            "train loss:0.00015958441030965254\n",
            "train loss:0.0015324455445182641\n",
            "train loss:0.00132059479908297\n",
            "train loss:0.0029863568584931888\n",
            "train loss:0.004939226095416676\n",
            "train loss:0.0010696267584183895\n",
            "train loss:0.0005270572388848793\n",
            "train loss:0.0022129146760520263\n",
            "train loss:0.001340056016670809\n",
            "train loss:0.0011713892063169795\n",
            "train loss:0.0003784770835762346\n",
            "train loss:0.0013713027968738018\n",
            "train loss:0.01388265765989465\n",
            "train loss:0.0055053876602850806\n",
            "train loss:0.0013225548918574018\n",
            "train loss:0.0023748924005197146\n",
            "train loss:0.00024363380284946778\n",
            "train loss:0.003042607559253849\n",
            "train loss:0.00013611439887395175\n",
            "train loss:0.0011746185750369136\n",
            "train loss:0.0072558855926496664\n",
            "train loss:0.07340106675408614\n",
            "train loss:0.00046624841368998347\n",
            "train loss:0.006053259010077552\n",
            "train loss:6.241875672489378e-05\n",
            "train loss:0.012861664543043548\n",
            "train loss:0.002186435462257389\n",
            "train loss:0.001989242158411306\n",
            "train loss:0.004219980325036733\n",
            "train loss:0.00036923439429692895\n",
            "train loss:0.002554016158283724\n",
            "train loss:0.002610462050444784\n",
            "train loss:0.0005898534838703789\n",
            "train loss:0.003024240650961508\n",
            "train loss:0.004930999433762892\n",
            "train loss:0.003733246663332226\n",
            "train loss:0.003939294191485696\n",
            "train loss:0.004368244811148585\n",
            "train loss:0.0035551338767054893\n",
            "train loss:0.0012559101295538783\n",
            "train loss:0.0027397517332346925\n",
            "train loss:0.00014161979841021937\n",
            "train loss:0.0005285738468942905\n",
            "train loss:0.002679064508181297\n",
            "train loss:0.00014883648747175785\n",
            "train loss:0.0007200997818752213\n",
            "train loss:0.004353755404333467\n",
            "train loss:0.0013526350137164742\n",
            "train loss:0.0022552784131924437\n",
            "train loss:0.0012388979120436321\n",
            "train loss:0.0026462045955009178\n",
            "train loss:0.004122042865795547\n",
            "train loss:0.0011662478384509506\n",
            "train loss:0.00045451870738333566\n",
            "train loss:0.005756460112242329\n",
            "train loss:0.002496235322818999\n",
            "train loss:0.00040734998203727083\n",
            "train loss:0.007699359037257413\n",
            "train loss:0.0004310559186475532\n",
            "train loss:0.00013230130305740508\n",
            "train loss:0.0003672906090651431\n",
            "train loss:0.00030082708645557077\n",
            "train loss:0.00632255106256055\n",
            "train loss:0.005189585556360946\n",
            "train loss:0.0008301652996760778\n",
            "train loss:0.0003610159946599147\n",
            "train loss:0.015274704934797418\n",
            "train loss:0.0003391526145606949\n",
            "train loss:0.0007891942789220487\n",
            "train loss:0.0036263692088930348\n",
            "train loss:0.0009805170894227192\n",
            "train loss:0.001613917469898935\n",
            "train loss:0.006787881192184803\n",
            "train loss:0.0056912326506398546\n",
            "train loss:0.0003960678214552906\n",
            "train loss:0.013525202212630393\n",
            "train loss:0.0020999890953077977\n",
            "train loss:0.006254927689480558\n",
            "train loss:0.002000424696303862\n",
            "train loss:0.00128654214868661\n",
            "train loss:0.005895428317527346\n",
            "train loss:0.0016668946278249152\n",
            "train loss:0.0036140986395737135\n",
            "train loss:0.00023422627811008515\n",
            "train loss:0.004010261806982354\n",
            "train loss:0.0005787742167133919\n",
            "train loss:0.003777038974939749\n",
            "train loss:0.005955098768139422\n",
            "train loss:0.0013883556414178442\n",
            "train loss:0.0020504264400756545\n",
            "train loss:0.000498145152470086\n",
            "train loss:0.004237302532282129\n",
            "train loss:0.0007205780508149188\n",
            "train loss:0.007025361102237292\n",
            "train loss:0.0012875630079943936\n",
            "train loss:0.0017505426752467438\n",
            "train loss:0.029469536260058167\n",
            "train loss:0.0011616540419660966\n",
            "train loss:0.0002440715510369872\n",
            "train loss:0.0016227542912329541\n",
            "train loss:0.0011334052904779677\n",
            "train loss:0.0022695603037489083\n",
            "train loss:0.0014379130023785098\n",
            "train loss:6.642970244905462e-05\n",
            "train loss:0.003148562548244963\n",
            "train loss:0.00019054543712587968\n",
            "train loss:0.0014515349551498902\n",
            "train loss:0.0030691292807020825\n",
            "train loss:0.0021410235600759333\n",
            "train loss:0.0008502136462124114\n",
            "train loss:0.005867611740004863\n",
            "train loss:0.0035110478588377854\n",
            "train loss:0.00021723919602172016\n",
            "train loss:0.003955939822781935\n",
            "train loss:0.0002896171656247969\n",
            "train loss:0.0019768112005069498\n",
            "train loss:0.0019186542457805102\n",
            "train loss:0.0007945725831561894\n",
            "train loss:0.0003454540592770237\n",
            "train loss:0.0018125952969608194\n",
            "train loss:0.0009103025715991905\n",
            "train loss:0.0027857056720490404\n",
            "train loss:0.005359112639925219\n",
            "train loss:0.0012435182149638292\n",
            "train loss:0.00021137178793592085\n",
            "train loss:0.001001024039948592\n",
            "train loss:0.000458571373940006\n",
            "train loss:0.00040736480398635233\n",
            "train loss:0.0022921509776372344\n",
            "train loss:0.008173131262987833\n",
            "train loss:0.0014301299145452505\n",
            "train loss:0.007708898076696663\n",
            "train loss:0.0019933874019805228\n",
            "train loss:0.0033167293024544274\n",
            "train loss:6.679761607945212e-05\n",
            "train loss:0.0012472816819702876\n",
            "train loss:0.0005667672264768611\n",
            "train loss:0.001630767844546302\n",
            "train loss:0.003221254027354738\n",
            "train loss:0.0013599455485337167\n",
            "train loss:0.0007040381636034482\n",
            "train loss:0.060546539874952766\n",
            "train loss:0.0043733625471858014\n",
            "train loss:0.0009284529743690323\n",
            "train loss:0.003440361309242409\n",
            "train loss:0.0016707740187400628\n",
            "train loss:0.005006534920788489\n",
            "train loss:0.00548662477186451\n",
            "train loss:0.0017736251400580789\n",
            "train loss:0.003372021359983614\n",
            "train loss:0.00039172876823909353\n",
            "train loss:0.00642934017697448\n",
            "train loss:0.005763949171738587\n",
            "train loss:0.008123557974271538\n",
            "train loss:0.00720144642841085\n",
            "train loss:0.0006807338546478622\n",
            "train loss:0.00041504478349172933\n",
            "train loss:0.0014020391491406797\n",
            "train loss:0.01865218735466328\n",
            "train loss:0.005713395876494761\n",
            "train loss:0.002630911230061697\n",
            "train loss:0.0001136081461787473\n",
            "train loss:0.012039021791536613\n",
            "train loss:0.0003412096817559025\n",
            "train loss:0.00125007662332199\n",
            "train loss:0.00239612229748201\n",
            "train loss:0.005168101781624373\n",
            "train loss:0.0007235256466869412\n",
            "train loss:0.0018534620691873832\n",
            "train loss:0.0027901045991927925\n",
            "train loss:0.003944534781404753\n",
            "train loss:0.0014684260267562904\n",
            "train loss:0.0034064294506316968\n",
            "train loss:0.00020357657005796642\n",
            "train loss:0.001338440785418209\n",
            "train loss:0.002794206408637587\n",
            "train loss:0.0016919432974834717\n",
            "train loss:0.0015916504450084739\n",
            "train loss:0.05229670715387067\n",
            "train loss:0.0024937443529532833\n",
            "train loss:0.0020528238202663683\n",
            "train loss:0.003782815700117045\n",
            "train loss:0.005593075899774904\n",
            "train loss:0.00010517095000128503\n",
            "train loss:0.0015340003972375363\n",
            "train loss:0.0002276844646707462\n",
            "train loss:0.003969162904113717\n",
            "train loss:0.003460199208012569\n",
            "train loss:0.004428477380522812\n",
            "train loss:0.001862620698801598\n",
            "train loss:0.0005301973093876929\n",
            "train loss:0.0006279251485883579\n",
            "train loss:0.004020492408626531\n",
            "train loss:0.004832887967821895\n",
            "train loss:4.790197665176685e-05\n",
            "train loss:0.007343268165143862\n",
            "train loss:0.0011605280009459112\n",
            "train loss:0.0018815063984725813\n",
            "train loss:0.001681265980603805\n",
            "train loss:0.000809804811044922\n",
            "train loss:0.00188480720784949\n",
            "train loss:0.001204105007120275\n",
            "train loss:0.00027761856408891136\n",
            "train loss:0.00024575299002622145\n",
            "train loss:0.006467228281122716\n",
            "train loss:0.0008098064884356795\n",
            "train loss:0.004838387083049691\n",
            "train loss:0.00028116036947963474\n",
            "train loss:0.0010343293673990308\n",
            "train loss:0.00043365978124349674\n",
            "train loss:0.006673073971700348\n",
            "train loss:0.00033016674909467725\n",
            "train loss:0.0009525626726980146\n",
            "train loss:0.0009630378654241503\n",
            "train loss:0.0023014905074022537\n",
            "train loss:0.00014622587953898224\n",
            "train loss:0.0014594446639837025\n",
            "train loss:0.0008853517651418183\n",
            "train loss:0.0003713016322148675\n",
            "train loss:0.020758001216337515\n",
            "train loss:0.0011601199472342685\n",
            "train loss:0.002167359848295118\n",
            "train loss:0.0023155414637681627\n",
            "train loss:0.0018681776292920813\n",
            "train loss:9.28878202431255e-05\n",
            "train loss:0.0037947002017840047\n",
            "train loss:0.0027880887024527325\n",
            "train loss:0.0020022102443067557\n",
            "train loss:0.003870519777833598\n",
            "train loss:0.00037510786102161063\n",
            "train loss:0.0004064124415876266\n",
            "train loss:0.0038894798257886167\n",
            "train loss:0.0017518343782122906\n",
            "train loss:0.0008990430678255505\n",
            "train loss:0.002269404537581699\n",
            "train loss:0.0013732022356617605\n",
            "train loss:0.0065145657658131385\n",
            "train loss:0.0001308705906224825\n",
            "train loss:0.0013177513532951011\n",
            "train loss:0.0008403517860064118\n",
            "train loss:0.008895926370110593\n",
            "train loss:0.0013516813296155833\n",
            "train loss:0.0033330545673664726\n",
            "train loss:0.0011675671181645983\n",
            "train loss:0.0024540392949448054\n",
            "train loss:7.25200318371673e-05\n",
            "train loss:0.0036694631193306955\n",
            "train loss:0.002763109396129149\n",
            "train loss:0.018517956051287015\n",
            "train loss:0.0017004641232094004\n",
            "train loss:0.0011491354816006417\n",
            "train loss:0.0012749826147483451\n",
            "train loss:0.0019474561148859356\n",
            "train loss:0.0018066259039414845\n",
            "train loss:0.0062244378807604925\n",
            "train loss:0.0021845287775905772\n",
            "train loss:0.0033715373246181444\n",
            "train loss:0.0003846949584563276\n",
            "train loss:6.545019276071924e-05\n",
            "train loss:0.0014730667271885675\n",
            "train loss:0.00044181318028595006\n",
            "train loss:0.003886699363447101\n",
            "train loss:0.0002063567012710217\n",
            "train loss:0.005949774579494754\n",
            "train loss:0.0017864701391856511\n",
            "train loss:0.002132217350076174\n",
            "train loss:0.0017961656277449523\n",
            "train loss:0.0006500298368264651\n",
            "train loss:0.0009362294649192066\n",
            "train loss:0.00048410424112031275\n",
            "train loss:0.0013432404358185383\n",
            "train loss:0.0022818572418756887\n",
            "train loss:0.0004525252806007626\n",
            "train loss:0.0016147146817408642\n",
            "train loss:0.0011445348880944758\n",
            "train loss:0.033531739958336096\n",
            "train loss:0.0023557774168326416\n",
            "train loss:0.00013680635982817448\n",
            "train loss:0.0004807981203652542\n",
            "train loss:0.001984329423132066\n",
            "train loss:0.0014876016972545376\n",
            "train loss:0.0004178901935715039\n",
            "train loss:0.01983849463330159\n",
            "train loss:0.00039599658112454965\n",
            "train loss:0.010642708041323659\n",
            "train loss:0.001813649950307229\n",
            "train loss:0.008591236020679403\n",
            "train loss:0.0005798426436993579\n",
            "train loss:0.0002847173992518276\n",
            "train loss:0.0013485749184829945\n",
            "train loss:0.00336892517848584\n",
            "train loss:0.0053393920529721415\n",
            "train loss:0.001848571572902916\n",
            "train loss:0.0017303318241121692\n",
            "train loss:0.0011999271763576509\n",
            "train loss:0.011919384186999591\n",
            "train loss:0.001077565751324055\n",
            "train loss:0.0006588285479102071\n",
            "train loss:0.003545262749667478\n",
            "train loss:0.0002648830565213217\n",
            "train loss:0.0006756324521387124\n",
            "train loss:0.00069823988076721\n",
            "train loss:0.00010537857017511907\n",
            "train loss:0.018559207820198386\n",
            "train loss:0.003865092454380564\n",
            "train loss:0.00048066873475010187\n",
            "train loss:0.00046508880106054223\n",
            "train loss:0.001391929817761427\n",
            "train loss:0.002175895426293874\n",
            "train loss:0.00342951789566147\n",
            "train loss:0.00046803280044803225\n",
            "train loss:6.45905832360255e-05\n",
            "train loss:0.0043637329791604\n",
            "train loss:0.0017477642853299543\n",
            "train loss:0.0025102558399289687\n",
            "train loss:0.004908755880580092\n",
            "train loss:0.0006381889434978521\n",
            "train loss:0.0009621249088778\n",
            "train loss:0.0013206042983958262\n",
            "train loss:0.0009091806048120498\n",
            "train loss:0.001985236591793457\n",
            "train loss:0.0013791453909828464\n",
            "train loss:0.0024246541251504235\n",
            "train loss:0.021230756722909704\n",
            "train loss:0.008871877958312435\n",
            "train loss:0.0018310640166871975\n",
            "train loss:0.0029612893672132457\n",
            "train loss:0.0031037822099074137\n",
            "train loss:0.00017649902306855444\n",
            "train loss:0.002335134520771701\n",
            "train loss:0.0005422859851058587\n",
            "train loss:0.0005392284713372851\n",
            "train loss:0.0009257493014546521\n",
            "train loss:0.006478422628485235\n",
            "train loss:0.00022842444602051107\n",
            "train loss:0.0007279059414302878\n",
            "train loss:0.0016304090275042781\n",
            "train loss:0.012491591499889343\n",
            "train loss:0.0007959646054032948\n",
            "train loss:0.0016948436753598962\n",
            "train loss:0.0042864696842890085\n",
            "train loss:0.004524110551359037\n",
            "train loss:0.0007763421878774422\n",
            "train loss:0.0007548516347287217\n",
            "train loss:0.0009237521801220007\n",
            "train loss:0.008187674091983937\n",
            "train loss:0.014421009043008987\n",
            "=== epoch:17, train acc:0.998, test acc:0.988 ===\n",
            "train loss:0.003636060413782604\n",
            "train loss:0.0005316564431783861\n",
            "train loss:0.0037937376260434325\n",
            "train loss:0.0009242668449383061\n",
            "train loss:0.0002264522869705091\n",
            "train loss:0.000800090511203701\n",
            "train loss:0.0006715784484043354\n",
            "train loss:0.004878004756969654\n",
            "train loss:0.002101766775574178\n",
            "train loss:0.0005813114083984806\n",
            "train loss:0.003184526382583493\n",
            "train loss:0.008200305517820524\n",
            "train loss:0.0010159092953238645\n",
            "train loss:0.0005829898306679755\n",
            "train loss:0.0009868132821543175\n",
            "train loss:0.006171030289172045\n",
            "train loss:0.0009465493397652497\n",
            "train loss:0.0013360044743395889\n",
            "train loss:0.0031437764203574945\n",
            "train loss:0.006604225610165361\n",
            "train loss:0.0016055214862469012\n",
            "train loss:0.00016767343789293807\n",
            "train loss:0.002402370642786333\n",
            "train loss:0.0037315088934578387\n",
            "train loss:0.0005749671263097528\n",
            "train loss:0.015223322830129867\n",
            "train loss:0.002248350035837869\n",
            "train loss:0.0048643119803222145\n",
            "train loss:0.0002093576094078336\n",
            "train loss:0.0006069602202429006\n",
            "train loss:0.004747943817014332\n",
            "train loss:0.003696332819323661\n",
            "train loss:0.006634516918790151\n",
            "train loss:0.006799960490647373\n",
            "train loss:3.0776663224730735e-05\n",
            "train loss:0.0062945674165595655\n",
            "train loss:0.003937966715851882\n",
            "train loss:0.001328817017759156\n",
            "train loss:0.0024039757648120674\n",
            "train loss:0.0002791433468037378\n",
            "train loss:0.006151036945476798\n",
            "train loss:0.000661006377279629\n",
            "train loss:0.00017871068494115596\n",
            "train loss:0.006924533275565732\n",
            "train loss:0.000653243110292152\n",
            "train loss:0.0019708973893872786\n",
            "train loss:0.0011634220395985793\n",
            "train loss:0.002987749799173606\n",
            "train loss:0.0016090401271943303\n",
            "train loss:0.000734382143586226\n",
            "train loss:0.0005842447244630852\n",
            "train loss:0.001325114730239885\n",
            "train loss:0.0027564156417033956\n",
            "train loss:0.002741766076098059\n",
            "train loss:0.0011822326719731567\n",
            "train loss:0.0003325724678186913\n",
            "train loss:0.0007161687363216636\n",
            "train loss:0.005683923276761951\n",
            "train loss:0.00045873089454123364\n",
            "train loss:0.0005773927192828072\n",
            "train loss:0.002558336968657944\n",
            "train loss:0.0007740978712501055\n",
            "train loss:0.011759582122878658\n",
            "train loss:0.0027940393997659984\n",
            "train loss:0.004683262938829491\n",
            "train loss:0.0009547773603277766\n",
            "train loss:0.01659037539352642\n",
            "train loss:0.00356864676956411\n",
            "train loss:0.005803817546187625\n",
            "train loss:0.0004598500639620024\n",
            "train loss:0.0007246794163713464\n",
            "train loss:0.0013048540542223255\n",
            "train loss:0.005426836342953534\n",
            "train loss:0.001444732915617461\n",
            "train loss:0.0013585472722618354\n",
            "train loss:0.011311888281985837\n",
            "train loss:0.0006436432942366215\n",
            "train loss:0.0007038898716266556\n",
            "train loss:0.002005228020529844\n",
            "train loss:0.0035697524933723966\n",
            "train loss:0.0001195477237184138\n",
            "train loss:0.01549250361691789\n",
            "train loss:0.00015080586518951132\n",
            "train loss:0.0027166541570834857\n",
            "train loss:0.0022137554699858345\n",
            "train loss:0.0019872055418512636\n",
            "train loss:0.0022801668052868113\n",
            "train loss:0.0019697950518766513\n",
            "train loss:0.001291256103846393\n",
            "train loss:0.006098846280003789\n",
            "train loss:0.0004666742454814201\n",
            "train loss:0.0015914779636781561\n",
            "train loss:0.0005863598085775454\n",
            "train loss:0.0036945269505182475\n",
            "train loss:0.0010804615844170972\n",
            "train loss:0.0007690599069142888\n",
            "train loss:0.0011254686048538705\n",
            "train loss:0.00016089172409868572\n",
            "train loss:0.0009456028435331672\n",
            "train loss:0.001321856268761247\n",
            "train loss:0.0009009372872843112\n",
            "train loss:0.004362446277332165\n",
            "train loss:0.005401626630049568\n",
            "train loss:0.002210149031454213\n",
            "train loss:0.0006601997386961767\n",
            "train loss:0.00014245173571134724\n",
            "train loss:0.0002467770004465093\n",
            "train loss:0.005863222870299057\n",
            "train loss:0.00018449560866844593\n",
            "train loss:0.0034249608850285946\n",
            "train loss:0.004281661774094375\n",
            "train loss:0.0041467630058424215\n",
            "train loss:0.0004776503140059888\n",
            "train loss:0.0024308378213305283\n",
            "train loss:0.0032840121764099485\n",
            "train loss:4.261232271049499e-05\n",
            "train loss:0.0009306952903842129\n",
            "train loss:0.0030285544380914747\n",
            "train loss:0.00035763824308217756\n",
            "train loss:0.0035312474011951105\n",
            "train loss:0.00030085884370241846\n",
            "train loss:0.0027481001157876788\n",
            "train loss:0.00020116085078248432\n",
            "train loss:0.002020792349374307\n",
            "train loss:0.0026221873327356643\n",
            "train loss:0.00010775261772965596\n",
            "train loss:0.00022157157853106235\n",
            "train loss:0.00023271664193070355\n",
            "train loss:0.000534705564528802\n",
            "train loss:0.0006321189983857481\n",
            "train loss:0.005391959499906801\n",
            "train loss:0.0016451594375621397\n",
            "train loss:0.0021785340239216205\n",
            "train loss:0.0012801319424890073\n",
            "train loss:0.0012496813102086974\n",
            "train loss:0.0007835561841719354\n",
            "train loss:0.0013133912578808316\n",
            "train loss:0.00928428863157813\n",
            "train loss:8.224774528712748e-05\n",
            "train loss:0.001092322435601121\n",
            "train loss:0.00032976194935207257\n",
            "train loss:0.0011199734740176873\n",
            "train loss:0.0006932637676327029\n",
            "train loss:0.0064548345277287145\n",
            "train loss:0.002233751010412644\n",
            "train loss:0.0010633396447798033\n",
            "train loss:0.001055424671156509\n",
            "train loss:0.005459078158102628\n",
            "train loss:0.0008972445156750213\n",
            "train loss:0.00025880222601414656\n",
            "train loss:0.0016081785775781349\n",
            "train loss:0.011449766554816736\n",
            "train loss:0.001975751414268607\n",
            "train loss:4.3685434248270425e-05\n",
            "train loss:0.00048662698424507036\n",
            "train loss:0.0006998737831561357\n",
            "train loss:0.001442396420407044\n",
            "train loss:0.009335028200862277\n",
            "train loss:0.0010128643839191608\n",
            "train loss:6.773146446800349e-05\n",
            "train loss:0.000766433287833939\n",
            "train loss:0.0023761012117018534\n",
            "train loss:0.0009070647824221698\n",
            "train loss:0.00023667119730947934\n",
            "train loss:0.0035331754377753693\n",
            "train loss:0.0018814063690458487\n",
            "train loss:0.004685713939523645\n",
            "train loss:0.0008318790284819913\n",
            "train loss:0.004157125471747968\n",
            "train loss:0.00039353966920110744\n",
            "train loss:0.0004900169094568816\n",
            "train loss:0.002141575012856384\n",
            "train loss:0.013306580043033178\n",
            "train loss:0.0869952683655387\n",
            "train loss:0.0009845686106627902\n",
            "train loss:0.0010342017543405677\n",
            "train loss:0.0019194233396876623\n",
            "train loss:0.004408285216201191\n",
            "train loss:0.0004917139842363749\n",
            "train loss:0.004430602698598152\n",
            "train loss:0.00354193606398296\n",
            "train loss:0.0057571308361252065\n",
            "train loss:0.0034991086784801123\n",
            "train loss:0.0007742025924730943\n",
            "train loss:6.189586795944653e-05\n",
            "train loss:0.00017674892313619822\n",
            "train loss:0.0016450810893313176\n",
            "train loss:0.0011092096690497398\n",
            "train loss:0.0059835236244321485\n",
            "train loss:6.866095427783398e-05\n",
            "train loss:0.00010673660071397604\n",
            "train loss:0.0022187358712046903\n",
            "train loss:0.0018403290777534121\n",
            "train loss:0.0008315447724611064\n",
            "train loss:0.009316267492610284\n",
            "train loss:0.0027734807593173465\n",
            "train loss:0.004810874952271954\n",
            "train loss:0.0011975515810808658\n",
            "train loss:0.001305892791631417\n",
            "train loss:0.004308614937484064\n",
            "train loss:0.0003074273412001161\n",
            "train loss:0.004167064058799772\n",
            "train loss:0.0015923073416473517\n",
            "train loss:0.0016952749885551731\n",
            "train loss:0.0003757038542769476\n",
            "train loss:0.0010598548349379747\n",
            "train loss:0.00026211045631487854\n",
            "train loss:0.002429926257968361\n",
            "train loss:0.0001275286325830921\n",
            "train loss:0.0015513885063063084\n",
            "train loss:0.0035656583983457997\n",
            "train loss:0.00022835726554948214\n",
            "train loss:0.001096205725036223\n",
            "train loss:0.0004571476232921352\n",
            "train loss:0.00017963749082234627\n",
            "train loss:0.0004281134470954673\n",
            "train loss:0.0008592998591951925\n",
            "train loss:0.0050992794878116175\n",
            "train loss:0.0002982481705329561\n",
            "train loss:0.00043660577656195825\n",
            "train loss:0.00023873952192441012\n",
            "train loss:0.00023756036702375055\n",
            "train loss:0.000919017076318644\n",
            "train loss:0.00036111131692077235\n",
            "train loss:0.00010639574840707504\n",
            "train loss:0.0007087883289895457\n",
            "train loss:0.0007765842696116311\n",
            "train loss:0.00037918260741077385\n",
            "train loss:0.0026926141964307864\n",
            "train loss:0.002149321029341123\n",
            "train loss:0.0003481556097208156\n",
            "train loss:0.000672506779797909\n",
            "train loss:0.004322948124463287\n",
            "train loss:0.0008570725903623215\n",
            "train loss:0.00035577553059493937\n",
            "train loss:0.0015991724418512774\n",
            "train loss:0.033008703072297814\n",
            "train loss:0.0018751192376128558\n",
            "train loss:0.0006069226803971386\n",
            "train loss:0.001898212513772828\n",
            "train loss:0.004241096065393314\n",
            "train loss:0.0011841929397293442\n",
            "train loss:0.0001912223995916793\n",
            "train loss:0.009272343601247086\n",
            "train loss:0.0007633021444574528\n",
            "train loss:0.006677882576130635\n",
            "train loss:0.00021259228852238792\n",
            "train loss:0.0008800969791982054\n",
            "train loss:0.0019489685341133856\n",
            "train loss:0.00012909143962273921\n",
            "train loss:0.0021200654707655433\n",
            "train loss:0.0003642317507400099\n",
            "train loss:0.008639034395949421\n",
            "train loss:0.014084708220611065\n",
            "train loss:0.0043315443190216985\n",
            "train loss:0.0016985458401191978\n",
            "train loss:0.0005383834518128093\n",
            "train loss:0.0006355693314475329\n",
            "train loss:0.011087549907440373\n",
            "train loss:0.011457279564382942\n",
            "train loss:0.0004479514819161347\n",
            "train loss:0.004519606960745428\n",
            "train loss:0.003312661399018638\n",
            "train loss:7.702789304688798e-05\n",
            "train loss:0.002174473026640402\n",
            "train loss:0.011004816593248595\n",
            "train loss:0.0013875831984256537\n",
            "train loss:0.0013866267823517712\n",
            "train loss:0.0003982073270432801\n",
            "train loss:0.006343761328443196\n",
            "train loss:0.0001472000636529749\n",
            "train loss:0.005646725081285312\n",
            "train loss:0.003892020721255844\n",
            "train loss:0.00040789834910133125\n",
            "train loss:0.0007362620017668474\n",
            "train loss:0.0007839301212837435\n",
            "train loss:0.001760089303720767\n",
            "train loss:0.0063898551753909195\n",
            "train loss:0.004822592784665441\n",
            "train loss:0.00026170987438683626\n",
            "train loss:0.025133342975449467\n",
            "train loss:0.0005334203715051202\n",
            "train loss:0.00022653881739102805\n",
            "train loss:0.00035878325092554445\n",
            "train loss:0.004176940672997065\n",
            "train loss:0.0017377021330452725\n",
            "train loss:0.0014169203122778224\n",
            "train loss:0.001732155233769735\n",
            "train loss:0.0036347227732172367\n",
            "train loss:0.000749251265052572\n",
            "train loss:0.0026392052390745756\n",
            "train loss:0.0005870273021567531\n",
            "train loss:0.001747271407172136\n",
            "train loss:0.003223922267170073\n",
            "train loss:0.002212890910861709\n",
            "train loss:0.0022317554794391683\n",
            "train loss:0.002658100643263729\n",
            "train loss:0.0020685441177871787\n",
            "train loss:0.005843229638206722\n",
            "train loss:0.0008858306285737368\n",
            "train loss:0.0016726810615519817\n",
            "train loss:0.020162169197687863\n",
            "train loss:0.0008934680632273367\n",
            "train loss:0.0022175378847668304\n",
            "train loss:2.9824876413920834e-05\n",
            "train loss:0.0008148849391723163\n",
            "train loss:0.0002383712160845286\n",
            "train loss:0.0002804390130250954\n",
            "train loss:0.0007730873068460496\n",
            "train loss:0.002086805346655786\n",
            "train loss:0.0006701093623614426\n",
            "train loss:0.0064194210410959155\n",
            "train loss:0.006426103222894657\n",
            "train loss:0.0014497938594622227\n",
            "train loss:0.004668170350854176\n",
            "train loss:0.012972191039474475\n",
            "train loss:0.0010927075141699471\n",
            "train loss:0.00032423129310716025\n",
            "train loss:0.0008622252562782974\n",
            "train loss:0.001719564648926702\n",
            "train loss:0.007271573454821918\n",
            "train loss:0.001935768455924183\n",
            "train loss:0.0011521305270882568\n",
            "train loss:0.0015803140391601718\n",
            "train loss:0.0002941264839619098\n",
            "train loss:0.0025444003471903516\n",
            "train loss:0.0009073001042110035\n",
            "train loss:0.0006919495943288235\n",
            "train loss:0.0005082945473012173\n",
            "train loss:0.0027563648007168547\n",
            "train loss:0.003738941602724604\n",
            "train loss:0.0046394292690080585\n",
            "train loss:0.04440358891577235\n",
            "train loss:0.0014185633289648706\n",
            "train loss:0.0006135878116320696\n",
            "train loss:0.023745969049525896\n",
            "train loss:0.00922585695096292\n",
            "train loss:0.0008513773266597791\n",
            "train loss:0.010179914942571967\n",
            "train loss:0.0006090432465630667\n",
            "train loss:0.0013937947261456341\n",
            "train loss:0.0007531566885491574\n",
            "train loss:0.00018990485346035858\n",
            "train loss:0.0005005359488467875\n",
            "train loss:0.005898879516207417\n",
            "train loss:0.001298660807125549\n",
            "train loss:6.563090800463676e-05\n",
            "train loss:0.00340639173992059\n",
            "train loss:0.0012222075153041254\n",
            "train loss:0.0024419417709198622\n",
            "train loss:0.0001994455125676596\n",
            "train loss:0.0014813460586785756\n",
            "train loss:0.0002590223593837862\n",
            "train loss:0.002169010599465851\n",
            "train loss:0.0005487152000786422\n",
            "train loss:0.008316038144270146\n",
            "train loss:0.002202278201360251\n",
            "train loss:3.946256332867735e-05\n",
            "train loss:0.01820121065041097\n",
            "train loss:0.0008293920715373358\n",
            "train loss:0.00016275211407628038\n",
            "train loss:0.0009420070195518598\n",
            "train loss:0.00033926946628725404\n",
            "train loss:0.010131056425237673\n",
            "train loss:0.000566333829737836\n",
            "train loss:0.0005036706912787845\n",
            "train loss:0.0007586263446382472\n",
            "train loss:0.0018631280626792892\n",
            "train loss:0.0028747400823190645\n",
            "train loss:0.0005240274410162598\n",
            "train loss:0.002234053935959336\n",
            "train loss:0.005730944347171088\n",
            "train loss:0.008054716732909882\n",
            "train loss:0.004922705686637763\n",
            "train loss:0.00022516243029167322\n",
            "train loss:0.001094878384073575\n",
            "train loss:0.0011148990007861061\n",
            "train loss:0.0006948930720301827\n",
            "train loss:0.0030373270438073755\n",
            "train loss:0.0022084880424800193\n",
            "train loss:0.00027190135314266925\n",
            "train loss:0.001183713411648267\n",
            "train loss:0.003176729989127961\n",
            "train loss:0.0014902059841523157\n",
            "train loss:0.0004190880290009911\n",
            "train loss:0.00032141491875113204\n",
            "train loss:0.016348996152228443\n",
            "train loss:0.007871735010609063\n",
            "train loss:0.002723146332020142\n",
            "train loss:0.001753232398779718\n",
            "train loss:0.0015541941123115093\n",
            "train loss:0.013536763646316213\n",
            "train loss:0.0025288462241681966\n",
            "train loss:0.0075656165278603\n",
            "train loss:0.01880202518996813\n",
            "train loss:0.006486232381634682\n",
            "train loss:0.0022053062781675153\n",
            "train loss:0.004094786576898251\n",
            "train loss:0.0004028482904281216\n",
            "train loss:0.00042837487673789786\n",
            "train loss:0.0004361536022488812\n",
            "train loss:0.002447907755629348\n",
            "train loss:0.0006091130333866617\n",
            "train loss:0.0035848395666098626\n",
            "train loss:0.005169218065516905\n",
            "train loss:0.0004594910938515814\n",
            "train loss:0.00592338754424757\n",
            "train loss:0.0057992959413642655\n",
            "train loss:0.00455930334667145\n",
            "train loss:0.0009671102916158298\n",
            "train loss:0.00026654628948524274\n",
            "train loss:0.000997055261999783\n",
            "train loss:0.003938746167816429\n",
            "train loss:0.019047461827475933\n",
            "train loss:0.0027494165000596328\n",
            "train loss:0.0003656834537835981\n",
            "train loss:0.0009611590790237489\n",
            "train loss:0.0014350506931801322\n",
            "train loss:0.0008425021099710475\n",
            "train loss:0.0006578173157795776\n",
            "train loss:0.002922952776891743\n",
            "train loss:0.0016703640871353351\n",
            "train loss:0.000571225608298894\n",
            "train loss:0.0001919950695519997\n",
            "train loss:0.0031999524179894107\n",
            "train loss:0.004694575574026488\n",
            "train loss:0.0011111514744923845\n",
            "train loss:0.0027739835401191758\n",
            "train loss:0.0005445653150194282\n",
            "train loss:0.015364542530840387\n",
            "train loss:0.0003047410470571994\n",
            "train loss:0.00011624788678938306\n",
            "train loss:0.006236314069046179\n",
            "train loss:0.00019500087782384052\n",
            "train loss:0.00030556266370739086\n",
            "train loss:0.00046788758586804505\n",
            "train loss:0.0055432464783495925\n",
            "train loss:0.014483146857187646\n",
            "train loss:0.0004330726687600714\n",
            "train loss:0.0006560388830571654\n",
            "train loss:0.0015579692514629754\n",
            "train loss:0.008567315980323552\n",
            "train loss:0.0013445246928187496\n",
            "train loss:0.0024834086449296543\n",
            "train loss:0.0039687618833880636\n",
            "train loss:0.004978532562254109\n",
            "train loss:0.002171334020012157\n",
            "train loss:0.0034833307822959257\n",
            "train loss:0.000739854717819213\n",
            "train loss:0.00046725477714439404\n",
            "train loss:0.0019219235700379705\n",
            "train loss:0.0008667345231664606\n",
            "train loss:0.026590070028103728\n",
            "train loss:0.000985237670513043\n",
            "train loss:0.0005709759517111496\n",
            "train loss:0.0027148535869676305\n",
            "train loss:0.00658961529435731\n",
            "train loss:0.004127202265973435\n",
            "train loss:0.01383759216788791\n",
            "train loss:0.0004138287071055638\n",
            "train loss:0.006292300253897107\n",
            "train loss:0.00044395345713100083\n",
            "train loss:0.00018701434661217017\n",
            "train loss:0.002742967995923814\n",
            "train loss:0.021395083871694802\n",
            "train loss:0.0006004013908026448\n",
            "train loss:0.0042681637973569254\n",
            "train loss:0.0025322908465049156\n",
            "train loss:0.00010753077500325536\n",
            "train loss:0.0010747077101900403\n",
            "train loss:0.0019183687700977294\n",
            "train loss:0.009595946281010997\n",
            "train loss:0.0010228193456613853\n",
            "train loss:0.0005169078817213003\n",
            "train loss:0.00054309936383034\n",
            "train loss:3.368931927883135e-05\n",
            "train loss:0.002342964239801751\n",
            "train loss:0.003596639773456074\n",
            "train loss:0.0037090746831809625\n",
            "train loss:0.027720198332635847\n",
            "train loss:0.03761296636409209\n",
            "train loss:0.0009896277036716967\n",
            "train loss:0.001876046779879151\n",
            "train loss:0.0010866976149211272\n",
            "train loss:0.003769936662009417\n",
            "train loss:0.012274573068851468\n",
            "train loss:0.005894985591624254\n",
            "train loss:0.0011864720294014663\n",
            "train loss:0.002573411660910585\n",
            "train loss:0.0020369156180742036\n",
            "train loss:0.004164265757812387\n",
            "train loss:0.006234903067792135\n",
            "train loss:0.0060480039421179745\n",
            "train loss:0.0015223045260662242\n",
            "train loss:0.00022705748231433026\n",
            "train loss:0.0001919089908969216\n",
            "train loss:0.006755994705214193\n",
            "train loss:0.0017220305101406839\n",
            "train loss:0.0006156221509020468\n",
            "train loss:0.0025825324139069268\n",
            "train loss:0.00047763321593859024\n",
            "train loss:0.0019644986214101805\n",
            "train loss:0.0026025160168130367\n",
            "train loss:0.0012671094505656063\n",
            "train loss:0.0022898445650140265\n",
            "train loss:0.00038181287031035496\n",
            "train loss:0.00036830108141753463\n",
            "train loss:0.00122857244242761\n",
            "train loss:0.04464327016604222\n",
            "train loss:0.00010806972096441206\n",
            "train loss:0.0027762139513867997\n",
            "train loss:0.0036362137598074783\n",
            "train loss:0.0018641461832495437\n",
            "train loss:0.005605921228022987\n",
            "train loss:0.0007137802241556848\n",
            "train loss:0.0014319504830826437\n",
            "train loss:0.0019509330406941383\n",
            "train loss:0.00048391436816842213\n",
            "train loss:6.60646279369914e-05\n",
            "train loss:0.00045424533364285633\n",
            "train loss:0.001107979130890035\n",
            "train loss:0.00320706417638019\n",
            "train loss:0.002059767829223319\n",
            "train loss:0.000525991273693367\n",
            "train loss:0.0025110620179982722\n",
            "train loss:0.0013691721737150884\n",
            "train loss:0.019113043775390446\n",
            "train loss:0.0003997026022499617\n",
            "train loss:9.950606433682265e-05\n",
            "train loss:5.4160997123025624e-05\n",
            "train loss:0.003136041063489067\n",
            "train loss:0.0007590061696305983\n",
            "train loss:0.0022084641892235308\n",
            "train loss:0.0014237552129308187\n",
            "train loss:0.0017946783160783328\n",
            "train loss:0.003209930926934988\n",
            "train loss:0.0010715352484881712\n",
            "train loss:0.002337961579547992\n",
            "train loss:0.00021943104101118397\n",
            "train loss:0.002918456309259872\n",
            "train loss:0.0005524991183186571\n",
            "train loss:0.002478033637307834\n",
            "train loss:0.0008559135900266559\n",
            "train loss:0.015633689428268354\n",
            "train loss:0.0029891597860744806\n",
            "train loss:0.0023685189283175205\n",
            "train loss:0.00023763643593761722\n",
            "train loss:0.0023160905413749395\n",
            "train loss:0.0030149670675360023\n",
            "train loss:0.000246008923967505\n",
            "train loss:0.00170941101499126\n",
            "train loss:0.001962171726430165\n",
            "train loss:0.0016618963742423784\n",
            "train loss:0.0012415191993169685\n",
            "train loss:0.0009387570623812812\n",
            "train loss:0.00017374163808995543\n",
            "train loss:0.005069488547561201\n",
            "train loss:0.0002782197573498788\n",
            "train loss:0.002237079795708555\n",
            "train loss:0.0016982320324279946\n",
            "train loss:0.0013421504948639832\n",
            "train loss:0.0003521593478363851\n",
            "train loss:0.00019537495496644983\n",
            "train loss:7.674122258635152e-05\n",
            "train loss:0.0028299996427406087\n",
            "train loss:0.0015892273498527413\n",
            "train loss:0.00024797316194111353\n",
            "train loss:0.00498482962333052\n",
            "train loss:0.0035850744730803684\n",
            "train loss:1.5860076984514504e-05\n",
            "train loss:0.0002598419773968253\n",
            "train loss:0.00026463733358757344\n",
            "train loss:0.0011660037369286445\n",
            "train loss:0.0004261101066951112\n",
            "train loss:0.0009786201744301532\n",
            "train loss:0.0004392738525448695\n",
            "train loss:0.00016648132120760983\n",
            "train loss:0.009477022706645875\n",
            "train loss:0.0016549230234368178\n",
            "train loss:0.005420395514458967\n",
            "train loss:0.000658120227802765\n",
            "train loss:0.0026147813440357786\n",
            "train loss:0.001092807385225952\n",
            "train loss:0.0005178797283052757\n",
            "train loss:0.0016504062048798692\n",
            "train loss:0.006190279563205536\n",
            "train loss:0.000838444557616754\n",
            "train loss:0.005823180971244826\n",
            "train loss:0.006555038716983508\n",
            "train loss:0.0011964918911401194\n",
            "train loss:0.002393384254612594\n",
            "train loss:0.0009574182230112714\n",
            "train loss:0.0006057805189192519\n",
            "train loss:0.003409443564466792\n",
            "train loss:0.006311461830020008\n",
            "train loss:0.0002830715302903434\n",
            "train loss:0.0011873136960396848\n",
            "train loss:0.0025473316706286\n",
            "train loss:0.00020529735569752255\n",
            "train loss:0.0007627373390226022\n",
            "=== epoch:18, train acc:0.997, test acc:0.987 ===\n",
            "train loss:0.006497290654330253\n",
            "train loss:0.0005669911916010022\n",
            "train loss:0.002027454078642019\n",
            "train loss:0.001073782758883786\n",
            "train loss:0.00033467113611438954\n",
            "train loss:0.05746497821290135\n",
            "train loss:0.007284088470100969\n",
            "train loss:0.0011651075551694463\n",
            "train loss:0.0005736817307923474\n",
            "train loss:0.003948411651472094\n",
            "train loss:0.003079419463684573\n",
            "train loss:0.0005031669921127502\n",
            "train loss:0.00015460140299140216\n",
            "train loss:0.0006772559573076083\n",
            "train loss:0.005473594995373834\n",
            "train loss:0.005903728361201582\n",
            "train loss:0.039663707476516354\n",
            "train loss:0.00027400944267171994\n",
            "train loss:0.005407536900922272\n",
            "train loss:0.0006505643534413722\n",
            "train loss:0.0010470872571062325\n",
            "train loss:0.026151330102397407\n",
            "train loss:0.0010544956270752432\n",
            "train loss:0.0013315515502307154\n",
            "train loss:0.0006342579918564409\n",
            "train loss:0.005395903306558971\n",
            "train loss:0.0005556049100302516\n",
            "train loss:0.0019974632496645136\n",
            "train loss:0.00017154102094952238\n",
            "train loss:0.0021925139153340673\n",
            "train loss:0.006934459498687209\n",
            "train loss:7.072830789418198e-05\n",
            "train loss:0.00033563342880516776\n",
            "train loss:0.0010602825025932642\n",
            "train loss:0.0036502988993987588\n",
            "train loss:0.0019121780792335965\n",
            "train loss:0.0037250981804081516\n",
            "train loss:0.0005330836297323016\n",
            "train loss:0.0015521034773493246\n",
            "train loss:0.0015066218132441208\n",
            "train loss:0.00047663949729383773\n",
            "train loss:0.006699904358561172\n",
            "train loss:0.00068623231762682\n",
            "train loss:0.0004904872511239306\n",
            "train loss:0.007765707643487727\n",
            "train loss:0.03455758005381423\n",
            "train loss:0.00034139973832555677\n",
            "train loss:0.02975652128853455\n",
            "train loss:0.0010163380168999132\n",
            "train loss:0.002086887812911549\n",
            "train loss:0.005726415525396954\n",
            "train loss:0.0008650925390198471\n",
            "train loss:0.026162820001322317\n",
            "train loss:0.0001229300133040906\n",
            "train loss:0.0005199709221435044\n",
            "train loss:0.00021086641800011373\n",
            "train loss:0.00021801670811306853\n",
            "train loss:0.0003094560111374021\n",
            "train loss:0.0036910921605406892\n",
            "train loss:5.890395937979516e-05\n",
            "train loss:0.0002815243738011926\n",
            "train loss:0.0022075040072992995\n",
            "train loss:0.0004919261847303898\n",
            "train loss:0.0007049665448882171\n",
            "train loss:0.0026175015899736697\n",
            "train loss:0.004295428353613308\n",
            "train loss:0.000348689426282947\n",
            "train loss:0.002526888802985375\n",
            "train loss:0.005477207855009686\n",
            "train loss:0.00013420712656677137\n",
            "train loss:0.001044391254531236\n",
            "train loss:0.0005934619918518359\n",
            "train loss:0.005980241632732668\n",
            "train loss:0.00047248496700416724\n",
            "train loss:0.004211414761241324\n",
            "train loss:0.00039075603809546653\n",
            "train loss:0.0005951333617202879\n",
            "train loss:0.0030639695258846385\n",
            "train loss:0.0031119300618650037\n",
            "train loss:0.0026067664681114493\n",
            "train loss:0.002264875572237767\n",
            "train loss:0.001110452866107014\n",
            "train loss:0.0010453224794247239\n",
            "train loss:0.0017691549062751103\n",
            "train loss:0.0015142041036702567\n",
            "train loss:0.0007051736668140959\n",
            "train loss:4.384212692841128e-05\n",
            "train loss:0.001426185092409061\n",
            "train loss:0.004944208286576332\n",
            "train loss:0.0018224286083095662\n",
            "train loss:0.00038628661222730505\n",
            "train loss:0.005584949108502158\n",
            "train loss:0.0011927244164493334\n",
            "train loss:0.0018673635484743034\n",
            "train loss:0.013506148590023082\n",
            "train loss:0.002713130272369857\n",
            "train loss:0.00044208553598498973\n",
            "train loss:0.0030418660089358927\n",
            "train loss:0.0003960646367672795\n",
            "train loss:0.0001885986803120727\n",
            "train loss:0.00019210503181548672\n",
            "train loss:0.0009005460455711235\n",
            "train loss:0.0023442783935776657\n",
            "train loss:0.0013154005817446119\n",
            "train loss:0.0024562363729532565\n",
            "train loss:0.0031527147450671564\n",
            "train loss:0.013285357374552385\n",
            "train loss:0.015342747681348872\n",
            "train loss:0.0028421231705132526\n",
            "train loss:0.0015420553633047338\n",
            "train loss:0.002812939178680389\n",
            "train loss:0.0018777554254817198\n",
            "train loss:0.0005000057728540684\n",
            "train loss:0.0001257211128856837\n",
            "train loss:0.0008870143557134166\n",
            "train loss:0.00034615523080527117\n",
            "train loss:0.0032614050350350757\n",
            "train loss:0.0017853519775703403\n",
            "train loss:0.02274557634103375\n",
            "train loss:0.002140597796451477\n",
            "train loss:0.0009033179171394851\n",
            "train loss:0.004084103583296136\n",
            "train loss:0.0005230037151944224\n",
            "train loss:0.00250483149075611\n",
            "train loss:0.002963232906938504\n",
            "train loss:0.00020328209313182487\n",
            "train loss:0.0019245110967029695\n",
            "train loss:0.003194069566517922\n",
            "train loss:0.055931605850799315\n",
            "train loss:0.016126232229545238\n",
            "train loss:0.010546273299177988\n",
            "train loss:0.021144671028162688\n",
            "train loss:0.0007933870389737573\n",
            "train loss:0.002737559059071718\n",
            "train loss:0.00017295188283629644\n",
            "train loss:0.0005609738428436272\n",
            "train loss:0.0007900240276726096\n",
            "train loss:0.0007616427264171976\n",
            "train loss:0.0019781310232108744\n",
            "train loss:0.003711027355841176\n",
            "train loss:0.0011879624416179495\n",
            "train loss:0.006508300630741446\n",
            "train loss:0.0020426625872732\n",
            "train loss:0.0008511897965346031\n",
            "train loss:0.0006159788879993557\n",
            "train loss:0.0003128866772225667\n",
            "train loss:0.003448844440403304\n",
            "train loss:0.007393760600896003\n",
            "train loss:0.007095485277601319\n",
            "train loss:0.00011554171697487868\n",
            "train loss:0.0018093980306861177\n",
            "train loss:0.009873640584041814\n",
            "train loss:0.012581726901750849\n",
            "train loss:0.0004667538960604454\n",
            "train loss:0.000871860984687041\n",
            "train loss:0.0018847796492630652\n",
            "train loss:0.031733113051758875\n",
            "train loss:0.0008558257971535794\n",
            "train loss:0.004034524287849636\n",
            "train loss:0.0007274628973671548\n",
            "train loss:0.012670315895533284\n",
            "train loss:0.0026007395417469753\n",
            "train loss:0.00017438846357726673\n",
            "train loss:0.010369916079503421\n",
            "train loss:0.0021181975040419224\n",
            "train loss:0.0006749944498539845\n",
            "train loss:0.0009696558701451258\n",
            "train loss:0.0016168548541059037\n",
            "train loss:0.0058597181909137005\n",
            "train loss:0.0016166154424165943\n",
            "train loss:0.000190080544859787\n",
            "train loss:0.0009167882335633344\n",
            "train loss:0.003478849809827408\n",
            "train loss:0.00010343876131080877\n",
            "train loss:0.0020755522076385943\n",
            "train loss:0.000335625170746653\n",
            "train loss:0.0007767958041898424\n",
            "train loss:0.004155933394108827\n",
            "train loss:0.002779217145127581\n",
            "train loss:8.243743616278092e-05\n",
            "train loss:0.00010207689520650006\n",
            "train loss:0.005169553304683737\n",
            "train loss:5.287798566381673e-05\n",
            "train loss:0.012995345185753822\n",
            "train loss:0.00015519794966252048\n",
            "train loss:0.001231195558798131\n",
            "train loss:0.0001832676442313054\n",
            "train loss:0.0016938159572346013\n",
            "train loss:0.00028853884405206134\n",
            "train loss:0.00023529066704316398\n",
            "train loss:0.004958922945179238\n",
            "train loss:0.003876518998087091\n",
            "train loss:0.005772337265430477\n",
            "train loss:0.0016477373689182226\n",
            "train loss:0.0017359105059241086\n",
            "train loss:0.00026067546445113763\n",
            "train loss:0.004603903411476754\n",
            "train loss:0.00048282204592236475\n",
            "train loss:0.002837345909814846\n",
            "train loss:0.0034459745727947765\n",
            "train loss:0.005026510864094629\n",
            "train loss:0.004147209499222285\n",
            "train loss:0.0007725197266270184\n",
            "train loss:0.00030502919945877004\n",
            "train loss:0.0010720500852328095\n",
            "train loss:0.0036068491314316126\n",
            "train loss:0.0034313030175179104\n",
            "train loss:0.0004622861603368718\n",
            "train loss:0.0010082871318780932\n",
            "train loss:0.0040634445163911515\n",
            "train loss:0.0004132981658719768\n",
            "train loss:0.0005820509836767434\n",
            "train loss:0.00024994828028726063\n",
            "train loss:0.0013681229795313302\n",
            "train loss:7.17631879286955e-05\n",
            "train loss:0.008212365838396421\n",
            "train loss:0.0008349971462020341\n",
            "train loss:0.00010710788740442139\n",
            "train loss:0.0007182826677863682\n",
            "train loss:0.01913918787573836\n",
            "train loss:0.00480280198686509\n",
            "train loss:0.0004872931732443402\n",
            "train loss:0.0016620863300757251\n",
            "train loss:0.0018841664238990017\n",
            "train loss:0.0012705128370613565\n",
            "train loss:0.0003747438545754026\n",
            "train loss:0.009299705137921393\n",
            "train loss:0.02538192349839982\n",
            "train loss:0.005178718340851228\n",
            "train loss:0.00023179876734880718\n",
            "train loss:0.0007198436141342744\n",
            "train loss:0.0007528739715445767\n",
            "train loss:0.002023159537751587\n",
            "train loss:0.004352172678934508\n",
            "train loss:0.00023271077132483255\n",
            "train loss:0.0023831006181788033\n",
            "train loss:0.004056674575870842\n",
            "train loss:0.0008258768188393645\n",
            "train loss:0.0005482176868738277\n",
            "train loss:0.007396813067683013\n",
            "train loss:0.0006150990860639953\n",
            "train loss:0.007547597726326455\n",
            "train loss:0.00943390200070796\n",
            "train loss:0.0006786215223903238\n",
            "train loss:0.003627811570331215\n",
            "train loss:0.0026975516750416327\n",
            "train loss:0.0005113944000801661\n",
            "train loss:0.00098056087868226\n",
            "train loss:0.0001270272067476063\n",
            "train loss:0.00040416270340718234\n",
            "train loss:0.0016044309374739496\n",
            "train loss:0.0014477660314872781\n",
            "train loss:0.0020925898194126386\n",
            "train loss:0.0003029212083764759\n",
            "train loss:0.0002967204840845954\n",
            "train loss:0.006939407631422543\n",
            "train loss:0.0026950385498181535\n",
            "train loss:0.002288471218360076\n",
            "train loss:0.00019303547127229315\n",
            "train loss:0.004050578560482999\n",
            "train loss:0.0022886808310221595\n",
            "train loss:0.007269702125050151\n",
            "train loss:0.0011501711530521538\n",
            "train loss:0.015392190168211061\n",
            "train loss:0.0014106265285992623\n",
            "train loss:0.00016350943603839012\n",
            "train loss:0.0011067274777807935\n",
            "train loss:0.0034464230658231136\n",
            "train loss:0.005066742631306616\n",
            "train loss:0.00018522455284197183\n",
            "train loss:0.0008199933723541034\n",
            "train loss:0.002416956217070064\n",
            "train loss:0.004622027547193233\n",
            "train loss:0.0005240748841567759\n",
            "train loss:0.02233114097816837\n",
            "train loss:0.0017129419225156983\n",
            "train loss:0.0015576788182583318\n",
            "train loss:0.00010966195907280714\n",
            "train loss:0.004804508298506792\n",
            "train loss:0.0007990044965406882\n",
            "train loss:0.010090728346376022\n",
            "train loss:0.0005631679095455133\n",
            "train loss:0.005463329552164498\n",
            "train loss:0.0006202553184784673\n",
            "train loss:9.03096126834201e-05\n",
            "train loss:0.0013610861230720745\n",
            "train loss:0.0010409727913048173\n",
            "train loss:0.0016385053887638253\n",
            "train loss:0.006973770287045713\n",
            "train loss:0.0059939688860365485\n",
            "train loss:0.0005103610980273017\n",
            "train loss:0.005876557140481793\n",
            "train loss:0.00011859850344854417\n",
            "train loss:0.00017654097379102426\n",
            "train loss:0.013273448861149157\n",
            "train loss:0.000828502585447693\n",
            "train loss:0.0029646120465432226\n",
            "train loss:0.00225131540800556\n",
            "train loss:0.0033155115731736823\n",
            "train loss:0.00030129396047385405\n",
            "train loss:0.001755267778637213\n",
            "train loss:0.0002698693119319909\n",
            "train loss:0.0011368869536261294\n",
            "train loss:0.0005164735913007828\n",
            "train loss:0.009118035992827834\n",
            "train loss:0.003748016151648524\n",
            "train loss:0.0008207996393760322\n",
            "train loss:0.004957578173467861\n",
            "train loss:0.0039165004929908685\n",
            "train loss:0.002534891565486238\n",
            "train loss:0.00024803926565503635\n",
            "train loss:0.003101580997349765\n",
            "train loss:0.0007334278100897595\n",
            "train loss:0.004812073955809865\n",
            "train loss:0.0004751403527951613\n",
            "train loss:0.0013690708014188417\n",
            "train loss:0.0002842863207427166\n",
            "train loss:0.004809605975846352\n",
            "train loss:0.0005022102426412048\n",
            "train loss:0.0021725479967922763\n",
            "train loss:0.001159346675531136\n",
            "train loss:0.007127214477057732\n",
            "train loss:0.0014880227136050955\n",
            "train loss:0.0027737281284145455\n",
            "train loss:0.00031220905773065276\n",
            "train loss:0.0005977842708985006\n",
            "train loss:0.00024424343058617327\n",
            "train loss:0.000722049620670466\n",
            "train loss:0.005232014089082857\n",
            "train loss:0.0012454311797358974\n",
            "train loss:0.001197270023694188\n",
            "train loss:0.0009976340655674688\n",
            "train loss:0.001037161286342305\n",
            "train loss:0.00047834254724077573\n",
            "train loss:0.0001904835139254214\n",
            "train loss:0.0027473800025109825\n",
            "train loss:0.00038156037281083263\n",
            "train loss:0.0012897897846968493\n",
            "train loss:0.0035784847748664096\n",
            "train loss:0.00013748779435311784\n",
            "train loss:0.000773469425042559\n",
            "train loss:0.0018432697460870208\n",
            "train loss:0.0006024489426187429\n",
            "train loss:0.0015587470217543246\n",
            "train loss:0.0004570590852643393\n",
            "train loss:0.0002426026252058442\n",
            "train loss:0.0014497384516452751\n",
            "train loss:0.0004476650821400412\n",
            "train loss:0.00039720466627631484\n",
            "train loss:9.114301685419091e-05\n",
            "train loss:0.0005773584205321948\n",
            "train loss:0.0032712678635180136\n",
            "train loss:0.0005238325959441268\n",
            "train loss:0.0012658853320164387\n",
            "train loss:7.785544726454495e-05\n",
            "train loss:0.0004331868182007909\n",
            "train loss:0.0006256418005987971\n",
            "train loss:0.003246328788419936\n",
            "train loss:0.0007904636547526922\n",
            "train loss:0.007852465749879932\n",
            "train loss:4.940172375758032e-05\n",
            "train loss:0.0019744988274875337\n",
            "train loss:0.00040360774151992055\n",
            "train loss:0.006309934471140013\n",
            "train loss:0.00015348482980047105\n",
            "train loss:0.001303271266451022\n",
            "train loss:0.005924757008404392\n",
            "train loss:0.001724289120103774\n",
            "train loss:0.0006587963388226933\n",
            "train loss:0.0051649320277991385\n",
            "train loss:0.00020176715219991654\n",
            "train loss:0.0009598452946070027\n",
            "train loss:7.546470848681877e-05\n",
            "train loss:0.0032425735443669355\n",
            "train loss:2.7452287972528057e-05\n",
            "train loss:0.0018686642827962308\n",
            "train loss:0.00022018222907059515\n",
            "train loss:0.002289350897023193\n",
            "train loss:0.0005100650643311736\n",
            "train loss:0.0013907398566966667\n",
            "train loss:0.005375461772754996\n",
            "train loss:0.00016643139752503918\n",
            "train loss:0.0006049267172810873\n",
            "train loss:0.00011263353174185318\n",
            "train loss:0.00289442650942067\n",
            "train loss:2.2165609473413316e-05\n",
            "train loss:0.0004654928816160903\n",
            "train loss:0.00029454522109430325\n",
            "train loss:6.170813066233468e-05\n",
            "train loss:0.001442147245238299\n",
            "train loss:0.0001298707436081168\n",
            "train loss:0.0003759605100238997\n",
            "train loss:0.00021888194593550542\n",
            "train loss:7.847501681946151e-05\n",
            "train loss:0.0005456607300758542\n",
            "train loss:4.9140993447531745e-05\n",
            "train loss:0.007905391509104673\n",
            "train loss:0.004376942507113423\n",
            "train loss:0.002891490905478504\n",
            "train loss:0.00041523392454749557\n",
            "train loss:0.0006902082588712457\n",
            "train loss:0.0010326782686378726\n",
            "train loss:0.0008120826098338454\n",
            "train loss:0.003958151187933012\n",
            "train loss:0.0013850681643530352\n",
            "train loss:0.00013173982426472545\n",
            "train loss:0.0007843824513949631\n",
            "train loss:0.0011466399174804305\n",
            "train loss:0.0017954148973401078\n",
            "train loss:0.0018942432638872678\n",
            "train loss:0.00033535993721496246\n",
            "train loss:0.0005041708772551496\n",
            "train loss:0.0007535863054118827\n",
            "train loss:4.395036403514109e-05\n",
            "train loss:0.0029674121146987197\n",
            "train loss:0.00016829668773337477\n",
            "train loss:0.00045310611498655207\n",
            "train loss:0.0017241162756821214\n",
            "train loss:0.0006094767065214609\n",
            "train loss:0.00398393484836317\n",
            "train loss:0.0005837629210765319\n",
            "train loss:3.768016333416365e-05\n",
            "train loss:0.00041376312322502094\n",
            "train loss:0.0014615776293204713\n",
            "train loss:0.0013221488655916112\n",
            "train loss:0.002512985648557543\n",
            "train loss:0.0012401330270109389\n",
            "train loss:0.00017222216758906638\n",
            "train loss:0.0020575600816319078\n",
            "train loss:0.002213006849055669\n",
            "train loss:0.0011918337488930047\n",
            "train loss:0.003528037844866952\n",
            "train loss:0.0013630114017046592\n",
            "train loss:0.0007681085106634952\n",
            "train loss:0.00015725861290319672\n",
            "train loss:0.0012205731045880743\n",
            "train loss:0.00185885212024009\n",
            "train loss:0.0018449775854987446\n",
            "train loss:0.0007446032143267493\n",
            "train loss:0.0007571224966395629\n",
            "train loss:9.078804411044532e-05\n",
            "train loss:0.002919213809856517\n",
            "train loss:0.0020653042577330706\n",
            "train loss:7.397452616211391e-05\n",
            "train loss:0.004625354746603927\n",
            "train loss:0.0003180507858575788\n",
            "train loss:0.0002692697621521555\n",
            "train loss:0.0003333667414508339\n",
            "train loss:0.00013232126960427504\n",
            "train loss:0.0007340453918121205\n",
            "train loss:0.00029714724557345317\n",
            "train loss:0.0004841271307188908\n",
            "train loss:0.007424176154954198\n",
            "train loss:0.002094781784066578\n",
            "train loss:7.29501547278583e-05\n",
            "train loss:0.0015968193955245866\n",
            "train loss:0.00031699794302411405\n",
            "train loss:0.0010638214890709352\n",
            "train loss:0.0014347216405084092\n",
            "train loss:0.0009757277525077563\n",
            "train loss:0.004397975395358759\n",
            "train loss:0.00019436640204817095\n",
            "train loss:7.800962291175735e-05\n",
            "train loss:0.0015942768293359495\n",
            "train loss:0.0023479900491718327\n",
            "train loss:0.0006427362640125087\n",
            "train loss:0.00037586018121388715\n",
            "train loss:0.00048617329429537226\n",
            "train loss:0.0012634110047042436\n",
            "train loss:0.00033783953773394666\n",
            "train loss:0.0012317100643496092\n",
            "train loss:0.0019627310285319317\n",
            "train loss:0.0017659877263876155\n",
            "train loss:0.00010246025695271426\n",
            "train loss:0.011985655028904373\n",
            "train loss:0.0003991817004269173\n",
            "train loss:0.0005829335684922778\n",
            "train loss:0.0024033889191274137\n",
            "train loss:0.00025467513812341787\n",
            "train loss:0.00030361948745034857\n",
            "train loss:0.0002797647163441093\n",
            "train loss:0.0029702306281641578\n",
            "train loss:0.0002496784790391328\n",
            "train loss:8.509119755568041e-05\n",
            "train loss:0.00013766141559297225\n",
            "train loss:0.004757248961402684\n",
            "train loss:0.0010546502939625592\n",
            "train loss:0.00034336823778573515\n",
            "train loss:0.0008662363852170228\n",
            "train loss:0.0016648294954900286\n",
            "train loss:0.0004694857114729891\n",
            "train loss:0.0013546212820731447\n",
            "train loss:7.840436703056949e-05\n",
            "train loss:9.281402196455066e-05\n",
            "train loss:0.0001245355447585552\n",
            "train loss:0.0005744444652547114\n",
            "train loss:0.00017001115545576262\n",
            "train loss:8.21681755594661e-05\n",
            "train loss:0.0026349622184533654\n",
            "train loss:0.008335749168934483\n",
            "train loss:0.00039808560553641854\n",
            "train loss:5.802285941587498e-05\n",
            "train loss:0.0006277819167379837\n",
            "train loss:0.0012567468364254309\n",
            "train loss:0.0005065670683737916\n",
            "train loss:0.0006492463157732338\n",
            "train loss:0.0021762001378527593\n",
            "train loss:0.0002618034334892075\n",
            "train loss:0.00022584797459656032\n",
            "train loss:0.0019819315724277585\n",
            "train loss:0.0013261147376852868\n",
            "train loss:8.547366321238575e-05\n",
            "train loss:0.0016346767928536563\n",
            "train loss:0.0032450089739899696\n",
            "train loss:0.0008208779981142883\n",
            "train loss:0.0004354937772078863\n",
            "train loss:0.00033140566008663564\n",
            "train loss:0.0002273152088418796\n",
            "train loss:0.009832709379407303\n",
            "train loss:0.00046244976671934473\n",
            "train loss:0.0043438826061756195\n",
            "train loss:0.000837312054819674\n",
            "train loss:0.00041373087367337324\n",
            "train loss:0.00014994120035929638\n",
            "train loss:0.0009278263562288364\n",
            "train loss:0.0143723579578053\n",
            "train loss:0.0002479767866249995\n",
            "train loss:0.0013047290946731575\n",
            "train loss:0.0011861095565857723\n",
            "train loss:0.002820026589260752\n",
            "train loss:0.00019416553665852808\n",
            "train loss:8.712573447819089e-05\n",
            "train loss:0.0016941443059798147\n",
            "train loss:0.0007218076490760621\n",
            "train loss:0.0023396405333712075\n",
            "train loss:0.0011672785420727015\n",
            "train loss:0.0008477708246182712\n",
            "train loss:0.0015170727052535582\n",
            "train loss:0.00016246793678956632\n",
            "train loss:0.001011567236874718\n",
            "train loss:0.004048198190035696\n",
            "train loss:0.00019603726116182102\n",
            "train loss:0.0012008395068766064\n",
            "train loss:0.0005409272883895459\n",
            "train loss:0.0007103039736184259\n",
            "train loss:0.001712967550420535\n",
            "train loss:0.0007833597525898704\n",
            "train loss:0.0036622957307570776\n",
            "train loss:0.0022677300806468806\n",
            "train loss:0.001535054099503461\n",
            "train loss:0.0003753183905350878\n",
            "train loss:0.0004473826928220298\n",
            "train loss:0.00011676735530432992\n",
            "train loss:0.0001902319752555108\n",
            "train loss:0.00019736088294866527\n",
            "train loss:0.00025847193632136145\n",
            "train loss:0.0017998065011607363\n",
            "train loss:0.00219321170634644\n",
            "train loss:0.0028177974484607103\n",
            "train loss:0.000630361011407946\n",
            "train loss:0.0024206533489460388\n",
            "train loss:0.00120777749696928\n",
            "train loss:0.0029988399827374323\n",
            "train loss:0.0005328793166685335\n",
            "train loss:0.005380017735750442\n",
            "train loss:0.0018842106638761518\n",
            "train loss:0.0010649059393745561\n",
            "train loss:0.0014419318407392692\n",
            "train loss:0.00025144321012171464\n",
            "train loss:5.598151591015611e-05\n",
            "train loss:0.0012874261311945614\n",
            "train loss:0.0011878886670169892\n",
            "train loss:3.58640314265806e-05\n",
            "train loss:0.0004000655267149442\n",
            "train loss:0.0006207176796332135\n",
            "train loss:0.0009349994312158282\n",
            "train loss:0.0007390254950196311\n",
            "train loss:0.00011886251207079138\n",
            "train loss:0.001614021496204178\n",
            "train loss:0.0008725571439174314\n",
            "train loss:0.0010507927442591186\n",
            "train loss:0.0005261343293319257\n",
            "train loss:0.0005096957044365335\n",
            "train loss:6.55610348866022e-05\n",
            "train loss:0.000263451127493831\n",
            "train loss:0.0015263668372660344\n",
            "train loss:0.00040657781812569635\n",
            "train loss:0.001115927107344412\n",
            "train loss:0.00020735673298591397\n",
            "train loss:0.0017223610560639817\n",
            "train loss:0.004035618624795188\n",
            "train loss:3.922735952828762e-05\n",
            "train loss:0.000939447915889402\n",
            "train loss:0.0008684697942772505\n",
            "train loss:0.0020056042116399038\n",
            "train loss:0.00038034632788224126\n",
            "train loss:0.00037959436207340145\n",
            "train loss:0.00024319480296938433\n",
            "train loss:0.0029462818921999296\n",
            "train loss:0.0010822344879531194\n",
            "=== epoch:19, train acc:1.0, test acc:0.988 ===\n",
            "train loss:0.0016919177502966274\n",
            "train loss:0.0009614901837111022\n",
            "train loss:0.00044289278939413124\n",
            "train loss:0.0009636322236831064\n",
            "train loss:0.0008160396207144025\n",
            "train loss:5.738705661692597e-05\n",
            "train loss:0.004566158856438376\n",
            "train loss:0.0011800253396071821\n",
            "train loss:0.004787237562263986\n",
            "train loss:0.00037413466696225466\n",
            "train loss:0.0015888504238434796\n",
            "train loss:0.0006005162816137979\n",
            "train loss:9.230679086718063e-05\n",
            "train loss:6.819067771931223e-05\n",
            "train loss:0.0012597324677729388\n",
            "train loss:0.00032740006419790474\n",
            "train loss:0.00199086111722257\n",
            "train loss:0.002884235473737255\n",
            "train loss:0.0015119698739413173\n",
            "train loss:0.0034773488734052456\n",
            "train loss:0.000680525597495481\n",
            "train loss:0.002042734291805315\n",
            "train loss:0.0016237102980850137\n",
            "train loss:0.0003498150919290081\n",
            "train loss:0.0001821108991155756\n",
            "train loss:0.0004961969859019638\n",
            "train loss:0.0013890849442823783\n",
            "train loss:0.00033074199407528813\n",
            "train loss:0.00022178247077510562\n",
            "train loss:0.0012021889040125348\n",
            "train loss:0.00016368020182787684\n",
            "train loss:0.00011367782316554402\n",
            "train loss:0.0007770640678773004\n",
            "train loss:0.0008344985344652121\n",
            "train loss:0.00023507431695974748\n",
            "train loss:0.0016650196853569368\n",
            "train loss:0.0013789755982859906\n",
            "train loss:0.0018112196981517575\n",
            "train loss:0.0018479788045459823\n",
            "train loss:0.0019486268662624975\n",
            "train loss:0.0007325486791587686\n",
            "train loss:0.00048599984532281953\n",
            "train loss:0.0006201938462072951\n",
            "train loss:0.0027525053969588483\n",
            "train loss:0.0004450079020012223\n",
            "train loss:1.0081977419567973e-05\n",
            "train loss:0.00048704183555921114\n",
            "train loss:9.615770655044705e-05\n",
            "train loss:0.00036455964451793786\n",
            "train loss:0.0022003453209031086\n",
            "train loss:0.0005862396440506335\n",
            "train loss:0.00036297009650837665\n",
            "train loss:0.000984739125398478\n",
            "train loss:0.0005659436979335565\n",
            "train loss:0.000682450369836093\n",
            "train loss:0.0017587743214730984\n",
            "train loss:1.951368387120927e-05\n",
            "train loss:0.00020532345104672768\n",
            "train loss:0.0036874205916466235\n",
            "train loss:0.00034376733622384025\n",
            "train loss:0.00016169764327238597\n",
            "train loss:0.0003719672263311229\n",
            "train loss:0.00022063109813952184\n",
            "train loss:0.0008517282820543099\n",
            "train loss:0.000774476515224265\n",
            "train loss:0.0012086074763670417\n",
            "train loss:0.0014878410489403218\n",
            "train loss:0.016530237606020116\n",
            "train loss:0.0004530191445649751\n",
            "train loss:0.00034201841158595063\n",
            "train loss:0.0014115871087717665\n",
            "train loss:0.006360437021145642\n",
            "train loss:0.0002465280486975044\n",
            "train loss:0.002248779251830146\n",
            "train loss:0.0006563020044723219\n",
            "train loss:0.004215892423655946\n",
            "train loss:0.0006304058819063951\n",
            "train loss:0.0031740790407046105\n",
            "train loss:0.0004674293186777799\n",
            "train loss:0.0010232579668424625\n",
            "train loss:1.811823537034739e-05\n",
            "train loss:0.0005383273427883668\n",
            "train loss:0.00023145052776363473\n",
            "train loss:0.000692634106135106\n",
            "train loss:0.004279158319984807\n",
            "train loss:0.0010476796591998708\n",
            "train loss:0.00042957282359590537\n",
            "train loss:0.002091780732556256\n",
            "train loss:0.0001844236275316358\n",
            "train loss:0.00033913924784171045\n",
            "train loss:0.0007861790352395857\n",
            "train loss:0.0014452201401292622\n",
            "train loss:0.00023918502126775133\n",
            "train loss:0.0023259328182406182\n",
            "train loss:0.001426859358873034\n",
            "train loss:0.0012278233517890383\n",
            "train loss:0.0003355386394389418\n",
            "train loss:0.0005782591899609372\n",
            "train loss:0.0014109175106777729\n",
            "train loss:0.005760754874249295\n",
            "train loss:0.0008064085383261115\n",
            "train loss:0.00021398178137624284\n",
            "train loss:0.0032861719374463337\n",
            "train loss:0.003779186797522462\n",
            "train loss:0.0015914420873136522\n",
            "train loss:0.0002279340357043233\n",
            "train loss:0.0041924069990546394\n",
            "train loss:0.0012197569366251264\n",
            "train loss:0.0011003417202788811\n",
            "train loss:0.0034919113326842975\n",
            "train loss:4.8000779970531956e-05\n",
            "train loss:0.0032766249646153083\n",
            "train loss:0.0006619795628417302\n",
            "train loss:0.0017500613373166956\n",
            "train loss:0.002091709157446951\n",
            "train loss:0.0019955993960578226\n",
            "train loss:0.0013773882194036162\n",
            "train loss:0.0011152735606386065\n",
            "train loss:0.00034688017026174447\n",
            "train loss:0.00010503513997836942\n",
            "train loss:0.008227746536104547\n",
            "train loss:0.0002960629351510791\n",
            "train loss:0.00045400516254410795\n",
            "train loss:0.00047631195444569515\n",
            "train loss:0.00010256974101058488\n",
            "train loss:0.0017615077100344453\n",
            "train loss:0.0004923706505883005\n",
            "train loss:0.0004323556989797232\n",
            "train loss:0.00041956072837606836\n",
            "train loss:0.008236548422525249\n",
            "train loss:0.0011140338399336519\n",
            "train loss:0.00011273911614365184\n",
            "train loss:0.0004750621986380869\n",
            "train loss:0.0016649490380354556\n",
            "train loss:0.03490289320306245\n",
            "train loss:0.004755759433436875\n",
            "train loss:0.0013492431511802497\n",
            "train loss:0.0011208546745947318\n",
            "train loss:0.0001930888444695512\n",
            "train loss:0.0029459992602587875\n",
            "train loss:0.002663505263409448\n",
            "train loss:0.0019171052805027763\n",
            "train loss:0.00026806207889035585\n",
            "train loss:0.00014854820240319943\n",
            "train loss:0.0036023563245747544\n",
            "train loss:0.0011211016439543638\n",
            "train loss:0.0005971414710962922\n",
            "train loss:0.0017595092395852312\n",
            "train loss:0.0007009204643767335\n",
            "train loss:0.0026174997397494216\n",
            "train loss:0.0021673439398736897\n",
            "train loss:4.689554728510338e-05\n",
            "train loss:0.002477681723656573\n",
            "train loss:0.0013505198737978113\n",
            "train loss:0.004779423652094456\n",
            "train loss:0.001342586040278756\n",
            "train loss:0.0018207185233405712\n",
            "train loss:0.0006762357301553436\n",
            "train loss:0.0009417888421027301\n",
            "train loss:0.00040630493769449607\n",
            "train loss:0.000755108988473728\n",
            "train loss:0.00017410181454802174\n",
            "train loss:0.000664923193390807\n",
            "train loss:0.001993158675153848\n",
            "train loss:0.0006114932751587757\n",
            "train loss:0.0011580828707784944\n",
            "train loss:0.0006366059228741994\n",
            "train loss:0.00010186816511878039\n",
            "train loss:0.0004616135021145525\n",
            "train loss:0.003399407470675133\n",
            "train loss:0.002121045589250898\n",
            "train loss:0.007604340406746957\n",
            "train loss:0.00036919993987135713\n",
            "train loss:0.002680785514303497\n",
            "train loss:0.00020364138561559695\n",
            "train loss:4.31868949154428e-05\n",
            "train loss:0.005090904335380825\n",
            "train loss:0.00013404360599317727\n",
            "train loss:6.239527141513008e-05\n",
            "train loss:0.0026109219688577666\n",
            "train loss:0.0003877889544467461\n",
            "train loss:0.00020703151660012817\n",
            "train loss:9.622273339817784e-05\n",
            "train loss:0.0028857055467681903\n",
            "train loss:0.0004852992279090329\n",
            "train loss:0.005515571875820238\n",
            "train loss:0.00035440990185033473\n",
            "train loss:2.6543948387332547e-05\n",
            "train loss:0.0001136260151018031\n",
            "train loss:0.0008062931404492192\n",
            "train loss:0.0008979226773007655\n",
            "train loss:0.01519761971839537\n",
            "train loss:0.0006896216223333144\n",
            "train loss:0.0008518438465353661\n",
            "train loss:0.0014259674677694256\n",
            "train loss:0.00048995922844381\n",
            "train loss:0.00014243538287617524\n",
            "train loss:0.0007817323059755377\n",
            "train loss:0.000620514597500586\n",
            "train loss:0.0004887617611399169\n",
            "train loss:0.004346844861278586\n",
            "train loss:0.008940954589607489\n",
            "train loss:0.0001773631077594779\n",
            "train loss:0.0005293620854044278\n",
            "train loss:9.118174558406091e-05\n",
            "train loss:0.00018359645360524967\n",
            "train loss:0.00011917507941722658\n",
            "train loss:0.0013969323690479238\n",
            "train loss:0.0009826998461694466\n",
            "train loss:0.0008994350528392349\n",
            "train loss:0.00749184547748127\n",
            "train loss:0.0011418985682811976\n",
            "train loss:0.00565110010553168\n",
            "train loss:0.00038059729696357216\n",
            "train loss:0.0007882409363373495\n",
            "train loss:0.0009444157335076138\n",
            "train loss:0.0004466950381613223\n",
            "train loss:0.0003880982851400353\n",
            "train loss:0.00015769757380015623\n",
            "train loss:0.00020377255050641206\n",
            "train loss:0.0006438730495034414\n",
            "train loss:8.936240411350899e-05\n",
            "train loss:0.0006224400407768836\n",
            "train loss:0.0010326265542145016\n",
            "train loss:0.0025563459795548637\n",
            "train loss:0.001594073477979639\n",
            "train loss:0.002418255988142064\n",
            "train loss:0.0010357540636047762\n",
            "train loss:0.0006738470696056414\n",
            "train loss:0.004012265162723995\n",
            "train loss:0.00249129151493236\n",
            "train loss:0.0014704195902624675\n",
            "train loss:0.0007976286093309038\n",
            "train loss:0.0030710788657387906\n",
            "train loss:0.00034598002288563275\n",
            "train loss:0.0001764246688648951\n",
            "train loss:0.005639556421287982\n",
            "train loss:0.0012065429630597258\n",
            "train loss:0.0027875962327713767\n",
            "train loss:0.0025697172586472087\n",
            "train loss:0.0011409283711671298\n",
            "train loss:0.0007594400613162512\n",
            "train loss:9.501803363538303e-05\n",
            "train loss:0.00015784786253665679\n",
            "train loss:0.0034279364621652452\n",
            "train loss:0.0003029875326109579\n",
            "train loss:0.0019336926991549751\n",
            "train loss:0.00014962735574216524\n",
            "train loss:0.0008121005194267576\n",
            "train loss:0.00017577234489702984\n",
            "train loss:0.00045341464916203724\n",
            "train loss:0.0008278359006005589\n",
            "train loss:0.0006262314032559098\n",
            "train loss:0.0024025297860058984\n",
            "train loss:0.0003023447320948337\n",
            "train loss:0.0007966010715697242\n",
            "train loss:0.0017604757424743514\n",
            "train loss:0.0007674578512714785\n",
            "train loss:0.0003185987772412503\n",
            "train loss:0.0003573091053164201\n",
            "train loss:0.001063068903346786\n",
            "train loss:0.0018344852553565357\n",
            "train loss:0.0003862845941778214\n",
            "train loss:0.004060057839269589\n",
            "train loss:0.00046380258939651995\n",
            "train loss:0.00036268527642492935\n",
            "train loss:4.224973269306972e-05\n",
            "train loss:0.002239964737652259\n",
            "train loss:0.009081486146903593\n",
            "train loss:0.0010594257470064783\n",
            "train loss:0.0003542841564291834\n",
            "train loss:0.00024109389553924053\n",
            "train loss:0.002774150282817699\n",
            "train loss:0.00017226200355152465\n",
            "train loss:0.014264979963559967\n",
            "train loss:0.0009798693499443335\n",
            "train loss:0.0010802796068190145\n",
            "train loss:0.0012773567342201791\n",
            "train loss:0.00023644925292628702\n",
            "train loss:0.0004585948574197126\n",
            "train loss:0.0025886761585273517\n",
            "train loss:0.0008140899391790554\n",
            "train loss:0.00026402437793034687\n",
            "train loss:0.0006333144190851274\n",
            "train loss:0.002602657101270584\n",
            "train loss:0.00023173932159857471\n",
            "train loss:0.0020173660538831055\n",
            "train loss:0.0010338675743897182\n",
            "train loss:0.00037359614750107436\n",
            "train loss:0.0029634010142176015\n",
            "train loss:0.0005728277830142749\n",
            "train loss:0.0013474547859098534\n",
            "train loss:0.0033523249048686443\n",
            "train loss:0.00015724262486618599\n",
            "train loss:0.0004488336041422728\n",
            "train loss:0.0015925884471032822\n",
            "train loss:0.0003000415994694799\n",
            "train loss:0.0008485614754716419\n",
            "train loss:0.0007167094422829622\n",
            "train loss:0.0017542281663145353\n",
            "train loss:0.000735370220247486\n",
            "train loss:0.000528768199619186\n",
            "train loss:0.00018756947466795352\n",
            "train loss:0.0016236527998765944\n",
            "train loss:0.000943334630188525\n",
            "train loss:0.0005299182514484583\n",
            "train loss:0.0002726756152732732\n",
            "train loss:0.0007313732472485391\n",
            "train loss:0.00012777492302771574\n",
            "train loss:0.0016567597596456008\n",
            "train loss:0.001159943396422746\n",
            "train loss:0.0004863781483174033\n",
            "train loss:0.00046672114352368064\n",
            "train loss:0.0005680575315905167\n",
            "train loss:0.0004096671488143521\n",
            "train loss:0.00015253305241807124\n",
            "train loss:0.0006718020917475318\n",
            "train loss:0.0007276698881387722\n",
            "train loss:0.001960996431749919\n",
            "train loss:0.004813777976550816\n",
            "train loss:0.005766030056275683\n",
            "train loss:0.0001074443222297718\n",
            "train loss:0.0021255061002224034\n",
            "train loss:0.0006905733011143669\n",
            "train loss:0.0004744972135886129\n",
            "train loss:0.004031109158462929\n",
            "train loss:0.0010135076661670036\n",
            "train loss:0.0031036275468504654\n",
            "train loss:0.0006996572987269413\n",
            "train loss:0.001315335988157281\n",
            "train loss:0.001006960086217824\n",
            "train loss:0.004370836547423349\n",
            "train loss:0.00019046773870952415\n",
            "train loss:0.004037213952217874\n",
            "train loss:0.00014728200060904744\n",
            "train loss:0.00018613332464465803\n",
            "train loss:0.0014228372923583608\n",
            "train loss:0.012173921056295505\n",
            "train loss:0.0007699897109700854\n",
            "train loss:0.015252459389309176\n",
            "train loss:0.0013433049653061152\n",
            "train loss:0.0029523215098813584\n",
            "train loss:0.0001572055901071644\n",
            "train loss:0.00019786281964109445\n",
            "train loss:0.0011850789430729845\n",
            "train loss:0.0025624724670190173\n",
            "train loss:0.004429049002669069\n",
            "train loss:0.0013899703163451653\n",
            "train loss:0.0016464334133366226\n",
            "train loss:0.006985930308328236\n",
            "train loss:0.00013884466504330577\n",
            "train loss:0.0010245723138402804\n",
            "train loss:0.006760735227759176\n",
            "train loss:2.9488490303465356e-05\n",
            "train loss:0.005232445466776555\n",
            "train loss:0.001914542529976442\n",
            "train loss:0.0006494972313323759\n",
            "train loss:0.000744633946142588\n",
            "train loss:0.0028425380143428285\n",
            "train loss:0.00027526520985012557\n",
            "train loss:0.0015467664208419776\n",
            "train loss:0.007596615638921378\n",
            "train loss:3.265380906044924e-05\n",
            "train loss:0.002251794949206071\n",
            "train loss:0.0017846523065496547\n",
            "train loss:0.03100721525050581\n",
            "train loss:0.001263249826488895\n",
            "train loss:0.000810571334824311\n",
            "train loss:0.018499036373096044\n",
            "train loss:0.0008952702029194269\n",
            "train loss:0.0010940937219538738\n",
            "train loss:0.0007685365946014267\n",
            "train loss:0.0003277372146703136\n",
            "train loss:0.001055061425131268\n",
            "train loss:0.00039343342033184637\n",
            "train loss:0.000707145113864114\n",
            "train loss:0.0003836092403036908\n",
            "train loss:0.0015837670035961492\n",
            "train loss:0.0006355711389436573\n",
            "train loss:3.328213415194394e-05\n",
            "train loss:0.0012384611982705154\n",
            "train loss:0.0019765234290794183\n",
            "train loss:0.00040200924254981985\n",
            "train loss:0.003003649022396937\n",
            "train loss:0.00012613558513248824\n",
            "train loss:0.00025805385220092534\n",
            "train loss:0.001522345961812636\n",
            "train loss:0.0008050735700078307\n",
            "train loss:0.0006387589284330964\n",
            "train loss:0.0007679944449510444\n",
            "train loss:0.0021556331437027274\n",
            "train loss:0.01829735109301543\n",
            "train loss:4.8865919163060396e-05\n",
            "train loss:0.00020912568883641198\n",
            "train loss:0.003731522864530807\n",
            "train loss:0.0004873953775039028\n",
            "train loss:0.001943103742248115\n",
            "train loss:0.00016567549977728247\n",
            "train loss:0.0013343531736816957\n",
            "train loss:0.0005648050649761248\n",
            "train loss:0.0005716387892244514\n",
            "train loss:0.0007130709759727808\n",
            "train loss:0.003563096854425706\n",
            "train loss:0.0004974797651391517\n",
            "train loss:0.00011298663743190841\n",
            "train loss:0.0010686243985070809\n",
            "train loss:0.0031668481903489344\n",
            "train loss:0.005581667639420913\n",
            "train loss:0.0019547681471176553\n",
            "train loss:0.0008645196681998556\n",
            "train loss:0.002522761124440042\n",
            "train loss:0.000828051528873954\n",
            "train loss:0.00017080312577912\n",
            "train loss:0.002226325686495302\n",
            "train loss:0.000956487698972153\n",
            "train loss:0.0010951910435134037\n",
            "train loss:0.0011978454435312997\n",
            "train loss:0.0009664807262918615\n",
            "train loss:0.0020757750519391914\n",
            "train loss:0.0006072126633487086\n",
            "train loss:0.0005903200851095494\n",
            "train loss:0.0008447560290060688\n",
            "train loss:0.00024053275677551775\n",
            "train loss:0.00016892924938681158\n",
            "train loss:0.00011670825785918457\n",
            "train loss:3.942071623434383e-05\n",
            "train loss:0.00126147245741161\n",
            "train loss:0.0007845776172889903\n",
            "train loss:0.0003509263965454513\n",
            "train loss:0.0005076984894212619\n",
            "train loss:0.00033643625767827164\n",
            "train loss:0.0008676892552003207\n",
            "train loss:0.016169781721146942\n",
            "train loss:0.00044451100153983936\n",
            "train loss:0.001686796654273368\n",
            "train loss:0.0004777579531715277\n",
            "train loss:0.00019141054564836635\n",
            "train loss:0.0006425267542018657\n",
            "train loss:0.0007715915941261541\n",
            "train loss:0.001681552079030205\n",
            "train loss:5.5482600094337315e-05\n",
            "train loss:0.0011687849612787848\n",
            "train loss:0.005344895394338898\n",
            "train loss:0.00013929522977586928\n",
            "train loss:0.003153669123627535\n",
            "train loss:0.0005720655861581317\n",
            "train loss:0.00032407438793581356\n",
            "train loss:0.0009391415702732498\n",
            "train loss:0.0008807742419563278\n",
            "train loss:0.002086694527902406\n",
            "train loss:0.0036813054736579997\n",
            "train loss:0.001375635785624263\n",
            "train loss:7.63215883914507e-05\n",
            "train loss:5.805460517173278e-05\n",
            "train loss:0.00343591282248184\n",
            "train loss:8.09766160427354e-05\n",
            "train loss:0.00022650244491425096\n",
            "train loss:0.0002565507622645483\n",
            "train loss:0.000244856995244812\n",
            "train loss:0.001556012471381673\n",
            "train loss:6.485468951642489e-05\n",
            "train loss:2.551886587050109e-05\n",
            "train loss:0.00021771134837379635\n",
            "train loss:0.00012830851951990745\n",
            "train loss:0.000728363215870309\n",
            "train loss:0.0014602785981711432\n",
            "train loss:3.2364593481124254e-05\n",
            "train loss:0.0014299756396392803\n",
            "train loss:0.0009244692880998397\n",
            "train loss:3.0981473359514536e-05\n",
            "train loss:0.00013239025962328419\n",
            "train loss:0.0014136333413610988\n",
            "train loss:0.0006902138937266876\n",
            "train loss:0.0008799883572747433\n",
            "train loss:0.001724915979236446\n",
            "train loss:0.003439271511444081\n",
            "train loss:0.0008965223194230642\n",
            "train loss:0.003814494322684669\n",
            "train loss:0.00044357846686395567\n",
            "train loss:0.00014996586485700812\n",
            "train loss:2.340971302223536e-05\n",
            "train loss:0.0004001398360229384\n",
            "train loss:0.0026172455327841716\n",
            "train loss:4.138934543001094e-05\n",
            "train loss:5.01016332038511e-06\n",
            "train loss:0.037175369674410715\n",
            "train loss:0.001190787772366039\n",
            "train loss:0.002350725278465917\n",
            "train loss:0.0004616733475726333\n",
            "train loss:0.002153511624302247\n",
            "train loss:0.00032544370364200764\n",
            "train loss:0.002252501212056056\n",
            "train loss:0.0019027996821321701\n",
            "train loss:0.000783408346779921\n",
            "train loss:0.0002795842864966354\n",
            "train loss:0.0003266911644294013\n",
            "train loss:0.0011152553136237239\n",
            "train loss:0.0006991078252138566\n",
            "train loss:0.003554783307905916\n",
            "train loss:0.00021078209185402364\n",
            "train loss:5.3457750249817e-05\n",
            "train loss:0.027485356795539092\n",
            "train loss:0.0007689440968496239\n",
            "train loss:0.00040422007256245057\n",
            "train loss:0.0004937881066958469\n",
            "train loss:0.0006609019133144308\n",
            "train loss:2.778425317633695e-05\n",
            "train loss:0.0001429297598682025\n",
            "train loss:0.00028741690800821926\n",
            "train loss:0.0018058931026508408\n",
            "train loss:0.0016253213487892383\n",
            "train loss:5.0742809404849476e-05\n",
            "train loss:0.0007334178013694494\n",
            "train loss:0.00014061274156565356\n",
            "train loss:0.0014507996295721152\n",
            "train loss:7.287940419255951e-05\n",
            "train loss:0.0010249857910947094\n",
            "train loss:0.0001865428770176666\n",
            "train loss:0.002440037994675103\n",
            "train loss:0.0016534383279779078\n",
            "train loss:0.0002226797092907501\n",
            "train loss:0.00019880138243660316\n",
            "train loss:0.00015055778183735384\n",
            "train loss:0.00028142456522562884\n",
            "train loss:0.001219322071397644\n",
            "train loss:0.0002639682759048885\n",
            "train loss:0.00015091858204282753\n",
            "train loss:0.0006688501871626748\n",
            "train loss:0.0002471967364787855\n",
            "train loss:7.148398462456627e-05\n",
            "train loss:0.00018821523460338364\n",
            "train loss:0.0010307585100093094\n",
            "train loss:0.0003190254983734236\n",
            "train loss:0.00036973501482923007\n",
            "train loss:0.0008595988580065046\n",
            "train loss:0.0006804069183249454\n",
            "train loss:0.003512511195845237\n",
            "train loss:0.0008793506635664808\n",
            "train loss:4.045672859145358e-05\n",
            "train loss:0.00029450076452186764\n",
            "train loss:0.0010603738640600905\n",
            "train loss:0.0004462922566476151\n",
            "train loss:0.0003809113533252414\n",
            "train loss:0.0004281944303040925\n",
            "train loss:0.00017888007564887575\n",
            "train loss:3.626773459695798e-05\n",
            "train loss:0.0031251144123496037\n",
            "train loss:0.00013234869192841212\n",
            "train loss:0.0009718034957463083\n",
            "train loss:0.00015734451405912336\n",
            "train loss:4.0666712598797454e-05\n",
            "train loss:0.0020026301124397516\n",
            "train loss:9.830753621902093e-05\n",
            "train loss:0.0005964458928262652\n",
            "train loss:6.470271932535421e-05\n",
            "train loss:0.001138733939580655\n",
            "train loss:0.00035263448859378094\n",
            "train loss:0.00044934809671600074\n",
            "train loss:0.003233036325582201\n",
            "train loss:0.0013554737168340126\n",
            "train loss:0.0001259415187473507\n",
            "train loss:0.0006493660268394755\n",
            "train loss:0.0006082656835380106\n",
            "train loss:6.436827753318219e-05\n",
            "train loss:0.0002311109929346616\n",
            "train loss:2.450246366166262e-05\n",
            "train loss:0.0002581944485826732\n",
            "train loss:0.00022682396935150121\n",
            "train loss:0.0006646754626896082\n",
            "train loss:0.0004059610812839051\n",
            "train loss:0.0026886709658365043\n",
            "train loss:0.0008014847749413917\n",
            "train loss:0.011722244467964459\n",
            "train loss:0.0009876459900216646\n",
            "train loss:8.569653597304428e-05\n",
            "train loss:0.002422674720732018\n",
            "train loss:0.0018653594418230443\n",
            "train loss:0.0008864420655678832\n",
            "train loss:0.002000059596207566\n",
            "train loss:0.0007297652844858688\n",
            "train loss:0.0009172115471432322\n",
            "train loss:0.0017281192840049695\n",
            "train loss:0.0014102288020411172\n",
            "train loss:0.0015047844647290511\n",
            "train loss:0.0009233701160222085\n",
            "train loss:0.0009050926468522579\n",
            "train loss:0.0006461695151473455\n",
            "train loss:0.00043692263715003495\n",
            "train loss:0.00014631106199179347\n",
            "train loss:0.0036638357502448275\n",
            "train loss:4.118520858561708e-05\n",
            "train loss:0.001067830869766616\n",
            "train loss:0.001198891504583697\n",
            "train loss:0.00041987057898598885\n",
            "train loss:0.00031175488662024534\n",
            "train loss:0.007209411033154921\n",
            "train loss:0.001804987970195647\n",
            "train loss:0.002032652064472032\n",
            "train loss:0.00011485580575273315\n",
            "train loss:0.0015620796854380764\n",
            "=== epoch:20, train acc:0.999, test acc:0.991 ===\n",
            "train loss:7.66730373882918e-05\n",
            "train loss:0.0006248486542127251\n",
            "train loss:0.001857102133805826\n",
            "train loss:0.002129135876164445\n",
            "train loss:5.05613458779132e-05\n",
            "train loss:0.003887638849597778\n",
            "train loss:0.0020115107507759724\n",
            "train loss:0.0006406219428919394\n",
            "train loss:0.00010961136391786042\n",
            "train loss:0.001084019797870671\n",
            "train loss:0.0002660657399724518\n",
            "train loss:8.539787836925837e-05\n",
            "train loss:0.0002760546770972905\n",
            "train loss:3.7294823625308755e-05\n",
            "train loss:0.004337339777620275\n",
            "train loss:0.00029382491805791873\n",
            "train loss:0.0002915748369384276\n",
            "train loss:5.052925166532176e-05\n",
            "train loss:0.0012914972871318747\n",
            "train loss:0.0009440130903297963\n",
            "train loss:0.0023344805486957216\n",
            "train loss:0.0007645388719482272\n",
            "train loss:0.003121936427683648\n",
            "train loss:3.146637536844251e-05\n",
            "train loss:0.0012932310330402241\n",
            "train loss:0.003331091633589543\n",
            "train loss:0.01885189784075869\n",
            "train loss:0.00032572062616237807\n",
            "train loss:0.00040934193824129024\n",
            "train loss:0.0063581322771768915\n",
            "train loss:0.001914639331420446\n",
            "train loss:0.0008070092983802421\n",
            "train loss:0.001291073007117974\n",
            "train loss:0.00019721785375516744\n",
            "train loss:0.0028412782968979876\n",
            "train loss:0.0003592936909198609\n",
            "train loss:0.0011343912663235333\n",
            "train loss:0.0010010606630797179\n",
            "train loss:0.0001320221453978056\n",
            "train loss:0.0016771044209108507\n",
            "train loss:0.0004135527918179111\n",
            "train loss:0.00025731840556642157\n",
            "train loss:0.002548154975285998\n",
            "train loss:0.0009708589542146539\n",
            "train loss:0.000584934420782983\n",
            "train loss:0.002242445778235617\n",
            "train loss:0.0008197216361981808\n",
            "train loss:0.00020814831818189716\n",
            "train loss:0.008468751500378529\n",
            "train loss:0.0010933959085349136\n",
            "train loss:0.00011428268869698495\n",
            "train loss:0.009897005913239507\n",
            "train loss:0.00484102296958935\n",
            "train loss:0.0016695740713093491\n",
            "train loss:0.00021191765280679543\n",
            "train loss:0.00020432800350419348\n",
            "train loss:0.0004672714275687745\n",
            "train loss:0.0018517544648519553\n",
            "train loss:2.8338851411910032e-05\n",
            "train loss:0.0014533212812560391\n",
            "train loss:0.0010179503284639543\n",
            "train loss:0.00018608607563195878\n",
            "train loss:0.00040681350389555615\n",
            "train loss:0.003145662326434749\n",
            "train loss:6.598577451797558e-05\n",
            "train loss:0.0009209472853994608\n",
            "train loss:0.005219865351489981\n",
            "train loss:0.00044093469086263644\n",
            "train loss:0.00024191060847378703\n",
            "train loss:0.00047313201564649443\n",
            "train loss:0.00018504374883026036\n",
            "train loss:0.0012991323356811681\n",
            "train loss:3.1741478138236604e-05\n",
            "train loss:0.0003959225785892528\n",
            "train loss:0.0022930005629657624\n",
            "train loss:0.001086712403049933\n",
            "train loss:4.6133070281491036e-05\n",
            "train loss:0.00044048723061671435\n",
            "train loss:0.0007021198988942132\n",
            "train loss:0.0008122944042258061\n",
            "train loss:0.0011030934831256203\n",
            "train loss:0.00030258406503961074\n",
            "train loss:0.002263811000292156\n",
            "train loss:0.0003793182088517335\n",
            "train loss:0.0007065237906325628\n",
            "train loss:0.001020023217792987\n",
            "train loss:0.000366450756948098\n",
            "train loss:0.0012100684730666903\n",
            "train loss:0.0023847280527087497\n",
            "train loss:0.001638453928875212\n",
            "train loss:0.003426556154909408\n",
            "train loss:0.0021888160248562955\n",
            "train loss:0.00021171015653323965\n",
            "train loss:3.52778748818873e-05\n",
            "train loss:0.00045474920162487343\n",
            "train loss:0.0020503479924769224\n",
            "train loss:7.132958310245713e-05\n",
            "train loss:0.0015749350885334635\n",
            "train loss:0.00046447815716326997\n",
            "train loss:0.0013175038859683935\n",
            "train loss:0.0014863955822286825\n",
            "train loss:8.829755837968248e-05\n",
            "train loss:0.0010818881606011422\n",
            "train loss:0.0018305951594091265\n",
            "train loss:0.00015734602708980712\n",
            "train loss:0.0007675551386967392\n",
            "train loss:0.00040637944069824966\n",
            "train loss:0.0017619966382123233\n",
            "train loss:0.003520759286227966\n",
            "train loss:0.0006415149967376239\n",
            "train loss:0.000252402347240808\n",
            "train loss:0.000703117958817452\n",
            "train loss:0.0002680876904125955\n",
            "train loss:0.0002853394362425234\n",
            "train loss:0.00021087981792992526\n",
            "train loss:0.00023317139210791377\n",
            "train loss:0.0007339089337863546\n",
            "train loss:1.1436520068592295e-05\n",
            "train loss:0.00017603840939438382\n",
            "train loss:0.0019465511752453913\n",
            "train loss:0.00041218046877029347\n",
            "train loss:0.00020748997465247932\n",
            "train loss:0.0021497592050045418\n",
            "train loss:0.0004269247004338592\n",
            "train loss:0.00018335507214859158\n",
            "train loss:0.0022047665821460093\n",
            "train loss:0.003953097402080635\n",
            "train loss:0.00040759802313861457\n",
            "train loss:0.002366929600339724\n",
            "train loss:0.0008556573980636641\n",
            "train loss:0.0009530844578001435\n",
            "train loss:0.0010641617687173956\n",
            "train loss:0.00018572742373076907\n",
            "train loss:0.0029758689723704008\n",
            "train loss:0.0009344758013198229\n",
            "train loss:0.0020846072848578505\n",
            "train loss:0.0015182360135076393\n",
            "train loss:6.130800698026697e-05\n",
            "train loss:0.00015028544241234092\n",
            "train loss:0.0016495719532080419\n",
            "train loss:0.00018995237827749653\n",
            "train loss:0.001527789967737224\n",
            "train loss:3.1150811844128603e-05\n",
            "train loss:0.0005882010742609204\n",
            "train loss:0.017425835285323103\n",
            "train loss:0.00018559626348050863\n",
            "train loss:0.0006554935630086193\n",
            "train loss:8.557908233929404e-05\n",
            "train loss:0.0020069908498271936\n",
            "train loss:0.0003735601402177789\n",
            "train loss:0.0029842570616552904\n",
            "train loss:0.0004428142952240899\n",
            "train loss:0.000648702807182584\n",
            "train loss:0.00032100525707913003\n",
            "train loss:0.001204542428080074\n",
            "train loss:0.0067623410047530155\n",
            "train loss:0.00046034646467990706\n",
            "train loss:0.0017124314844186958\n",
            "train loss:0.0007153123610402036\n",
            "train loss:0.0015148580821150864\n",
            "train loss:0.0022582717511476333\n",
            "train loss:0.0022081796627277804\n",
            "train loss:0.0003367186589029553\n",
            "train loss:0.0015741295303151421\n",
            "train loss:0.0005042865242446083\n",
            "train loss:0.0007425688361157931\n",
            "train loss:0.00159069480289514\n",
            "train loss:0.025100928100384827\n",
            "train loss:6.635167040097062e-05\n",
            "train loss:0.0013918116540684942\n",
            "train loss:0.003015199215979951\n",
            "train loss:3.4331797518562414e-05\n",
            "train loss:0.0004256000696239698\n",
            "train loss:0.0016474965119923574\n",
            "train loss:0.00014166092142070267\n",
            "train loss:0.005610468431306402\n",
            "train loss:0.0002576426683350712\n",
            "train loss:0.00018892890656282822\n",
            "train loss:0.0017455884646866552\n",
            "train loss:0.00039741907631378004\n",
            "train loss:0.0011347898708335483\n",
            "train loss:0.0006700601792140061\n",
            "train loss:2.3605871127356416e-05\n",
            "train loss:0.0023857389844230757\n",
            "train loss:0.011350900675376339\n",
            "train loss:0.0031693257739364745\n",
            "train loss:7.56311688052948e-05\n",
            "train loss:4.0503915300047135e-05\n",
            "train loss:0.0003170248177319776\n",
            "train loss:0.003109952097872472\n",
            "train loss:0.00015237660693880726\n",
            "train loss:0.0005252168385521075\n",
            "train loss:0.004241289051745237\n",
            "train loss:0.0011122082305222599\n",
            "train loss:0.00311529838448466\n",
            "train loss:0.009847604601251711\n",
            "train loss:0.006991619415213982\n",
            "train loss:0.0009125907635122244\n",
            "train loss:0.004035157467766772\n",
            "train loss:0.002499595944816335\n",
            "train loss:0.000732186150457261\n",
            "train loss:0.001113943200893515\n",
            "train loss:0.003432123136363228\n",
            "train loss:0.0009551405487350676\n",
            "train loss:0.012029471460049658\n",
            "train loss:0.0018517128985258184\n",
            "train loss:0.0001011336702134654\n",
            "train loss:7.339241038359231e-05\n",
            "train loss:0.0006961847199231341\n",
            "train loss:0.0003644666552457131\n",
            "train loss:0.00025883719349182444\n",
            "train loss:0.0040416917474694085\n",
            "train loss:0.0025567719581361236\n",
            "train loss:0.0017725817091538588\n",
            "train loss:0.00010329565827544383\n",
            "train loss:0.012741611484746585\n",
            "train loss:0.00026848855030725744\n",
            "train loss:0.00484717896407903\n",
            "train loss:0.0003478047323886776\n",
            "train loss:0.0026281809332658283\n",
            "train loss:0.0008710065377075879\n",
            "train loss:0.0004519543617142894\n",
            "train loss:0.0011431126629631696\n",
            "train loss:0.010659223032959938\n",
            "train loss:0.001530133190207566\n",
            "train loss:0.0009974729398369868\n",
            "train loss:4.566398416479045e-05\n",
            "train loss:0.0005692335899123417\n",
            "train loss:0.001867209761089819\n",
            "train loss:0.0002059189538343069\n",
            "train loss:0.0008536935876563145\n",
            "train loss:3.361003112647167e-05\n",
            "train loss:0.0025522239837995698\n",
            "train loss:0.001843549030042632\n",
            "train loss:0.0018352786195662573\n",
            "train loss:0.0005843820591811925\n",
            "train loss:0.0010029413491309262\n",
            "train loss:0.0003540354668015548\n",
            "train loss:0.0001908692643590498\n",
            "train loss:0.0005997235570397616\n",
            "train loss:0.00019263036667994333\n",
            "train loss:0.0004786431157165386\n",
            "train loss:0.0022745486740716964\n",
            "train loss:0.0009197804457447805\n",
            "train loss:0.0003856627198626646\n",
            "train loss:0.0010064470800122357\n",
            "train loss:0.0006250168612653953\n",
            "train loss:0.0003378540447402963\n",
            "train loss:0.00013923385123434373\n",
            "train loss:0.0013846611572057713\n",
            "train loss:0.00034797033631947847\n",
            "train loss:0.00024632048674526086\n",
            "train loss:0.0006351101663455407\n",
            "train loss:0.0006988869858039876\n",
            "train loss:0.00019417636462927621\n",
            "train loss:0.00025194073602504856\n",
            "train loss:0.0003016445607059273\n",
            "train loss:8.216572960128584e-05\n",
            "train loss:0.00046029965525574165\n",
            "train loss:0.001676454504357718\n",
            "train loss:0.007952293270279407\n",
            "train loss:0.00010828742882995538\n",
            "train loss:0.0027466660848686104\n",
            "train loss:0.0004799695368018287\n",
            "train loss:0.0004579185360495266\n",
            "train loss:0.00187469535036991\n",
            "train loss:0.0016697153268241823\n",
            "train loss:0.002888642563990145\n",
            "train loss:0.0011607950620865547\n",
            "train loss:0.00020886736410652594\n",
            "train loss:0.0019144186485301742\n",
            "train loss:0.00021647263816512512\n",
            "train loss:0.0016145556052243586\n",
            "train loss:0.00036896160125630235\n",
            "train loss:0.00029292144134504067\n",
            "train loss:0.0041081227727708105\n",
            "train loss:7.73343973480237e-05\n",
            "train loss:0.00048720447189177244\n",
            "train loss:0.0011334701201900015\n",
            "train loss:0.0022039275580789043\n",
            "train loss:0.0010958534792894672\n",
            "train loss:0.00011900799366383589\n",
            "train loss:0.00042839554973028514\n",
            "train loss:0.0034971801759940586\n",
            "train loss:0.0003319407234680657\n",
            "train loss:0.0016638376932165853\n",
            "train loss:0.008185183323926364\n",
            "train loss:0.001862871834701546\n",
            "train loss:0.00030168342261022423\n",
            "train loss:0.0012935863646334864\n",
            "train loss:8.929083007305002e-05\n",
            "train loss:0.0023007885014359477\n",
            "train loss:0.00024632678066100974\n",
            "train loss:0.00034929510230342984\n",
            "train loss:5.499009332761453e-05\n",
            "train loss:0.0001825371573893092\n",
            "train loss:7.158853100672974e-05\n",
            "train loss:0.0002642765537357567\n",
            "train loss:0.00033996836209065136\n",
            "train loss:0.002155405205652901\n",
            "train loss:0.00033992614285187713\n",
            "train loss:2.9834436720425386e-05\n",
            "train loss:0.0014003554479044892\n",
            "train loss:0.0004996781362814183\n",
            "train loss:0.0018431080876143253\n",
            "train loss:0.00010268883520211952\n",
            "train loss:0.0007867760642978429\n",
            "train loss:3.666825040430132e-05\n",
            "train loss:0.00010913762243009571\n",
            "train loss:0.000506054120547019\n",
            "train loss:0.0006621885767649005\n",
            "train loss:0.002163851407027391\n",
            "train loss:0.0018677080784368825\n",
            "train loss:0.003943470399925032\n",
            "train loss:0.002177822370944456\n",
            "train loss:3.426277377924238e-05\n",
            "train loss:0.006931564562139849\n",
            "train loss:3.190327676641901e-05\n",
            "train loss:7.650706961233187e-05\n",
            "train loss:0.0009132868372839537\n",
            "train loss:3.591831525864999e-05\n",
            "train loss:0.0013958842539506591\n",
            "train loss:7.346061502249424e-05\n",
            "train loss:8.728666159611213e-05\n",
            "train loss:0.0009088841006683975\n",
            "train loss:6.001701531315679e-05\n",
            "train loss:0.0006830444333597567\n",
            "train loss:0.0018440398787391379\n",
            "train loss:0.0002244759724486199\n",
            "train loss:0.004439733455107222\n",
            "train loss:0.0031033786075082416\n",
            "train loss:0.00038852728628270815\n",
            "train loss:0.001056412744989871\n",
            "train loss:0.002155926293250308\n",
            "train loss:0.0012043528748437342\n",
            "train loss:0.00897858835493292\n",
            "train loss:0.008054634371758464\n",
            "train loss:0.003043482183244128\n",
            "train loss:8.281448719786996e-05\n",
            "train loss:0.001275984874932277\n",
            "train loss:0.000413662566876555\n",
            "train loss:0.0003632054669336484\n",
            "train loss:0.00015096839447609303\n",
            "train loss:0.00014098701043079793\n",
            "train loss:8.929396964814728e-05\n",
            "train loss:0.0053602394187979895\n",
            "train loss:0.0012709847015144992\n",
            "train loss:0.002282062637070012\n",
            "train loss:0.0007713748518975185\n",
            "train loss:0.00010386743668868571\n",
            "train loss:0.0076348841898671305\n",
            "train loss:5.4627565787717876e-05\n",
            "train loss:0.0004684209536074542\n",
            "train loss:0.00031540269062916367\n",
            "train loss:0.015648673011919065\n",
            "train loss:5.6170275330981395e-05\n",
            "train loss:0.00028465287448343725\n",
            "train loss:0.001282438928933116\n",
            "train loss:0.0015502352229080205\n",
            "train loss:0.0003519116214987393\n",
            "train loss:0.0006714069773720533\n",
            "train loss:6.761941624611757e-05\n",
            "train loss:0.0016723735330580426\n",
            "train loss:0.0003097270550610777\n",
            "train loss:0.011245355015403236\n",
            "train loss:0.004094736525082121\n",
            "train loss:0.0043563019888433014\n",
            "train loss:0.0002793561296688793\n",
            "train loss:0.00015632909995287722\n",
            "train loss:0.0020231574366201756\n",
            "train loss:0.000929891002472005\n",
            "train loss:0.0014007197312345474\n",
            "train loss:0.001070579830004174\n",
            "train loss:0.0009545297214089615\n",
            "train loss:0.00015918472722196766\n",
            "train loss:0.0013109371803448238\n",
            "train loss:1.8108787349575356e-05\n",
            "train loss:0.00024019376075094605\n",
            "train loss:0.0010545460163862651\n",
            "train loss:4.6380462806505237e-05\n",
            "train loss:0.0007783426158736911\n",
            "train loss:7.10097822290199e-05\n",
            "train loss:5.8590071767601295e-05\n",
            "train loss:0.0010390249487297657\n",
            "train loss:0.0008870041357189482\n",
            "train loss:0.0010598644782567012\n",
            "train loss:0.00011823104837794348\n",
            "train loss:0.0009198725271364895\n",
            "train loss:0.00017560383872299495\n",
            "train loss:0.00016149653081828767\n",
            "train loss:0.0023157782891622463\n",
            "train loss:0.0001358383827897174\n",
            "train loss:0.0009647488825597515\n",
            "train loss:0.00030108445034343335\n",
            "train loss:0.00037257491570045624\n",
            "train loss:0.001006908856498316\n",
            "train loss:0.001410233153026604\n",
            "train loss:0.00024829716792244545\n",
            "train loss:4.989458680565095e-06\n",
            "train loss:0.00020785151798771796\n",
            "train loss:0.000589135707546722\n",
            "train loss:2.599477083052974e-05\n",
            "train loss:8.826701800982715e-05\n",
            "train loss:0.00014397697362311633\n",
            "train loss:0.00045768065075643016\n",
            "train loss:0.0003683273590319006\n",
            "train loss:0.0002443029306574903\n",
            "train loss:0.0006098333638325125\n",
            "train loss:0.0003579393534124508\n",
            "train loss:8.871713359672243e-05\n",
            "train loss:0.0007165086010773702\n",
            "train loss:0.0009339797621144365\n",
            "train loss:0.0005203190154798118\n",
            "train loss:0.00022162968440372595\n",
            "train loss:5.257357616981112e-06\n",
            "train loss:0.0007164285828476638\n",
            "train loss:4.828521664654654e-05\n",
            "train loss:0.0038307787910882587\n",
            "train loss:6.230702706512892e-05\n",
            "train loss:0.00019419148060793474\n",
            "train loss:0.0009385850160572856\n",
            "train loss:0.00046480968284395385\n",
            "train loss:0.00023800685181522304\n",
            "train loss:0.0002590460922758454\n",
            "train loss:0.0005315062021464209\n",
            "train loss:0.0005451932187004538\n",
            "train loss:0.00018945399771335306\n",
            "train loss:0.00034367803708261946\n",
            "train loss:0.0010458597703451634\n",
            "train loss:0.0006078521140207\n",
            "train loss:5.1774845196387354e-05\n",
            "train loss:0.0017510729123386556\n",
            "train loss:0.0018599596395222754\n",
            "train loss:0.00022123170446812542\n",
            "train loss:6.07027874360318e-05\n",
            "train loss:0.000995609260060009\n",
            "train loss:9.994742268244807e-06\n",
            "train loss:0.0004562025861057845\n",
            "train loss:0.001943355246996686\n",
            "train loss:0.001432689501644938\n",
            "train loss:6.52600238321411e-05\n",
            "train loss:0.0010579860167061967\n",
            "train loss:0.00010913858613562502\n",
            "train loss:0.00013512685095360351\n",
            "train loss:0.0002840379311899935\n",
            "train loss:0.0002288089684449788\n",
            "train loss:0.00034216356355261916\n",
            "train loss:0.00013732308611709196\n",
            "train loss:5.6968960239281224e-05\n",
            "train loss:3.7567197712234844e-05\n",
            "train loss:9.046835213039692e-05\n",
            "train loss:0.00032903019543458416\n",
            "train loss:0.0001287581869428161\n",
            "train loss:0.0013587103675282279\n",
            "train loss:0.007416661473895723\n",
            "train loss:0.00114027847654137\n",
            "train loss:0.000850751522303942\n",
            "train loss:0.0010081275325583517\n",
            "train loss:0.0007678563736036901\n",
            "train loss:1.2399443762930568e-05\n",
            "train loss:0.0003883490384536806\n",
            "train loss:0.00011650077739451505\n",
            "train loss:0.003606542696997136\n",
            "train loss:0.00042858074094226167\n",
            "train loss:2.564416287099613e-05\n",
            "train loss:0.0006084416457942305\n",
            "train loss:0.0005761306453124858\n",
            "train loss:2.504290584474639e-05\n",
            "train loss:0.005671878457807854\n",
            "train loss:0.00451443196897806\n",
            "train loss:0.00020529338726838042\n",
            "train loss:3.426693343772696e-05\n",
            "train loss:0.0005721357643721642\n",
            "train loss:0.00042934548946503386\n",
            "train loss:0.023530452866658055\n",
            "train loss:0.0007259008128652\n",
            "train loss:0.0004032997894212921\n",
            "train loss:0.0013312373718014129\n",
            "train loss:1.087326098396104e-05\n",
            "train loss:0.001798885237387877\n",
            "train loss:0.003330800934631303\n",
            "train loss:0.005483997137663443\n",
            "train loss:5.473746323724185e-05\n",
            "train loss:0.003294258349625775\n",
            "train loss:0.00012880584833563572\n",
            "train loss:0.009033333333546197\n",
            "train loss:0.0012750009575540832\n",
            "train loss:0.0009460971748558486\n",
            "train loss:0.0007144842718133354\n",
            "train loss:0.001723356658489513\n",
            "train loss:0.001118186035078846\n",
            "train loss:0.0011687632160940153\n",
            "train loss:0.0016601920372239843\n",
            "train loss:0.0016833854089985092\n",
            "train loss:0.0031098033896148204\n",
            "train loss:0.0027499252693093086\n",
            "train loss:0.001119604371428486\n",
            "train loss:0.0007391089338901467\n",
            "train loss:0.0017895893087400527\n",
            "train loss:0.0026212913394016678\n",
            "train loss:0.0014476969569852188\n",
            "train loss:0.000515570126432451\n",
            "train loss:0.00014171354328149278\n",
            "train loss:0.0006352284979888956\n",
            "train loss:0.001205674765121227\n",
            "train loss:0.009409628370965359\n",
            "train loss:0.0015628639203616288\n",
            "train loss:0.010663905512267272\n",
            "train loss:0.0021461718094232776\n",
            "train loss:0.0017825947625423385\n",
            "train loss:0.0001327011321044265\n",
            "train loss:0.00010298157459974274\n",
            "train loss:0.022122097567100135\n",
            "train loss:0.0015759006452492398\n",
            "train loss:0.0004518578650354348\n",
            "train loss:0.003198885082185109\n",
            "train loss:0.0002730692957204536\n",
            "train loss:0.003061841339863716\n",
            "train loss:0.00021113706919825766\n",
            "train loss:0.006288725564958615\n",
            "train loss:0.0011292832524467033\n",
            "train loss:0.001486239332662235\n",
            "train loss:0.006117019184059039\n",
            "train loss:0.0005845487887630453\n",
            "train loss:0.030955588998470073\n",
            "train loss:9.059429222345955e-05\n",
            "train loss:0.0008855758471106162\n",
            "train loss:0.009058328896539854\n",
            "train loss:0.0038735391896512423\n",
            "train loss:0.0026361584874889242\n",
            "train loss:0.0002926101727323379\n",
            "train loss:0.0003954855320843477\n",
            "train loss:0.002417542180359231\n",
            "train loss:0.00321805264764454\n",
            "train loss:0.004954631638940124\n",
            "train loss:0.0008727354784431788\n",
            "train loss:0.0008223560055489548\n",
            "train loss:0.004917973814328438\n",
            "train loss:4.938313234216656e-05\n",
            "train loss:0.00264441019766428\n",
            "train loss:0.004185980976680571\n",
            "train loss:0.00019476873223957\n",
            "train loss:0.004037960367948214\n",
            "train loss:0.00038031461881773157\n",
            "train loss:0.0016416264215589602\n",
            "train loss:0.006489377327747151\n",
            "train loss:0.0023013929755532074\n",
            "train loss:0.0005166793538121993\n",
            "train loss:0.0018178570189917793\n",
            "train loss:0.0009898501242144656\n",
            "train loss:0.000745977921823634\n",
            "train loss:0.00028481429725613983\n",
            "train loss:0.00011075222026036518\n",
            "train loss:8.04157991857503e-05\n",
            "train loss:0.05255150373169144\n",
            "train loss:0.00026507014139662846\n",
            "train loss:0.00031640595434696996\n",
            "train loss:5.883151837209799e-05\n",
            "train loss:0.0006192602389021929\n",
            "train loss:0.028957439011746938\n",
            "train loss:0.0009034726818801116\n",
            "train loss:5.262046426074014e-05\n",
            "train loss:0.0009290818064617504\n",
            "train loss:0.0012272854747409057\n",
            "train loss:0.0007902317571841892\n",
            "train loss:0.002781031358771813\n",
            "train loss:0.00013397421016266025\n",
            "train loss:0.006281871757454736\n",
            "train loss:1.2197709803349081e-05\n",
            "train loss:0.0004322610339115108\n",
            "train loss:0.0020601237148764723\n",
            "train loss:0.00045363500593261137\n",
            "train loss:0.001209547445216126\n",
            "train loss:0.0018689217104795111\n",
            "train loss:0.0013984332617526546\n",
            "train loss:0.0014516779775226197\n",
            "train loss:0.0007204153484406109\n",
            "train loss:0.001441017221001083\n",
            "train loss:5.319042774468195e-05\n",
            "train loss:7.40052985528997e-05\n",
            "train loss:4.711711454266547e-05\n",
            "train loss:0.0007924730978294647\n",
            "train loss:5.492218480365801e-05\n",
            "train loss:0.00043629791929310685\n",
            "train loss:0.0017983240310957705\n",
            "train loss:0.005138997050523602\n",
            "train loss:0.0027935035723769177\n",
            "train loss:0.0008823495875882534\n",
            "train loss:0.0007272248434755697\n",
            "train loss:0.0009736795342957085\n",
            "train loss:0.000734642652513287\n",
            "train loss:0.0022329474826739953\n",
            "train loss:3.537393959451903e-05\n",
            "train loss:0.003090216459033266\n",
            "train loss:0.0002803482320753375\n",
            "train loss:0.0017687208524978346\n",
            "train loss:0.0030103805885339173\n",
            "train loss:0.00015876412315012637\n",
            "train loss:0.0006398713306863006\n",
            "=============== Final Test Accuracy ===============\n",
            "test acc:0.9873\n",
            "Saved Network Parameters!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sGd1saXkYaF"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from simple_convnet import SimpleConvNet\n",
        "\n",
        "def filter_show(filters, nx=8, margin=3, scale=10):\n",
        "  \n",
        "    FN, C, FH, FW = filters.shape\n",
        "    ny = int(np.ceil(FN / nx))\n",
        "\n",
        "    fig = plt.figure()\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "    for i in range(FN):\n",
        "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
        "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "network = SimpleConvNet()\n",
        "# ランダム初期化後の重み\n",
        "filter_show(network.params['W1'])\n",
        "\n",
        "# 学習後の重み\n",
        "network.load_params(\"params.pkl\")\n",
        "filter_show(network.params['W1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HfutnzxlRJE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}